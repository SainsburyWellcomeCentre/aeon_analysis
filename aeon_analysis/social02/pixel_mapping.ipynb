{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image registration to create a pixel map between top camera (A) and quadrant camera (B) with overlapping fields of view (FOV), where quadtant camera's FOV is a subset and a rotated version of top camera's FOV. \n",
    "1. Exrtact and Load Images: Extract random matching frames from the video frames for both Camera A and Camera B and load them. Use multiple images to get moe accurate map.\n",
    "2. Detect Features: Use ORB (Oriented FAST and Rotated BRIEF) to detect keypoints and get descriptors. \n",
    "3. Match Features: Use a matcher (rute-Force matcher with Hamming distance) to find corresponding keypoints between the images. Keep best matches.\n",
    "4. Compute Homography: Estimate the homography matrix (matrix that best transforms the matched keypoints from Camera B's frame of reference to Camera A's frame of reference) to align the images (rotation, translation, scaling).\n",
    "5. Warp Images: Apply the homography to transform Camera B's images to align with Camera A's perspective.\n",
    "6. Pixel map: Get the pixel map from A to B and vice versa based on this.\n",
    "7. Multi-frame averaging: Perform these computation on many frames and average over individual homography matrices for more accurate results.\n",
    "6. Visualise results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method seems to work better then other tried, becasue:\n",
    "\n",
    "- can deal with low number of unique features in the image (feature matching algorithms failed)\n",
    "- can deal with orientation and perspective differences (template matching (= find B within A) failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook settings and imports\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"File paths (example: CameraNorth and CameraTop)\"\"\"\n",
    "camera_a = 'CameraTop'\n",
    "camera_b = 'CameraNorth'\n",
    "\n",
    "# Define file paths\n",
    "base_path = '/ceph/aeon/aeon'\n",
    "video_path = base_path + '/data/raw/AEON3/social0.2/2024-01-31T11-28-39'\n",
    "video_path_a = video_path + f'/{camera_a}/{camera_a}_2024-01-31T11-00-00.avi'\n",
    "video_path_b = video_path + f'/{camera_b}/{camera_b}_2024-01-31T11-00-00.avi'\n",
    "\n",
    "# Define image output directory\n",
    "output_dir = base_path + '/code/scratchpad/Orsi/pixel_mapping/example_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract some frames from videos and save them as images\"\"\"\n",
    "\n",
    "number_of_frames = 20\n",
    "\n",
    "# Function to get total number of frames in a video\n",
    "def get_total_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return total_frames\n",
    "\n",
    "# Function to extract and save frames\n",
    "def extract_and_save_frames(video_path, frame_indices, prefix):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        frame_filename = os.path.join(output_dir, f'{prefix}_frame_{i}.png')\n",
    "        if not os.path.exists(frame_filename):  # Check if frame already exists\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "    cap.release()\n",
    "    \n",
    "# Check if there are already number_of_frames frames saved for both cameras\n",
    "existing_frames_north = [f for f in os.listdir(output_dir) if f.startswith(f'{camera_b}_frame_')]\n",
    "existing_frames_top = [f for f in os.listdir(output_dir) if f.startswith(f'{camera_a}_frame_')]\n",
    "\n",
    "if len(existing_frames_north) >= number_of_frames and len(existing_frames_top) >= number_of_frames:\n",
    "    print(\"Frames already exist for both cameras. No new frames will be saved.\")\n",
    "else:\n",
    "    # Get total number of frames in the videos\n",
    "    total_frames_a = get_total_frames(video_path_a)\n",
    "    total_frames_b = get_total_frames(video_path_b)\n",
    "    print(total_frames_b)\n",
    "\n",
    "    # Ensure both videos have the same number of frames\n",
    "    assert total_frames_a == total_frames_b, \"Videos do not have the same number of frames.\"\n",
    "\n",
    "    # Randomly select number_of_frames frame indices\n",
    "    random_frame_indices = random.sample(range(total_frames_a), number_of_frames)\n",
    "    print(random_frame_indices)\n",
    "\n",
    "    # Extract and save frames from both videos\n",
    "    extract_and_save_frames(video_path_a, random_frame_indices, f'{camera_a}')\n",
    "    extract_and_save_frames(video_path_b, random_frame_indices, f'{camera_b}')\n",
    "\n",
    "    print(f\"Extracted frames saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(camera_a_frame_path, camera_b_frame_path):\n",
    "    \"\"\"\n",
    "    Load images from the given paths.\n",
    "    \"\"\"\n",
    "    img_a = cv2.imread(camera_a_frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_b = cv2.imread(camera_b_frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return img_a, img_b\n",
    "\n",
    "def detect_and_match_features(img_a, img_b, nfeatures=1000):\n",
    "    \"\"\"\n",
    "    Detect and match features between two images using ORB.\n",
    "    \"\"\"\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures)\n",
    "\n",
    "    # Detect keypoints and descriptors\n",
    "    kp_a, des_a = orb.detectAndCompute(img_a, None)\n",
    "    kp_b, des_b = orb.detectAndCompute(img_b, None)\n",
    "\n",
    "    # Match features using the Brute-Force matcher with Hamming distance\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des_a, des_b)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)  # Sort matches by distance\n",
    "\n",
    "    return kp_a, kp_b, matches\n",
    "\n",
    "def compute_homography(kp_a, kp_b, matches):\n",
    "    \"\"\"\n",
    "    Compute the homography matrix to map Image B to Image A.\n",
    "    \"\"\"\n",
    "    # Extract matched keypoints\n",
    "    src_pts = np.float32([kp_b[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp_a[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Compute homography using RANSAC\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return H, mask\n",
    "\n",
    "def warp_image(img_b, H, img_a_shape):\n",
    "    \"\"\"\n",
    "    Warp Image B to Image A's perspective using the homography matrix.\n",
    "    \"\"\"\n",
    "    # Apply homography to warp Image B\n",
    "    img_b_aligned = cv2.warpPerspective(img_b, H, (img_a_shape[1], img_a_shape[0]))\n",
    "    return img_b_aligned\n",
    "\n",
    "def plot_results(img_a, img_b, img_b_aligned, kp_a, kp_b, matches, mask):\n",
    "    \"\"\"\n",
    "    Plot the original and aligned images, and matched features with each match in a different color.\n",
    "    \"\"\"\n",
    "    # Generate different colors for each match line\n",
    "    colors = [(np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)) for _ in matches]\n",
    "\n",
    "    # Draw matches\n",
    "    img_matches = cv2.drawMatches(img_a, kp_a, img_b, kp_b, matches, None, \n",
    "                                  matchColor=None, singlePointColor=None, \n",
    "                                  matchesMask=mask.ravel().tolist(), flags=2)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_a, cmap='gray')\n",
    "    plt.title(\"Camera A (Original)\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(img_b, cmap='gray')\n",
    "    plt.title(\"Camera B (Original)\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img_b_aligned, cmap='gray')\n",
    "    plt.title(\"Camera B (Aligned to A)\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(img_matches)\n",
    "    plt.title('Feature Matches')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_pixel_mapping(kp_a, kp_b, H, img_shape):\n",
    "    \"\"\"\n",
    "    Calculate the pixel mapping from Image A to Image B and vice versa.\n",
    "    \"\"\"\n",
    "    height, width = img_shape\n",
    "    map_a_to_b = np.zeros((height, width, 2), dtype=np.float32)\n",
    "    map_b_to_a = np.zeros((height, width, 2), dtype=np.float32)\n",
    "\n",
    "    # Create pixel grid for Image A\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "    # Flatten and combine to create homogeneous coordinates\n",
    "    points_a = np.stack([grid_x.ravel(), grid_y.ravel(), np.ones(grid_x.size)], axis=-1).T\n",
    "\n",
    "    # Map pixels from A to B using the homography\n",
    "    points_b = H @ points_a\n",
    "    points_b /= points_b[2, :]  # Convert to Cartesian coordinates\n",
    "\n",
    "    # Store the results in the pixel map\n",
    "    map_a_to_b[grid_y, grid_x] = points_b[:2].T.reshape(height, width, 2)\n",
    "\n",
    "    # Calculate the inverse homography for mapping from B to A\n",
    "    H_inv = np.linalg.inv(H)\n",
    "    points_b_inv = H_inv @ points_b\n",
    "    points_b_inv /= points_b_inv[2, :]  # Convert to Cartesian coordinates\n",
    "\n",
    "    # Store the results in the pixel map\n",
    "    map_b_to_a[grid_y, grid_x] = points_b_inv[:2].T.reshape(height, width, 2)\n",
    "\n",
    "    return map_a_to_b, map_b_to_a\n",
    "\n",
    "def multi_frame_registration(frame_paths_a, frame_paths_b):\n",
    "    \"\"\"\n",
    "    Main function to perform registration using multiple frames to compute a more accurate homography.\n",
    "    \"\"\"\n",
    "    homographies = []\n",
    "    for frame_a_path, frame_b_path in zip(frame_paths_a, frame_paths_b):\n",
    "        # Load Images\n",
    "        img_a, img_b = load_images(frame_a_path, frame_b_path)\n",
    "        \n",
    "        # Detect and Match Features\n",
    "        kp_a, kp_b, matches = detect_and_match_features(img_a, img_b)\n",
    "\n",
    "        # Compute Homography\n",
    "        H, mask = compute_homography(kp_a, kp_b, matches)\n",
    "        if H is not None:\n",
    "            homographies.append(H)\n",
    "    \n",
    "    # Average Homography\n",
    "    H_avg = np.mean(homographies, axis=0)\n",
    "    print(f\"Averaged Homography:\\n{H_avg}\")\n",
    "\n",
    "    # Use the first image shape for warping\n",
    "    img_a, img_b = load_images(frame_paths_a[0], frame_paths_b[0])\n",
    "    img_b_aligned = warp_image(img_b, H_avg, img_a.shape)\n",
    "    \n",
    "    # Plot Results\n",
    "    plot_results(img_a, img_b, img_b_aligned, kp_a, kp_b, matches, mask)\n",
    "    \n",
    "    # Calculate Pixel Maps\n",
    "    map_a_to_b, map_b_to_a = calculate_pixel_mapping(kp_a, kp_b, H_avg, img_a.shape)\n",
    "\n",
    "    return H_avg, map_a_to_b, map_b_to_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect frame paths\n",
    "frame_paths_a = [os.path.join(output_dir, f'{camera_a}_frame_{i}.png') for i in range(number_of_frames)]\n",
    "frame_paths_b = [os.path.join(output_dir, f'{camera_b}_frame_{i}.png') for i in range(number_of_frames)]\n",
    "\n",
    "# Run the multi-frame registration and plot for first frame\n",
    "H_avg, map_a_to_b, map_b_to_a = multi_frame_registration(frame_paths_a, frame_paths_b)\n",
    "H_avg, map_a_to_b, map_b_to_a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

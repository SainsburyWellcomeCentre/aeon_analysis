{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import aeon\n",
    "from aeon.io import video\n",
    "from aeon.schema.schemas import exp02, social02\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "directory = '/ceph/aeon/aeon/code/scratchpad/sleap/multi_point_tracking/multi_animal_CameraTop/predictions_social02'\n",
    "h5_directory = 'AEON4/analyses'\n",
    "filename = 'CameraTop_2024-02-17T18-00-00_full_pose_id_all_frames.analysis.h5'\n",
    "filepath = os.path.join(directory, h5_directory, filename)\n",
    "\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(filepath, 'r') as f:\n",
    "    # Extract the tracks\n",
    "    tracks = f['tracks'][:]\n",
    "    track_occupancy = f['track_occupancy'][:]\n",
    "    track_names = f['track_names'][:]\n",
    "    track_names = [name.decode('utf-8') for name in track_names]\n",
    "    node_names = f['node_names'][:].astype(str)\n",
    "    edge_inds = f['edge_inds'][:]\n",
    "    video_path = f['video_path'][()].decode('utf-8')\n",
    "print(track_names)\n",
    "print(tracks.shape)\n",
    "\n",
    "root = Path(\"/ceph/aeon/aeon/data/raw/AEON4/social0.2\")\n",
    "start, end = pd.Timestamp(\"2024-02-17 18:00:00\"), pd.Timestamp(\"2024-02-17 19:00:00\"),\n",
    "centroid_blob_data = aeon.load(root, exp02.CameraTop.Position, start, end)\n",
    "centroid_blob_data.reset_index(inplace=True)\n",
    "centroid_blob_data.dropna(inplace=True)\n",
    "print(centroid_blob_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations and extraction of fighting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "spine2_index = np.where(node_names == 'spine2')[0][0]\n",
    "cm2px = 5.4  # 1 cm = 5.4 px\n",
    "fps = 50\n",
    "\n",
    "# Centroid distances \n",
    "centroid_mouse0 = tracks[0, :, spine2_index, :]\n",
    "centroid_mouse1 = tracks[1, :, spine2_index, :]\n",
    "centroid_distances = np.linalg.norm(centroid_mouse0 - centroid_mouse1, axis=0)\n",
    "centroid_distances_ffill = pd.Series(centroid_distances).fillna(method='ffill').to_numpy()\n",
    "\n",
    "# Internode distances\n",
    "internode_distances_mouse0 = np.zeros((len(edge_inds), tracks.shape[3]))\n",
    "internode_distances_mouse1 = np.zeros((len(edge_inds), tracks.shape[3]))\n",
    "for i, node_pair in enumerate(edge_inds):\n",
    "    internode_distances_mouse0[i] = np.linalg.norm(tracks[0, :, node_pair[0], :] - tracks[0, :, node_pair[1], :], axis=0)\n",
    "    internode_distances_mouse1[i] = np.linalg.norm(tracks[1, :, node_pair[0], :] - tracks[1, :, node_pair[1], :], axis=0)\n",
    "nose_head_distances_mouse0 = internode_distances_mouse0[0,:]\n",
    "nose_head_distances_mouse1 = internode_distances_mouse1[0,:]\n",
    "mean_interspinal_distances_mouse0 = np.mean(internode_distances_mouse0[3:,:], axis=0)\n",
    "mean_interspinal_distances_mouse1 = np.mean(internode_distances_mouse1[3:,:], axis=0)\n",
    "\n",
    "# Blob speed\n",
    "dxy = centroid_blob_data[[\"x\", \"y\"]].diff().values[1:]\n",
    "dt = (np.diff(centroid_blob_data[\"time\"]) / 1e6).astype(int)  # ms\n",
    "centroid_blob_data[\"speed\"] = np.concatenate(([0], np.linalg.norm(dxy, axis=1) / dt / cm2px * 1000))  # cm/s\n",
    "k = np.ones(10) / 10  # running avg filter kernel (10 frames)\n",
    "centroid_blob_data[\"speed\"] = np.convolve(centroid_blob_data[\"speed\"], k, mode=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 20 # px\n",
    "max_nose_head_distance = 7 # px\n",
    "max_interspinal_distance = 10 # px\n",
    "min_blob_speed = 3  # cm/s \n",
    "\n",
    "# Condition 1: the mice are close to each other\n",
    "cond1_frames = np.where(centroid_distances_ffill < max_distance)[0]\n",
    "\n",
    "# Condition 2: the mean internode distances are within a certain range\n",
    "# Condition 2a: the distance between the mice's noses and heads is within a certain range\n",
    "cond2a = np.logical_or(nose_head_distances_mouse0 > max_nose_head_distance, nose_head_distances_mouse1 > max_nose_head_distance)\n",
    "# Condition 2b: the mean distance between the mice's own spine nodes is within a certain range\n",
    "cond2b = np.logical_or(mean_interspinal_distances_mouse0 > max_interspinal_distance, mean_interspinal_distances_mouse1 > max_interspinal_distance)\n",
    "# Find frames where conditions 2a or 2b are true\n",
    "cond2 = np.logical_or(cond2a, cond2b)\n",
    "cond2_frames = np.where(cond2)[0]\n",
    "\n",
    "# Condition 3: the speed of the blob is above a certain threshold\n",
    "cond3_frames = centroid_blob_data[(centroid_blob_data[\"speed\"] > min_blob_speed)].index.values\n",
    "\n",
    "possible_fights = np.intersect1d(np.intersect1d(cond1_frames, cond2_frames), cond3_frames)\n",
    "possible_fights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide possible fighting frames into subarrays of consecutive frames = one possible fight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 50\n",
    "max_frame_gap = fps*4\n",
    "min_num_frames = int(fps*0.1)\n",
    "\n",
    "# Divide possible_tube_test_starts into sub_arrays of consecutive frames (allowing for gaps up to a certain max)\n",
    "diffs = np.diff(possible_fights)\n",
    "indices = np.where(diffs > max_frame_gap)[0]\n",
    "indices += 1\n",
    "possible_fights = np.split(possible_fights, indices)\n",
    "# Filter sub_arrays to keep only those with more than a certain number of frames\n",
    "possible_fights = [sub_array for sub_array in possible_fights if len(sub_array) > min_num_frames]\n",
    "print(len(possible_fights), possible_fights)\n",
    "\n",
    "\n",
    "max_frame_gap = fps*2\n",
    "# Include empty frames where the mice were close to each other in the previous frame they were detected\n",
    "# If these occur close to or during the time of a possible fight, it's likely the mice are fighting and not detected due to weird poses\n",
    "# These frames will have been dropped by condition 2 but can help connect/extend the possible fights detected above\n",
    "empty_frames = np.where(np.where((track_occupancy[:, 0] == 0) & (track_occupancy[:, 1] == 0), 1, 0))[0]\n",
    "empty_frames = np.intersect1d(cond1_frames, empty_frames) # Only select empty frames where the mice were previously close to each other\n",
    "possible_fights = np.concatenate(possible_fights)\n",
    "possible_fights_w_empty_frames = np.union1d(possible_fights, empty_frames)\n",
    "diffs = np.diff(possible_fights_w_empty_frames)\n",
    "indices = np.where(diffs > max_frame_gap)[0]\n",
    "indices += 1\n",
    "possible_fights_w_empty_frames = np.split(possible_fights_w_empty_frames, indices)\n",
    "# Only keep the subarrays that contain at least one frame from the original possible_fights array\n",
    "# i.e., don't include subarrays entirely composed of empty frames\n",
    "check = [any(frame in possible_fights for frame in sub_array) for sub_array in possible_fights_w_empty_frames]\n",
    "possible_fights = [possible_fights_w_empty_frames[i] for i, val in enumerate(check) if val]\n",
    "print(len(possible_fights_w_empty_frames), len(possible_fights), possible_fights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of possible fights based on the mean individual speeds of the mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_centroid_speed = 20  # cm/s min speed for fighting\n",
    "min_both_centroid_speed = 15\n",
    "\n",
    "fights = []\n",
    "for sub_array in possible_fights:\n",
    "    start = sub_array[0]-1\n",
    "    end = sub_array[-1]\n",
    "    # Clean up identity\n",
    "    # Trim the centroid data to the frames we are currently considering\n",
    "    centroid_mouse0_trimmed = centroid_mouse0[:, start:end]\n",
    "    centroid_mouse1_trimmed = centroid_mouse1[:, start:end]\n",
    "    # Initialize variables to hold the last known positions of each mouse (used to deal with NaN values in the tracking data)\n",
    "    last_known_pos0 = centroid_mouse0_trimmed[:, 0]\n",
    "    last_known_pos1 = centroid_mouse1_trimmed[:, 0]\n",
    "    # Initialize arrays to hold the cleaned centroid data\n",
    "    centroid_mouse0_cleaned = centroid_mouse0_trimmed.copy()\n",
    "    centroid_mouse1_cleaned = centroid_mouse1_trimmed.copy()\n",
    "    # Loop over the frames from the second frame to the last\n",
    "    for i in range(1, end-start):\n",
    "        if np.isnan(centroid_mouse0_trimmed[:, i]).any() and np.isnan(centroid_mouse1_trimmed[:, i]).any():\n",
    "            continue\n",
    "        # Calculate the Euclidean distance from each centroid in the current frame to each centroid in the previous frame\n",
    "        dists = np.zeros((2, 2))\n",
    "        dists[0, 0] = np.sqrt(np.sum((centroid_mouse0_trimmed[:, i] - last_known_pos0)**2))\n",
    "        dists[0, 1] = np.sqrt(np.sum((centroid_mouse0_trimmed[:, i] - last_known_pos1)**2))\n",
    "        dists[1, 0] = np.sqrt(np.sum((centroid_mouse1_trimmed[:, i] - last_known_pos0)**2))\n",
    "        dists[1, 1] = np.sqrt(np.sum((centroid_mouse1_trimmed[:, i] - last_known_pos1)**2))\n",
    "        if dists[0, 0] + dists[1, 1] <= dists[0, 1] + dists[1, 0]:\n",
    "            last_known_pos0 = centroid_mouse0_trimmed[:, i]\n",
    "            last_known_pos1 = centroid_mouse1_trimmed[:, i] \n",
    "        else:\n",
    "            last_known_pos0 = centroid_mouse1_trimmed[:, i]\n",
    "            last_known_pos1 = centroid_mouse0_trimmed[:, i]\n",
    "            centroid_mouse0_cleaned[:, i], centroid_mouse1_cleaned[:, i] = centroid_mouse1_trimmed[:, i].copy(), centroid_mouse0_trimmed[:, i].copy()\n",
    "    # Calculate centroid speed for each mouse\n",
    "    mouse0_df = pd.DataFrame(centroid_mouse0_cleaned.T, columns=[\"x\", \"y\"]).dropna()\n",
    "    mouse1_df = pd.DataFrame(centroid_mouse1_cleaned.T, columns=[\"x\", \"y\"]).dropna()\n",
    "    dt_mouse0 = np.diff(mouse0_df.index.values*1000/fps).astype(int) # ms\n",
    "    dt_mouse1 = np.diff(mouse1_df.index.values*1000/fps).astype(int) # ms\n",
    "    dxy_mouse0 = mouse0_df[['x', 'y']].diff().values[1:]\n",
    "    dxy_mouse1 = mouse1_df[['x', 'y']].diff().values[1:]\n",
    "    mouse0_df = mouse0_df.iloc[1:]\n",
    "    mouse1_df = mouse1_df.iloc[1:]\n",
    "    mouse0_df[\"speed\"] = np.linalg.norm(dxy_mouse0, axis=1) / dt_mouse0 / cm2px * 1000  # cm/s\n",
    "    mouse1_df[\"speed\"] = np.linalg.norm(dxy_mouse1, axis=1) / dt_mouse1 / cm2px * 1000  # cm/s\n",
    "    mean_centroid0_speed = mouse0_df[\"speed\"].mean()\n",
    "    mean_centroid1_speed = mouse1_df[\"speed\"].mean()\n",
    "    mean_both_centroid_speed = np.mean([mean_centroid0_speed, mean_centroid1_speed])\n",
    "    # Add to fights list if either of the mice have a speed above the threshold\n",
    "    if (mean_centroid0_speed > min_centroid_speed or mean_centroid1_speed > min_centroid_speed or mean_both_centroid_speed > min_both_centroid_speed):\n",
    "        print(mean_centroid0_speed, mean_centroid1_speed)\n",
    "        # print(mouse1_df)\n",
    "        fights.append(sub_array)\n",
    "print(fights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_export_dir = directory + '/fight_videos/'\n",
    "\n",
    "fight_data = {'start_frame' : [], 'end_frame' : [], 'start_timestamp' : [], 'end_timestamp' : [], 'duration (seconds)' : []}\n",
    "\n",
    "for subarray in fights:\n",
    "    metadata_retrieval_matches = re.search(r'(.*?)(\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2}).*(\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2})', video_path)\n",
    "    arena_number_match = re.search(r'AEON(\\d)', video_path)\n",
    "    root = metadata_retrieval_matches.group(1)\n",
    "    chunk_time = pd.to_datetime(metadata_retrieval_matches.group(3), format='%Y-%m-%dT%H-%M-%S')\n",
    "    arena_number = arena_number_match.group(1)\n",
    "    # Option to change the drive\n",
    "    new_drive = \"/ceph/aeon\"\n",
    "    root = re.sub(r'^.*?:', new_drive, root)\n",
    "\n",
    "    start_frame = subarray[0]\n",
    "    end_frame = subarray[-1]\n",
    "    start_timestamp = chunk_time + pd.Timedelta(seconds=start_frame/fps)\n",
    "    end_timestamp = chunk_time + pd.Timedelta(seconds=end_frame/fps)\n",
    "    duration = (end_timestamp - start_timestamp).total_seconds()\n",
    "    # Very short fights are likely to be false positives (errors in tracking)\n",
    "    if duration > 1:\n",
    "        fight_data['start_frame'].append(start_frame)\n",
    "        fight_data['end_frame'].append(end_frame)\n",
    "        fight_data['start_timestamp'].append(start_timestamp)\n",
    "        fight_data['end_timestamp'].append(end_timestamp)\n",
    "        fight_data['duration (seconds)'].append(duration)\n",
    "\n",
    "        vid_start = start_timestamp - pd.Timedelta(seconds=1)\n",
    "        vid_end   = end_timestamp + pd.Timedelta(seconds=1)\n",
    "        frames_info = aeon.load(root, social02.CameraTop.Video, start=vid_start, end=vid_end)\n",
    "        vid = video.frames(frames_info)\n",
    "        save_path = vid_export_dir + \"AEON\" + arena_number + \"_CameraTop_\" + start_timestamp.strftime('%Y-%m-%dT%H-%M-%S') + \"_\" + end_timestamp.strftime('%Y-%m-%dT%H-%M-%S') + \".avi\"\n",
    "        video.export(vid, save_path, fps=fps)\n",
    "fights_df = pd.DataFrame(fight_data)\n",
    "display(fights_df)\n",
    "fights_df['start_timestamp'] = fights_df['start_timestamp'].apply(lambda x: x.strftime('%Y-%m-%dT%H-%M-%S'))\n",
    "fights_df['end_timestamp'] = fights_df['end_timestamp'].apply(lambda x: x.strftime('%Y-%m-%dT%H-%M-%S'))\n",
    "csv_path = vid_export_dir + \"AEON\" + arena_number + \"_fights.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    fights_df.to_csv(csv_path, index=False)\n",
    "else:\n",
    "    existing_fights_df = pd.read_csv(csv_path)\n",
    "    fights_df = pd.concat([existing_fights_df, fights_df]).drop_duplicates()\n",
    "    fights_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Identity Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chang Huan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import deque\n",
    "import datajoint as dj\n",
    "import aeon\n",
    "from aeon.io import video\n",
    "from aeon.io import api\n",
    "from aeon.schema.schemas import social02\n",
    "from shapely.geometry import Point, Polygon\n",
    "from aeon.dj_pipeline.analysis.block_analysis import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "\"\"\"Define functions\"\"\"\n",
    "\n",
    "\n",
    "def plot_xy(df):\n",
    "    \"\"\"Function to plot the x and y positions of the subjects.\"\"\"\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "    classes = df[\"class\"].unique()\n",
    "    for class_ in classes:\n",
    "        data = df[df[\"class\"] == class_]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index,\n",
    "                y=data[\"x\"],\n",
    "                mode=\"markers\",\n",
    "                name=class_,  # Use the class as the name of the trace\n",
    "                marker=dict(color=subject_colors_dict[class_], symbol=\"circle\"),\n",
    "                hovertemplate=\"Speed: %{text}\",\n",
    "                text=data[\"speed\"].tolist(),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index,\n",
    "                y=data[\"y\"],\n",
    "                mode=\"markers\",\n",
    "                name=class_,  # Use the class as the name of the trace\n",
    "                marker=dict(color=subject_colors_dict[class_], symbol=\"square\"),\n",
    "                hovertemplate=\"Speed: %{text}\",\n",
    "                text=data[\"speed\"].tolist(),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "    fig.update_yaxes(title_text=\"x position\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"y position\", row=2, col=1)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_speed(df):\n",
    "    \"\"\"Function to plot the speeds of the subjects.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    classes = df[\"class\"].unique()\n",
    "    for class_ in classes:\n",
    "        data = df[df[\"class\"] == class_]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index,\n",
    "                y=data[\"speed\"],\n",
    "                mode=\"markers\",\n",
    "                name=class_,  # Use the class as the name of the trace\n",
    "                marker=dict(color=subject_colors_dict[class_], symbol=\"circle\"),\n",
    "            )\n",
    "        )\n",
    "    fig.update_yaxes(title_text=\"speed\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compute_class_speed(df):\n",
    "    \"\"\"Function to compute the instantaneous speed of each class.\"\"\"\n",
    "    return (\n",
    "        df.groupby(\"class\")[[\"x\", \"y\"]].diff().apply(np.linalg.norm, axis=1)\n",
    "        / df.reset_index().groupby(\"class\")[\"time\"].diff().dt.total_seconds().values\n",
    "    )\n",
    "\n",
    "def compute_speed_mask(df, threshold):\n",
    "    \"\"\"Function to compute the mask of df rows with speed > threshold.\"\"\"\t\n",
    "    speed_mask = (np.isfinite(df[\"speed\"].values)) & (\n",
    "        df[\"speed\"] > threshold\n",
    "    )\n",
    "    # select only rows when more than 1 subject has speed > threshold\n",
    "    speed_mask &= (speed_mask.groupby(level=0).transform(\"sum\") > 1)\n",
    "    return speed_mask\n",
    "\n",
    "\"\"\"Standardize subject colors for plotting\"\"\"\n",
    "\n",
    "subject_colors = plotly.colors.qualitative.Plotly\n",
    "subject_colors_dict = {\n",
    "    \"BAA-1104045\": subject_colors[0],\n",
    "    \"BAA-1104047\": subject_colors[1],\n",
    "    \"BAA-1104048\": subject_colors[2],\n",
    "    \"BAA-1104049\": subject_colors[3],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just get metadata base on a random solo block\n",
    "\n",
    "exp_start = pd.Timestamp(\"2024-01-31\")\n",
    "\n",
    "metadata = (\n",
    "    api.load('/ceph/aeon/aeon/data/raw/AEON3/social0.2', social02.Metadata, exp_start, pd.Timestamp('2024-02-11 15:57:42')).iloc[0].metadata\n",
    ")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use processed instead cuz it has likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/ceph/aeon/aeon/data/processed/AEON3/social0.2/\"\n",
    "# Pick start and end time as you like\n",
    "vid_start = pd.Timestamp(\"2024-02-18 17:00:00\")\n",
    "vid_end = vid_start + pd.Timedelta(\"1h\") \n",
    "# All files within the root directory with the following pattern will be loaded\n",
    "print(\"Pattern:\", aeon.io.reader.Pose(pattern=\"CameraTop_202*\").pattern)\n",
    "df = api.load(root, aeon.io.reader.Pose(pattern=\"CameraTop_202*\"), start=vid_start, end=vid_end) \n",
    "df= df[df['part'] == 'spine2']\n",
    "df = df.drop(columns=['part_likelihood', 'part'])\n",
    "pose_df = df\n",
    "pose_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format df\n",
    "# rename variables\n",
    "pose_df.rename(columns={\"identity\": \"class\",\n",
    "                        \"position_timestamps\": \"time\",\n",
    "                        \"identity_likelihood\": \"class_likelihood\"}, inplace=True)\n",
    "pose_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2px = 5.4 \n",
    "fps = 50\n",
    "unique_classes = pose_df[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample ot 10hz\n",
    "pose_df = pose_df.reset_index()\n",
    "\n",
    "# Select every 5th timestamp\n",
    "timestamps = pose_df['time'].iloc[::5]\n",
    "\n",
    "# Filter the DataFrame to keep rows corresponding to the selected timestamps\n",
    "pose_df = pose_df[pose_df['time'].isin(timestamps)]\n",
    "\n",
    "# Set 'time' back as the index\n",
    "pose_df = pose_df.set_index('time')\n",
    "\n",
    "# Display the downsampled DataFrame\n",
    "pose_df = pose_df.sort_index()\n",
    "pose_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the speed \n",
    "pose_df[\"speed\"] = compute_class_speed(pose_df)\n",
    "pose_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualise data\n",
    "fig = plot_xy(pose_df[:10000])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues\n",
    "- Track IDs swap between frames (temporal discontinuities)\n",
    "- Same Track ID is assigned to multiple animals in the same frame/timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Assign the row with duplicated ID with lower likelihood to another ID\"\"\"\n",
    "\n",
    "pose_df_cp = pose_df.reset_index().copy()\n",
    "classes = np.array(pose_df_cp[\"class\"].unique())\n",
    "# Mask for rows with multiple assignments of the same ID at the same time\n",
    "many_to_one_mask = pose_df_cp.groupby([\"time\", \"class\"]).transform(\"size\") > 1\n",
    "duplicated_data = pose_df_cp.loc[many_to_one_mask]\n",
    "print(duplicated_data.shape)\n",
    "# Indices for rows with lower likelihood\n",
    "low_likelihood_idx = duplicated_data.loc[\n",
    "    ~duplicated_data.index.isin(\n",
    "        duplicated_data.groupby([\"time\", \"class\"])[\"class_likelihood\"].idxmax()\n",
    "    )\n",
    "].index\n",
    "# This assigns another class randomly (in 2-animal case, it's the other animal, but in >2-animal case, it may assign duplicate IDs again)\n",
    "pose_df_cp.loc[low_likelihood_idx, \"class\"] = pose_df_cp.loc[low_likelihood_idx].apply(\n",
    "    lambda x: np.random.choice(classes[classes != x[\"class\"]]), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with timestamps where only one class has data\n",
    "initial_row_count = pose_df_cp.shape[0]\n",
    "valid_times = pose_df_cp.groupby(\"time\")[\"class\"].nunique() > 1\n",
    "pose_df_cp = pose_df_cp[pose_df_cp[\"time\"].isin(valid_times[valid_times].index)]\n",
    "final_row_count = pose_df_cp.shape[0]\n",
    "\n",
    "# Print the number of rows removed\n",
    "rows_removed = initial_row_count - final_row_count\n",
    "print(f\"Number of rows removed: {rows_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_df_cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get speed\n",
    "pose_df_cp.set_index(\"time\", inplace=True)\n",
    "pose_df_cp[\"speed\"] = compute_class_speed(pose_df_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Temporal discontinuities\n",
    "- Typically we use distance between consecutive frames to determine potential swaps\n",
    "- However, this is not always reliable as there can be missing data (e.g. occlusions) &rarr; use _speed_ \n",
    "\n",
    "Pseudocode\n",
    "```\n",
    "Define a speed threshold for speed violation\n",
    "Start with small time window t (e.g. 3s)\n",
    "While speed violation exists\n",
    "    Use consecutive pairs of violation timestamps as \"start\" and \"end\" of a potential swap duration\n",
    "        If swap duration exceeds t\n",
    "            Discard the current \"start\" and move on to the next iteration, using \"end\" as the next \"start\"\n",
    "        Else \n",
    "            Flip IDs between \"start\" and \"end\"\n",
    "    Recompute speed and speed violation mask\n",
    "    Increase t   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boxplot of speed for each class\n",
    "fig = go.Figure()\n",
    "for class_ in pose_df_cp[\"class\"].unique():\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=pose_df_cp[pose_df_cp[\"class\"] == class_][\"speed\"],\n",
    "            name=class_,\n",
    "            marker=dict(color=subject_colors_dict[class_]),\n",
    "        )\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_threshold = 700\n",
    "speed_mask = compute_speed_mask(pose_df_cp, threshold=speed_threshold)\n",
    "classes = pose_df_cp[\"class\"].unique()\n",
    "timedelta = 3\n",
    "iter = 0\n",
    "max_iter = 4 # limit swap window duration to 3 * 2**(3) = 24 seconds\n",
    "while speed_mask.sum() > 2 and iter <= max_iter: \n",
    "    print(f\"Iteration {iter}: {speed_mask.sum()} rows with speed > {speed_threshold}\")\n",
    "    q = deque(pose_df_cp[speed_mask].index.unique())\n",
    "    while q:\n",
    "        start = q.popleft()\n",
    "        try:\n",
    "            end = q[0]\n",
    "        except IndexError:\n",
    "            break\n",
    "        # compute timedelta between start and end\n",
    "        # ignore if timedelta is more than t seconds\n",
    "        if (end - start) > pd.Timedelta(timedelta, unit=\"s\"):\n",
    "            continue\n",
    "        end = q.popleft()\n",
    "        # ``end`` needs to be exclusive\n",
    "        end = pose_df_cp.index[pose_df_cp.index < end].max()\n",
    "        pose_df_cp.loc[start:end, \"class\"] = pose_df_cp.loc[start:end].apply(\n",
    "            lambda x: np.random.choice(classes[classes != x[\"class\"]]), axis=1\n",
    "        )\n",
    "    # recompute speed and speed_mask\n",
    "    pose_df_cp[\"speed\"] = compute_class_speed(pose_df_cp)\n",
    "    speed_mask = compute_speed_mask(pose_df_cp, threshold=speed_threshold)\n",
    "    # update timedelta\n",
    "    timedelta *= 2\n",
    "    # update iter count\n",
    "    iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high speed frames that remain:\n",
    "speed_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can still have high speed outliers if tracking errors. Delete these unrealistic points and interpolate speed instead\n",
    "max_speed_threshold = 400 * cm2px # 400 cm/s\n",
    "pose_df_cp = pose_df_cp.reset_index()\n",
    "pose_df_cp = pose_df_cp.groupby('class').apply(\n",
    "    # Identify and set unrealistic speed points to NaN and interpolate\n",
    "    lambda group: group.assign(\n",
    "        speed=group['speed'].mask(group['speed'] > max_speed_threshold).interpolate().fillna(method='bfill').fillna(method='ffill')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Reset the index without inserting the 'class' column again\n",
    "pose_df_cp = pose_df_cp.reset_index(drop=True)\n",
    "pose_df_cp= pose_df_cp.set_index(\"time\")\n",
    "pose_df_cp = pose_df_cp.sort_index()\n",
    "\n",
    "\n",
    "pose_df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth data\n",
    "# Apply smoothing using a rolling window separately for each subject\n",
    "window_size = 5  # 5 frames window size = 0.5s at 10hz\n",
    "smoothed_df_list = []\n",
    "\n",
    "for class_name, class_df in pose_df_cp.groupby('class'):\n",
    "    class_df['x'] = class_df['x'].rolling(window=window_size, min_periods=1, center = True).mean()\n",
    "    class_df['y'] = class_df['y'].rolling(window=window_size, min_periods=1, center = True).mean()\n",
    "    smoothed_df_list.append(class_df)\n",
    "\n",
    "# Concatenate the smoothed results back into a single DataFrame\n",
    "smoothed_pose_df_cp = pd.concat(smoothed_df_list)\n",
    "smoothed_pose_df_cp = smoothed_pose_df_cp.sort_index()\n",
    "smoothed_pose_df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_xy(smoothed_pose_df_cp[:10000])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect sleeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition 1:  In nest\n",
    "# Define the nest region as a polygon\n",
    "nest_corners = metadata.ActiveRegion.NestRegion.ArrayOfPoint\n",
    "nest_polygon = Polygon([\n",
    "    (int(nest_corners[0][\"X\"]), int(nest_corners[0][\"Y\"])),\n",
    "    (int(nest_corners[1][\"X\"]), int(nest_corners[1][\"Y\"])),\n",
    "    (int(nest_corners[2][\"X\"]), int(nest_corners[2][\"Y\"])),\n",
    "    (int(nest_corners[3][\"X\"]), int(nest_corners[3][\"Y\"]))\n",
    "])\n",
    "\n",
    "# Function to check if a point is within the nest polygon\n",
    "def is_in_nest(x, y):\n",
    "    point = Point(x, y)\n",
    "    return nest_polygon.contains(point)\n",
    "\n",
    "# Apply the function to create a boolean mask\n",
    "in_nest_mask = smoothed_pose_df_cp.apply(lambda row: is_in_nest(row[\"x\"], row[\"y\"]), axis=1)\n",
    "\n",
    "# Calculate the \"in nest\" time ratio\n",
    "in_nest_time_ratio = in_nest_mask.sum() / len(smoothed_pose_df_cp)\n",
    "print(f'In nest time ratio is {in_nest_time_ratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Sidenote: it can be that the ids aer swappin over two mice bein very close to eac othr while sleeping?? - NO, doesn't help!\n",
    "# Ensure there are exactly two unique classes\n",
    "unique_classes = smoothed_pose_df_cp[\"class\"].unique()\n",
    "if len(unique_classes) != 2:\n",
    "    raise ValueError(\"There should be exactly two unique classes to compute the distance.\")\n",
    "\n",
    "class1, class2 = unique_classes\n",
    "\n",
    "# Pivot the DataFrame to separate x and y coordinates for each class\n",
    "merged_df = smoothed_pose_df_cp.pivot(columns='class', values=['x', 'y'])\n",
    "\n",
    "# Compute the Euclidean distance for each time point\n",
    "merged_df['distance'] = np.sqrt(\n",
    "    (merged_df['x'][class1] - merged_df['x'][class2])**2 +\n",
    "    (merged_df['y'][class1] - merged_df['y'][class2])**2\n",
    ")\n",
    "# Set distance to NaN if any x or y values are None\n",
    "merged_df['distance'] = merged_df['distance'].where(\n",
    "    merged_df['x'][class1].notna() & merged_df['x'][class2].notna() &\n",
    "    merged_df['y'][class1].notna() & merged_df['y'][class2].notna(), np.nan\n",
    ")\n",
    "# Compute the time difference between consecutive frames\n",
    "merged_df['time_diff'] = merged_df.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# Compute the speed (distance/time)\n",
    "merged_df['swapping_speed'] = merged_df['distance'] / merged_df['time_diff']\n",
    "# Set swapping_speed to NaN if time_diff is NaN\n",
    "merged_df['swapping_speed'] = merged_df['swapping_speed'].where(merged_df['time_diff'].notna(), np.nan)\n",
    "\n",
    "# Add the computed columns to the original DataFrame\n",
    "smoothed_pose_df_cp['distance'] = merged_df['distance']\n",
    "smoothed_pose_df_cp['swapping_speed'] = merged_df['swapping_speed']\n",
    "# Set swapping_speed to NaN where speed is NaN\n",
    "smoothed_pose_df_cp['swapping_speed'] = smoothed_pose_df_cp['swapping_speed'].where(smoothed_pose_df_cp['speed'].notna(), np.nan)\n",
    "\n",
    "# Apply smoothing to swapping_speed\n",
    "window_size = 100  # You can adjust the window size as needed\n",
    "smoothed_pose_df_cp['swapping_speed'] = smoothed_pose_df_cp['swapping_speed'].rolling(window=window_size, min_periods=1, center = True).mean()\n",
    "\n",
    "fig = plot_speed(smoothed_pose_df_cp)\n",
    "\n",
    "\n",
    "# Add the smoothed swapping speed as a new trace\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=smoothed_pose_df_cp.index,\n",
    "        y=smoothed_pose_df_cp[\"swapping_speed\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"Smoothed Swapping Speed\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Speed and Smoothed Swapping Speed over time\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Speed\"\n",
    ")\n",
    "\n",
    "fig.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition 2: Below threshold movement for a certain time\n",
    "# apply different threshold to in nest and to outside nest, because in nest awake state has less movement than outside nest normally??\n",
    "# Define thresholds\n",
    "speed_threshold = 20 * cm2px # in cm/s\n",
    "speed_crossing_frame_ratio = 0.05 # for max 5% speed can go over threshold\n",
    "min_sleeping_time = 4 * 60 * fps # met 4min of consiitons met to be sleeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot speed over time\n",
    "fig = plot_speed(smoothed_pose_df_cp)\n",
    "# Add a horizontal line at the speed threshold\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=smoothed_pose_df_cp.index.min(),\n",
    "    y0=speed_threshold,\n",
    "    x1=smoothed_pose_df_cp.index.max(),\n",
    "    y1=speed_threshold,\n",
    "    line=dict(color=\"black\", width=2, dash=\"dash\"),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sleeping_periods(group):\n",
    "    group = group.reset_index()\n",
    "    \n",
    "    # Identify low-speed frames\n",
    "    group['below_threshold'] = (group['speed'] < speed_threshold)\n",
    "    \n",
    "    # Find segments of consecutive below-threshold frames\n",
    "    group['segment'] = (group['below_threshold'] != group['below_threshold'].shift(1)).cumsum() # Create a new segment when the below_threshold value changes\n",
    "    \n",
    "    # Initialize the sleeping column\n",
    "    group['inactive'] = False\n",
    "    \n",
    "    for segment, segment_data in group.groupby('segment'):\n",
    "        low_speed_frames = segment_data['below_threshold'].sum()\n",
    "        total_frames = len(segment_data)\n",
    "        \n",
    "        if low_speed_frames == total_frames:  # All frames in the segment are below the threshold\n",
    "            if total_frames >= min_sleeping_time:\n",
    "                # Mark the entire segment as sleeping\n",
    "                group.loc[segment_data.index, 'inactive'] = True\n",
    "        else:\n",
    "            # Calculate the allowed frames above threshold\n",
    "            allowed_above_threshold = int(speed_crossing_frame_ratio * total_frames)\n",
    "            \n",
    "            if low_speed_frames >= (min_sleeping_time - allowed_above_threshold):\n",
    "                # Mark the entire segment as sleeping\n",
    "                group.loc[segment_data.index, 'inactive'] = True\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply to each class (mouse) group\n",
    "grouped = smoothed_pose_df_cp.groupby('class')\n",
    "smoothed_pose_df_cp = grouped.apply(detect_sleeping_periods).reset_index(drop=True)\n",
    "\n",
    "# Set the time column as the index\n",
    "smoothed_pose_df_cp.set_index('time', inplace=True)\n",
    "smoothed_pose_df_cp.sort_index(inplace=True)\n",
    "\n",
    "# Calculate the ratio of sleeping time\n",
    "sleeping_ratio = smoothed_pose_df_cp['inactive'].sum() / len(smoothed_pose_df_cp)\n",
    "print(f'Ratio of inactive time is {sleeping_ratio}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get intersection of nest and inactive time\n",
    "smoothed_pose_df_cp['sleeping'] = in_nest_mask & smoothed_pose_df_cp['inactive']\n",
    "print(f'Ratio of sleeping time in nest is {smoothed_pose_df_cp[\"sleeping\"].sum() / len(smoothed_pose_df_cp)}')\n",
    "\n",
    "# Assuming plot_speed is a function that plots the speed over time\n",
    "fig = plot_speed(smoothed_pose_df_cp)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=smoothed_pose_df_cp[smoothed_pose_df_cp['class'] == unique_classes[0]].index,\n",
    "        y=smoothed_pose_df_cp[smoothed_pose_df_cp['class'] == unique_classes[0]]['sleeping'].apply(lambda x: 3200 if x else None),\n",
    "        mode=\"markers\",\n",
    "        name=f'{unique_classes[0]}_sleeping',  \n",
    "        marker=dict(color=subject_colors_dict[unique_classes[0]], symbol=\"circle\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=smoothed_pose_df_cp[smoothed_pose_df_cp['class'] == unique_classes[1]].index,\n",
    "        y=smoothed_pose_df_cp[smoothed_pose_df_cp['class'] == unique_classes[1]]['sleeping'].apply(lambda x: 3000 if x else None),\n",
    "        mode=\"markers\",\n",
    "        name=f'{unique_classes[1]}_sleeping', \n",
    "        marker=dict(color=subject_colors_dict[unique_classes[1]], symbol=\"circle\"),\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sleeping detection: better thresholds?\n",
    "- removing a lot fo data, e.g. when onlyone subject\n",
    "- sleeping  ID not awlways correct\n",
    "   - the swap occurs where SLEAP detects only a single instance of the animal\n",
    "   - the swap never ends (at the end of the dataframe)\n",
    "   - animals are close together (in this case do we care?)\n",
    "- grooming detected as sleeping!!\n",
    "- assumes only sleeping in nest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

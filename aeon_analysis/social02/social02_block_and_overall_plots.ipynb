{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social exp timeline\n",
    "\n",
    "# Aeon3\n",
    "#  2024-01-31 : 2024-02-03 - BAA-1104045 pre solo\n",
    "#  2024-02-05 : 2024-02-08 - BAA-1104047 pre solo (dominant)\n",
    "#  2024-02-09 : 2024-02-23 - BAA-1104045, BAA-1104047 social\n",
    "#  2024-02-25 : 2024-02-28 - BAA-1104045 post solo\n",
    "#  2024-02-28 : 2024-03-02 - BAA-1104047 post solo\n",
    "\n",
    "# Aeon4\n",
    "#  2024-01-31 : 2024-02-03 - BAA-1104048 pre solo (dominant)\n",
    "#  2024-02-05 : 2024-02-08 - BAA-1104049 pre solo\n",
    "#  2024-02-09 : 2024-02-23 - BAA-1104048, BAA-1104049 social\n",
    "#  2024-02-25 : 2024-02-28 - BAA-1104048 post solo\n",
    "#  2024-02-28 : 2024-03-02 - BAA-1104049 post solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports and settings.\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %flow mode reactive\n",
    "\n",
    "from colorsys import hls_to_rgb, rgb_to_hls\n",
    "from pathlib import Path\n",
    "\n",
    "import aeon\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "from aeon.schema.schemas import social02\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "# .pkl files written on Windows are incompatible with Unix systems\n",
    "@contextmanager\n",
    "def set_windows_path_as_posix():\n",
    "    windows_backup = pathlib.WindowsPath\n",
    "    try:\n",
    "        pathlib.WindowsPath = pathlib.PosixPath\n",
    "        yield\n",
    "    finally:\n",
    "        pathlib.WindowsPath = windows_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load data.\"\"\"\n",
    "\n",
    "with set_windows_path_as_posix():\n",
    "    root_prefix = \"/ceph/aeon\"  # or \"Z:\"\n",
    "    roots = [\n",
    "        Path(f\"{root_prefix}/aeon/data/raw/AEON3/social0.2\"),\n",
    "        Path(f\"{root_prefix}/aeon/data/raw/AEON4/social0.2\"),\n",
    "    ]\n",
    "\n",
    "    blocks_df_2024_01_31 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-01-31_2024-02-14.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_14 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-14_2024-02-16.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_16 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-16_2024-02-23.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_25 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-25_2024-02-28.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_29 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-29_2024-03-02.pkl\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    skipped_blocks_2024_01_31 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-01-31_2024-02-14.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_14 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-14_2024-02-16.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_16 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-16_2024-02-23.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_25 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-25_2024-02-28.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_29 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-29_2024-03-02.npy\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Clean data.\"\"\"\n",
    "\n",
    "# Concatenate loaded data\n",
    "blocks_df = pd.concat(\n",
    "    [\n",
    "        blocks_df_2024_01_31,\n",
    "        blocks_df_2024_02_14,\n",
    "        blocks_df_2024_02_16,\n",
    "        blocks_df_2024_02_25,\n",
    "        blocks_df_2024_02_29,\n",
    "    ]\n",
    ")\n",
    "skipped_blocks = np.concatenate(\n",
    "    [\n",
    "        skipped_blocks_2024_01_31,\n",
    "        skipped_blocks_2024_02_14,\n",
    "        skipped_blocks_2024_02_16,\n",
    "        skipped_blocks_2024_02_25,\n",
    "        skipped_blocks_2024_02_29,\n",
    "    ]\n",
    ")\n",
    "# Clean indices\n",
    "blocks_df.reset_index(inplace=True, drop=True)\n",
    "# Remove skipped blocks (blocks with few pellets)\n",
    "good_blocks_df = blocks_df[~skipped_blocks].reset_index(drop=True)\n",
    "# Make paths consistent with my ceph network map\n",
    "good_blocks_df[\"root\"] = (\n",
    "    good_blocks_df[\"root\"]\n",
    "    .apply(lambda path: Path(str(path).replace(\"S:\", \"Z:\")))\n",
    "    .apply(lambda path: Path(str(path).replace(\"Z:\\\\\", root_prefix)))\n",
    ")\n",
    "good_blocks_df[\"sleap_model_dir\"] = (\n",
    "    good_blocks_df[\"sleap_model_dir\"]\n",
    "    .apply(lambda path: Path(str(path).replace(\"S:\", \"Z:\")))\n",
    "    .apply(lambda path: Path(str(path).replace(\"Z:\\\\\", root_prefix)))\n",
    ")\n",
    "# Round timestamps to nearest ms\n",
    "good_blocks_df[\"start\"] = good_blocks_df[\"start\"].apply(lambda x: x.round(\"ms\"))\n",
    "good_blocks_df[\"end\"] = good_blocks_df[\"end\"].apply(lambda x: x.round(\"ms\"))\n",
    "good_blocks_df[\"block_duration\"].apply(lambda x: x.round(\"ms\"))\n",
    "# Create df we can iterate through (pandas doesn't like format of \"cum_wheel_dist\" col for some reason)\n",
    "good_blocks_df_cp = good_blocks_df.drop(columns=[\"cum_wheel_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"See percentage of 'good' blocks (> 3 pellets).\"\"\"\n",
    "\n",
    "pct_blocks_foraging = len(good_blocks_df_cp) / len(blocks_df)\n",
    "print(f\"{len(good_blocks_df_cp)=}\\n{len(good_blocks_df)=}\\n{pct_blocks_foraging=:.3f}\")\n",
    "\n",
    "display(good_blocks_df_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"View a particular block.\"\"\"\n",
    "\n",
    "b_i = 250\n",
    "block = good_blocks_df_cp.iloc[b_i]\n",
    "print(block)\n",
    "# Example for getting cum_wheel_dist\n",
    "# good_blocks_df[\"cum_wheel_dist\"].iloc[b_i]  # have to use `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Standardize subject colors, patch colors, and markers.\"\"\"\n",
    "\n",
    "subject_colors = plotly.colors.qualitative.Plotly\n",
    "subject_colors_dict = {\n",
    "    \"BAA-1104045\": subject_colors[0],\n",
    "    \"BAA-1104047\": subject_colors[1],\n",
    "    \"BAA-1104048\": subject_colors[2],\n",
    "    \"BAA-1104049\": subject_colors[3],\n",
    "}\n",
    "patch_colors = plotly.colors.qualitative.Pastel2\n",
    "patch_markers = [\n",
    "    \"circle\",\n",
    "    \"bowtie\",\n",
    "    \"square\",\n",
    "    \"hourglass\",\n",
    "    \"diamond\",\n",
    "    \"cross\",\n",
    "    \"x\",\n",
    "    \"triangle\",\n",
    "    \"star\",\n",
    "]\n",
    "patch_markers_symbols = [\"●\", \"⧓\", \"■\", \"⧗\", \"♦\", \"✖\", \"×\", \"▲\", \"★\"]\n",
    "patch_markers_dict = {\n",
    "    marker: symbol for marker, symbol in zip(patch_markers, patch_markers_symbols)\n",
    "}\n",
    "# patch_markers = {}\n",
    "# for patch, symbol in zip(cum_pel_ct[\"patch\"].unique(), symbols):\n",
    "#     patch_markers[patch] = symbol\n",
    "# patch_markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. x,y animal location, over time, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get pose data.\"\"\"\n",
    "\n",
    "# Change model root path to my network mapped ceph path\n",
    "social02.CameraTop.Pose._model_root = Path(f\"{root_prefix}/aeon/data/processed\")\n",
    "pose_df = aeon.load(block.root, social02.CameraTop.Pose, block.start, block.end)\n",
    "pose_df.resample(\"100ms\").first()\n",
    "pose_df.index = pose_df.index.round(\"100ms\")\n",
    "pose_df = social02.CameraTop.Pose.class_int2str(pose_df, block.sleap_model_dir)\n",
    "# Simplify to centroid only.\n",
    "centroid_df = pose_df[pose_df[\"part\"] == \"centroid\"].drop(\n",
    "    columns=[\"part\", \"part_likelihood\"]\n",
    ")\n",
    "centroid_df[\"x\"], centroid_df[\"y\"] = (\n",
    "    centroid_df[\"x\"].astype(np.int32),\n",
    "    centroid_df[\"y\"].astype(np.int32),\n",
    ")\n",
    "# For each time point and class, keep the row with the highest likelihood\n",
    "centroid_df = centroid_df.iloc[\n",
    "    centroid_df.reset_index().groupby([\"time\", \"class\"])[\"class_likelihood\"].idxmax()\n",
    "]\n",
    "# Compute instantaneous speed\n",
    "centroid_df[\"speed\"] = (\n",
    "    centroid_df.groupby(\"class\")[[\"x\", \"y\"]].diff().apply(np.linalg.norm, axis=1)\n",
    "    / centroid_df.reset_index()\n",
    "    .groupby(\"class\")[\"time\"]\n",
    "    .diff()\n",
    "    .dt.total_seconds()\n",
    "    .values\n",
    ")\n",
    "display(centroid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create function for generating arrays of hex color values from a single initial hex color.\"\"\"\n",
    "\n",
    "\n",
    "def gen_hex_grad(hex_col, vals, min_l=0.3):\n",
    "    \"\"\"Generates an array of hex color values based on a gradient defined by unit-normalized values.\"\"\"\n",
    "    # Convert hex to rgb to hls\n",
    "    h, l, s = rgb_to_hls(\n",
    "        *[int(hex_col.lstrip(\"#\")[i : i + 2], 16) / 255 for i in (0, 2, 4)]\n",
    "    )\n",
    "    grad = np.empty(shape=(len(vals),), dtype=\"<U10\")  # init grad\n",
    "    for i, val in enumerate(vals):\n",
    "        cur_l = (l * val) + (\n",
    "            min_l * (1 - val)\n",
    "        )  # get cur lightness relative to `hex_col`\n",
    "        cur_l = max(min(cur_l, l), min_l)  # set min, max bounds\n",
    "        cur_rgb_col = hls_to_rgb(h, cur_l, s)  # convert to rgb\n",
    "        cur_hex_col = \"#%02x%02x%02x\" % tuple(\n",
    "            int(c * 255) for c in cur_rgb_col\n",
    "        )  # convert to hex\n",
    "        grad[i] = cur_hex_col\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create position over time scatter plot.\"\"\"\n",
    "\n",
    "fig = go.Figure()\n",
    "for id_i, (id_val, id_grp) in enumerate(centroid_df.groupby(\"class\")):\n",
    "    norm_time = (\n",
    "        (id_grp.index - id_grp.index[0]) / (id_grp.index[-1] - id_grp.index[0])\n",
    "    ).values.round(3)\n",
    "    colors = gen_hex_grad(subject_colors[id_i], norm_time)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"x\"],\n",
    "            y=id_grp[\"y\"],\n",
    "            mode=\"markers\",\n",
    "            name=id_val,\n",
    "            marker={\n",
    "                # \"opacity\": norm_time,\n",
    "                \"color\": colors\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "fig.update_layout(\n",
    "    title=\"Position Tracking over Time\",\n",
    "    xaxis_title=\"X Coordinate\",\n",
    "    yaxis_title=\"Y Coordinate\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. x,y animal location heatmap, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(arr, kernel):\n",
    "    \"\"\"Performs \"valid\" 2d convolution using numpy `as_strided` and `einsum`\"\"\"\n",
    "    out_shape = tuple(np.subtract(arr.shape, kernel.shape) + 1)\n",
    "    sub_mat_shape = kernel.shape + out_shape\n",
    "    # Create \"new view\" of `arr` as submatrices at which kernel will be applied\n",
    "    sub_mats = as_strided(arr, shape=sub_mat_shape, strides=(arr.strides * 2))\n",
    "    out = np.einsum(\"ij, ijkl -> kl\", kernel, sub_mats)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create position heatmaps per subject.\"\"\"\n",
    "\n",
    "max_x, max_y = centroid_df[\"x\"].max(), centroid_df[\"y\"].max()\n",
    "for id_i, (id_val, id_grp) in enumerate(centroid_df.groupby(\"class\")):\n",
    "    # <s Add counts of x,y points to a grid that will be used for heatmap\n",
    "    img_grid = np.zeros((max_x + 1, max_y + 1))\n",
    "    points, counts = np.unique(id_grp[[\"x\", \"y\"]].values, return_counts=True, axis=0)\n",
    "    for point, count in zip(points, counts):\n",
    "        img_grid[point[0], point[1]] = count\n",
    "    img_grid /= img_grid.max()  # normalize\n",
    "    # /s>\n",
    "    # <s Smooth `img_grid`\n",
    "    # Mice can go ~450 cm/s, we've downsampled to 10 frames/s, we have 200 px / 1000 cm,\n",
    "    # so 45 cm/frame ~= 9 px/frame\n",
    "    win_sz = 9  # in pixels  (ensure odd for centering)\n",
    "    kernel = np.ones((win_sz, win_sz)) / win_sz**2  # moving avg kernel\n",
    "    img_grid_p = np.pad(\n",
    "        img_grid, win_sz // 2, mode=\"edge\"\n",
    "    )  # pad for full output from convolution\n",
    "    img_grid_smooth = conv2d(img_grid_p, kernel)\n",
    "    # /s>\n",
    "    fig = px.imshow(\n",
    "        img_grid_smooth.T,\n",
    "        zmin=0,\n",
    "        zmax=(img_grid_smooth.max() / 1000),\n",
    "        x=np.arange(img_grid.shape[0]),\n",
    "        y=np.arange(img_grid.shape[1]),\n",
    "        labels=dict(x=\"X\", y=\"Y\", color=\"Norm Freq / 1e3\"),\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    fig.update_layout(title=f\"Position Heatmap ({id_val})\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Patch mean, next to boxplots of each pellet threshold per patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patches = len(block.patch_info)\n",
    "pellet_info = block.pellet_info.sort_values(\"time\").iloc[\n",
    "    :-n_patches\n",
    "]  # drop updates for each patch at new block\n",
    "display(pellet_info)\n",
    "display(block.patch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pellet_info = pd.DataFrame(index=np.arange(n_patches), columns=pellet_info.columns)\n",
    "mean_pellet_info[\"time\"] = block.start\n",
    "mean_pellet_info[\"id\"] = \"mean\"\n",
    "for i, patch in enumerate(block.patch_info.index):\n",
    "    mean_pellet_info.loc[i, \"patch\"] = patch\n",
    "    mean_pellet_info.loc[i, \"threshold\"] = (\n",
    "        block.patch_info.loc[patch, \"mean\"] + block.patch_info.loc[patch, \"offset\"]\n",
    "    )\n",
    "    mean_pellet_info.loc[i, \"patch\"] = patch\n",
    "pellet_info_plus = pd.concat((mean_pellet_info, pellet_info)).reset_index(drop=True)\n",
    "pellet_info_plus[\"norm_time\"] = (\n",
    "    (pellet_info_plus[\"time\"] - pellet_info_plus[\"time\"].iloc[0])\n",
    "    / (pellet_info_plus[\"time\"].iloc[-1] - pellet_info_plus[\"time\"].iloc[0])\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pellet_info_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_colors = [\"#0A0A0A\"] + subject_colors[\n",
    "    0 : len(block.subjects)\n",
    "]  # subject colors + mean color\n",
    "\n",
    "fig = px.box(\n",
    "    pellet_info_plus.sort_values(\"patch\"),\n",
    "    x=\"patch\",\n",
    "    y=\"threshold\",\n",
    "    color=\"id\",\n",
    "    hover_data=[\"norm_time\"],\n",
    "    color_discrete_sequence=box_colors,\n",
    "    # notched=True,\n",
    "    points=\"all\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Patch Stats\", xaxis_title=\"Patch\", yaxis_title=\"Threshold (cm)\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Cumulative pellet count over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_helper(group):\n",
    "    group[\"counter\"] = np.arange(len(group)) + 1\n",
    "    return group\n",
    "\n",
    "\n",
    "cum_pel_ct = (\n",
    "    pellet_info.groupby(\"id\", group_keys=False)\n",
    "    .apply(cumsum_helper)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "cum_pel_ct = cum_pel_ct.merge(\n",
    "    mean_pellet_info[[\"patch\", \"threshold\"]].rename(\n",
    "        columns={\"threshold\": \"mean_thresh\"}\n",
    "    ),\n",
    "    on=\"patch\",\n",
    "    how=\"left\",\n",
    ")\n",
    "cum_pel_ct[\"patch_label\"] = cum_pel_ct.apply(\n",
    "    lambda row: f\"{row['patch']} μ: {row['mean_thresh']}\", axis=1\n",
    ")\n",
    "display(cum_pel_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_pel_ct[\"norm_thresh_val\"] = (\n",
    "    (cum_pel_ct[\"threshold\"] - cum_pel_ct[\"threshold\"].min())\n",
    "    / (cum_pel_ct[\"threshold\"].max() - cum_pel_ct[\"threshold\"].min())\n",
    ").round(3)\n",
    "\n",
    "fig = go.Figure()\n",
    "for id_val, id_grp in cum_pel_ct.groupby(\"id\"):\n",
    "    # Add lines by subject\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"time\"],\n",
    "            y=id_grp[\"counter\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=2),\n",
    "            name=id_val,\n",
    "        )\n",
    "    )\n",
    "for patch_i, (patch_val, patch_grp) in enumerate(cum_pel_ct.groupby(\"patch_label\")):\n",
    "    # Add markers by patch\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=patch_grp[\"time\"],\n",
    "            y=patch_grp[\"counter\"],\n",
    "            mode=\"markers\",\n",
    "            marker={\n",
    "                \"symbol\": patch_markers[patch_i],\n",
    "                \"color\": gen_hex_grad(subject_colors[-1], patch_grp[\"norm_thresh_val\"]),\n",
    "                \"size\": 8,\n",
    "            },\n",
    "            name=patch_val,\n",
    "            customdata=np.stack((patch_grp[\"threshold\"],), axis=-1),\n",
    "            hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Pellet Count\", xaxis_title=\"Time\", yaxis_title=\"Count\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Pellet delivery over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for id_i, (id_val, id_grp) in enumerate(cum_pel_ct.groupby(\"id\")):\n",
    "    # Add lines by subject\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"time\"],\n",
    "            y=id_grp[\"patch_label\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(width=2),\n",
    "            marker={\n",
    "                \"symbol\": patch_markers[id_i],\n",
    "                \"color\": gen_hex_grad(subject_colors[id_i], id_grp[\"norm_thresh_val\"]),\n",
    "                \"size\": 8,\n",
    "            },\n",
    "            name=id_val,\n",
    "            customdata=np.stack((id_grp[\"threshold\"],), axis=-1),\n",
    "            hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pellet Delivery Over Time\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Patch\",\n",
    "    yaxis={\n",
    "        \"categoryorder\": \"array\",\n",
    "        \"categoryarray\": cum_pel_ct.sort_values(\"mean_thresh\")[\n",
    "            \"patch_label\"\n",
    "        ].unique(),  # sort y-axis by patch threshold mean\n",
    "    },\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pellet threshold vals over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for id_val, id_grp in cum_pel_ct.groupby(\"id\"):\n",
    "    # Add lines by subject\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"time\"],\n",
    "            y=id_grp[\"threshold\"],\n",
    "            mode=\"lines\",\n",
    "            name=id_val,\n",
    "        )\n",
    "    )\n",
    "for patch_i, (patch_val, patch_grp) in enumerate(cum_pel_ct.groupby(\"patch_label\")):\n",
    "    # Add markers by patch\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=patch_grp[\"time\"],\n",
    "            y=patch_grp[\"threshold\"],\n",
    "            mode=\"markers\",\n",
    "            marker={\n",
    "                \"symbol\": patch_markers[patch_i],\n",
    "                \"color\": \"black\",\n",
    "            },\n",
    "            name=patch_val,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pellet Thresholds\", xaxis_title=\"Time\", yaxis_title=\"Threshold (cm)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cumulative wheel distance over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_wheel_dist = good_blocks_df[\"cum_wheel_dist\"].iloc[b_i]\n",
    "patches = block.patch_info.index\n",
    "\n",
    "fig = go.Figure()\n",
    "for subj_i, subj in enumerate(block.subjects):\n",
    "    for patch_i, p in enumerate(patches):\n",
    "        cur_cum_wheel_dist = cum_wheel_dist[p][subj]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cur_cum_wheel_dist.index,\n",
    "                y=cur_cum_wheel_dist,\n",
    "                mode=\"lines\",  # +  markers\",\n",
    "                line={\"width\": 2, \"color\": subject_colors[subj_i]},\n",
    "                name=f\"{p} {subj}\",\n",
    "                legendgroup=subj,\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "        # Add markers for each pellet\n",
    "        cur_cum_pel_ct = pd.merge_asof(\n",
    "            cum_pel_ct[(cum_pel_ct[\"id\"] == subj) & (cum_pel_ct[\"patch\"] == p)],\n",
    "            cur_cum_wheel_dist.reset_index(name=\"cum_wheel_dist\"),\n",
    "            on=\"time\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=pd.Timedelta(\"0.1s\"),\n",
    "        )\n",
    "        if not cur_cum_pel_ct.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cur_cum_pel_ct[\"time\"],\n",
    "                    y=cur_cum_pel_ct[\"cum_wheel_dist\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker={\n",
    "                        \"symbol\": patch_markers[patch_i],\n",
    "                        \"color\": subject_colors[subj_i],\n",
    "                        \"size\": 7,\n",
    "                    },\n",
    "                    name=cur_cum_pel_ct[\"patch_label\"].iloc[0],\n",
    "                    legendgroup=subj,\n",
    "                    legendgrouptitle_text=subj,\n",
    "                    customdata=np.stack((cur_cum_pel_ct[\"threshold\"],), axis=-1),\n",
    "                    hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "                )\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Wheel Distance\", xaxis_title=\"Time\", yaxis_title=\"Distance (cm)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Plots (per experiment and room)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Threshold vals per block per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only blocks with more than 15 pellets\n",
    "\n",
    "pel_thresh = 15\n",
    "foraging_blocks = good_blocks_df_cp[\n",
    "    good_blocks_df_cp[\"pellet_info\"].apply(len) > pel_thresh\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column \"block_type\" with values [\"presocial\", \"social\", \"postsocial\"]\n",
    "\n",
    "mask_social = foraging_blocks[\"subjects\"].apply(len) > 1\n",
    "subj_str = foraging_blocks[\"subjects\"].apply(str)\n",
    "presocial_condition = foraging_blocks[mask_social].groupby(subj_str)[\n",
    "    \"start\"].min()\n",
    "postsocial_condition = foraging_blocks[mask_social].groupby(subj_str)[\n",
    "    \"end\"].max()\n",
    "\n",
    "\n",
    "def assign_block_type(row):\n",
    "    if len(row[\"subjects\"]) > 1:\n",
    "        return \"social\"\n",
    "    else:\n",
    "        subj = row[\"subjects\"][0]\n",
    "        idx = next(\n",
    "            iter([idx for idx in presocial_condition.index if subj in idx]), None\n",
    "        )\n",
    "        if idx is not None:\n",
    "            if row[\"start\"] < presocial_condition[idx]:\n",
    "                return \"presocial\"\n",
    "            elif row[\"start\"] > postsocial_condition[idx]:\n",
    "                return \"postsocial\"\n",
    "\n",
    "\n",
    "foraging_blocks[\"block_type\"] = foraging_blocks.apply(\n",
    "    assign_block_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold vals obtained from halfway thru block (lower better, obvs)\n",
    "\n",
    "fig = go.Figure()\n",
    "legend_added = set()  # legend only for unique subjs\n",
    "learning_threshold_vals = pd.DataFrame(columns=[\"threshold_vals\", \"id\"])\n",
    "block_type_markers = {\n",
    "    \"presocial\": patch_markers[0],\n",
    "    \"social\": patch_markers[1],\n",
    "    \"postsocial\": patch_markers[2],\n",
    "}\n",
    "for block_i, block in enumerate(foraging_blocks.itertuples()):\n",
    "    n_pellets = len(block.pellet_info)\n",
    "    pellet_info = block.pellet_info.sort_values(\"time\")\n",
    "    pellet_info_post = pellet_info.iloc[\n",
    "        (n_pellets // 2):\n",
    "    ]  # halfway point (in terms of pellets obtained)\n",
    "    # Get threshold vals, per subject.\n",
    "    for subj_val, subj_grp in pellet_info_post.groupby(\"id\"):\n",
    "        # Add threshold_vals, id as row to `learning_threshold_vals`.\n",
    "        new_row = pd.DataFrame(\n",
    "            columns=[\"threshold_vals\", \"id\"], index=[block.Index])\n",
    "        new_row[\"threshold_vals\"], new_row[\"id\"] = (\n",
    "            [subj_grp[\"threshold\"].values],\n",
    "            subj_val,\n",
    "        )\n",
    "        learning_threshold_vals = pd.concat((learning_threshold_vals, new_row))\n",
    "        # subj_val\n",
    "        grouping_factor = f\"{patch_markers_dict.get(block_type_markers[block.block_type])} {subj_val} {block.block_type}\"\n",
    "        show_in_legend = grouping_factor not in legend_added\n",
    "        # If not, add it and set the flag to False for subsequent rows with the same ID\n",
    "        if show_in_legend:\n",
    "            legend_added.add(grouping_factor)\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=new_row.loc[block.Index, \"threshold_vals\"],\n",
    "                x=[block.Index] *\n",
    "                len(new_row.loc[block.Index, \"threshold_vals\"]),\n",
    "                name=grouping_factor,\n",
    "                legendgroup=grouping_factor,\n",
    "                boxpoints=\"all\",\n",
    "                # jitter=0.5,\n",
    "                marker={\n",
    "                    \"color\": subject_colors_dict[subj_val],\n",
    "                    \"symbol\": block_type_markers[block.block_type],\n",
    "                },\n",
    "                showlegend=show_in_legend,  # legend only for unique subjs\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pellet Thresholds\",\n",
    "    xaxis_title=\"Block Index\",\n",
    "    yaxis_title=\"Threshold (cm)\",\n",
    ")\n",
    "fig.update_layout(legend_tracegroupgap=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Patch preference per block per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch preference by wheel dist spun from halfway through block\n",
    "\n",
    "pp_overall = pd.DataFrame(\n",
    "    columns=[\"one_best_patch\", \"two_best_patches\", \"id\", \"block_type\"]\n",
    ")  # e.g. easy vs. (medium + hard); (easy + medium) vs. hard\n",
    "\n",
    "for block_i, block in enumerate(foraging_blocks.itertuples()):\n",
    "    easy_p, med_p, hard_p = block.patch_info.sort_values(\"mean\").index\n",
    "    n_pellets = len(block.pellet_info)\n",
    "    pellet_info = block.pellet_info.sort_values(\"time\")\n",
    "    halfway_ts = pellet_info[\"time\"].iloc[n_pellets // 2]\n",
    "    cum_wheel_dist = good_blocks_df[\"cum_wheel_dist\"].loc[block.Index]\n",
    "    for subj in block.subjects:\n",
    "        easy_dist = cum_wheel_dist[easy_p][subj]\n",
    "        easy_dist = (\n",
    "            easy_dist[easy_dist.index > halfway_ts].iloc[-1]\n",
    "            - easy_dist[easy_dist.index > halfway_ts].iloc[0]\n",
    "        )\n",
    "        easy_dist = 1 if easy_dist < 0 else easy_dist\n",
    "        med_dist = cum_wheel_dist[med_p][subj]\n",
    "        med_dist = (\n",
    "            med_dist[med_dist.index > halfway_ts].iloc[-1]\n",
    "            - med_dist[med_dist.index > halfway_ts].iloc[0]\n",
    "        )\n",
    "        med_dist = 1 if med_dist < 0 else med_dist\n",
    "        hard_dist = cum_wheel_dist[hard_p][subj]\n",
    "        hard_dist = (\n",
    "            hard_dist[hard_dist.index > halfway_ts].iloc[-1]\n",
    "            - hard_dist[hard_dist.index > halfway_ts].iloc[0]\n",
    "        )\n",
    "        hard_dist = 1 if hard_dist < 0 else hard_dist\n",
    "        new_row = pd.DataFrame(\n",
    "            columns=[\"one_best_patch\", \"two_best_patches\"], index=[block.Index]\n",
    "        )\n",
    "        new_row[\"one_best_patch\"] = np.round(\n",
    "            (easy_dist / (easy_dist + med_dist + hard_dist)), 3\n",
    "        )\n",
    "        new_row[\"two_best_patches\"] = np.round(\n",
    "            ((easy_dist + med_dist) / (easy_dist + med_dist + hard_dist)), 3\n",
    "        )\n",
    "        new_row[\"id\"] = subj\n",
    "        new_row[\"block_type\"] = block.block_type\n",
    "        pp_overall = pd.concat((pp_overall, new_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for block_type in block_type_markers.keys():\n",
    "    for id, group in pp_overall[pp_overall[\"block_type\"] == block_type].groupby(\"id\"):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=group.index,\n",
    "                y=group[\"one_best_patch\"],\n",
    "                mode=\"markers\",\n",
    "                name=block_type,\n",
    "                legendgroup=id,\n",
    "                legendgrouptitle_text=id,\n",
    "                marker={\"color\": subject_colors_dict[id]},\n",
    "                marker_symbol=block_type_markers[block_type],\n",
    "            )\n",
    "        )\n",
    "fig.update_layout(\n",
    "    title=\"Patch Preference: Easy Only\",\n",
    "    xaxis_title=\"Block Index\",\n",
    "    yaxis_title=\"Preference\",\n",
    "    legend_tracegroupgap=0,\n",
    ")\n",
    "fig.update_traces(\n",
    "    legendgrouptitle_font_size=12,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pp_overall,\n",
    "    x=pp_overall.index,\n",
    "    y=[\"one_best_patch\"],\n",
    "    color=\"id\",\n",
    "    symbol=\"block_type\",\n",
    "    title=\"Patch Preference: Easy Only\",\n",
    "    labels={\"index\": \"Block Index\", \"value\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"\")\n",
    "fig.for_each_trace(lambda trace: setattr(trace, \"name\", trace.name.replace(\",\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pp_overall,\n",
    "    x=pp_overall.index,\n",
    "    y=[\"two_best_patches\"],\n",
    "    color=\"id\",\n",
    "    symbol=\"block_type\",\n",
    "    title=\"Patch Preference: Easy + Medium\",\n",
    "    labels={\"index\": \"Block Index\", \"value\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"\")\n",
    "fig.for_each_trace(lambda trace: setattr(trace, \"name\", trace.name.replace(\",\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Patch Preference by Block Type (presocial, social, postsocial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    pp_overall,\n",
    "    x=\"block_type\",\n",
    "    y=\"one_best_patch\",\n",
    "    color=\"id\",\n",
    "    points=\"all\",\n",
    "    title=\"Patch Preference: Easy Only by Block Type\",\n",
    "    labels={\"block_type\": \"Block Type\", \"one_best_patch\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"ID\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    pp_overall,\n",
    "    x=\"block_type\",\n",
    "    y=\"two_best_patches\",\n",
    "    color=\"id\",\n",
    "    points=\"all\",\n",
    "    title=\"Patch Preference: Easy + Medium by Block Type\",\n",
    "    labels={\"block_type\": \"Block Type\", \"two_best_patches\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"ID\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Patch Preference Difference between First- and Second-Half of Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Cumulative Wheel Distance by Patch Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Cumulative Wheel Distance by Patch ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Social Distancing =p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get position for each individual animal for first day of solo\n",
    "# Sample 100k points from each of these\n",
    "# Create \"synthetic\" distribution of euclidean distances away from each other\n",
    "\n",
    "baa45_solo_pos = aeon.load(\n",
    "    roots[0],\n",
    "    social02.CameraTop.Pose,\n",
    "    pd.Timestamp(\"2024-02-01 00:00:00\"),\n",
    "    pd.Timestamp(\"2024-02-02 00:00:00\"),\n",
    ")\n",
    "baa47_solo_pos = aeon.load(\n",
    "    roots[0],\n",
    "    social02.CameraTop.Pose,\n",
    "    pd.Timestamp(\"2024-02-06 00:00:00\"),\n",
    "    pd.Timestamp(\"2024-02-07 00:00:00\"),\n",
    ")\n",
    "\n",
    "baa48_solo_pos = aeon.load(\n",
    "    roots[1],\n",
    "    social02.CameraTop.Pose,\n",
    "    pd.Timestamp(\"2024-02-01 00:00:00\"),\n",
    "    pd.Timestamp(\"2024-02-02 00:00:00\"),\n",
    ")\n",
    "baa49_solo_pos = aeon.load(\n",
    "    roots[1],\n",
    "    social02.CameraTop.Pose,\n",
    "    pd.Timestamp(\"2024-02-06 00:00:00\"),\n",
    "    pd.Timestamp(\"2024-02-07 00:00:00\"),\n",
    ")\n",
    "\n",
    "baa45_47_joint_pos = aeon.load(\n",
    "    roots[0],\n",
    "    social02.CameraTop.Pose,\n",
    "    pd.Timestamp(\"2024-02-15 00:00:00\"),\n",
    "    pd.Timestamp(\"2024-02-16 00:00:00\"),\n",
    ")\n",
    "baa48_49_joint_pos = aeon.load(\n",
    "    roots[1],\n",
    "    social02.CameraTop.Pose,\n",
    "    pd.Timestamp(\"2024-02-15 00:00:00\"),\n",
    "    pd.Timestamp(\"2024-02-16 00:00:00\"),\n",
    ")\n",
    "\n",
    "baa45_from_joint = baa45_47_joint_pos[baa45_47_joint_pos[\"class\"] == 0.0].sample(100000)\n",
    "baa47_from_joint = baa45_47_joint_pos[baa45_47_joint_pos[\"class\"] == 1.0].sample(100000)\n",
    "distances2_45_47 = np.sqrt(\n",
    "    ((baa45_from_joint[\"x\"].values - baa47_from_joint[\"x\"].values) ** 2)\n",
    "    + ((baa45_from_joint[\"y\"].values - baa47_from_joint[\"y\"].values) ** 2)\n",
    ")\n",
    "\n",
    "baa48_from_joint = baa48_49_joint_pos[baa48_49_joint_pos[\"class\"] == 0.0].sample(100000)\n",
    "baa49_from_joint = baa48_49_joint_pos[baa48_49_joint_pos[\"class\"] == 1.0].sample(100000)\n",
    "distances2_48_49 = np.sqrt(\n",
    "    ((baa48_from_joint[\"x\"].values - baa49_from_joint[\"x\"].values) ** 2)\n",
    "    + ((baa48_from_joint[\"y\"].values - baa49_from_joint[\"y\"].values) ** 2)\n",
    ")\n",
    "\n",
    "sampled_df1 = baa48_solo_pos.sample(n=100000, random_state=1)\n",
    "sampled_df2 = baa49_solo_pos.sample(n=100000, random_state=1)\n",
    "distances0_48_49 = np.sqrt(\n",
    "    ((sampled_df1[\"x\"].values - sampled_df2[\"x\"].values) ** 2)\n",
    "    + ((sampled_df1[\"y\"].values - sampled_df2[\"y\"].values) ** 2)\n",
    ")\n",
    "\n",
    "sampled_df1 = baa45_solo_pos.sample(n=100000, random_state=1)\n",
    "sampled_df2 = baa47_solo_pos.sample(n=100000, random_state=1)\n",
    "distances0_45_47 = np.sqrt(\n",
    "    ((sampled_df1[\"x\"].values - sampled_df2[\"x\"].values) ** 2)\n",
    "    + ((sampled_df1[\"y\"].values - sampled_df2[\"y\"].values) ** 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(distances0_45_47, kde=True, bins=1000, ax=ax)\n",
    "sns.histplot(distances2_45_47, kde=True, bins=1000, ax=ax)\n",
    "ax.set_title(\"Distances between subjects 45-47\")\n",
    "ax.set_xlabel(\"Distance (px)\")\n",
    "ax.legend([\"Synthetic\", \"True\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(distances0_48_49, kde=True, bins=1000, ax=ax)\n",
    "sns.histplot(distances2_48_49, kde=True, bins=1000, ax=ax)\n",
    "ax.set_title(\"Distances between subjects 48-49\")\n",
    "ax.set_xlabel(\"Distance (px)\")\n",
    "ax.legend([\"Synthetic\", \"True\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

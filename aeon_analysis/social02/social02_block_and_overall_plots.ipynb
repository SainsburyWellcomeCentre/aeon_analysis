{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social exp timeline\n",
    "\n",
    "# Aeon3\n",
    "#  2024-01-31 : 2024-02-03 - BAA-1104045 pre solo\n",
    "#  2024-02-05 : 2024-02-08 - BAA-1104047 pre solo (dominant)\n",
    "#  2024-02-09 : 2024-02-23 - BAA-1104045, BAA-1104047 social\n",
    "#  2024-02-25 : 2024-02-28 - BAA-1104045 post solo\n",
    "#  2024-02-28 : 2024-03-02 - BAA-1104047 post solo\n",
    "\n",
    "# Aeon4\n",
    "#  2024-01-31 : 2024-02-03 - BAA-1104048 pre solo (dominant)\n",
    "#  2024-02-05 : 2024-02-08 - BAA-1104049 pre solo\n",
    "#  2024-02-09 : 2024-02-23 - BAA-1104048, BAA-1104049 social\n",
    "#  2024-02-25 : 2024-02-28 - BAA-1104048 post solo\n",
    "#  2024-02-28 : 2024-03-02 - BAA-1104049 post solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports and settings.\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %flow mode reactive\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from colorsys import hls_to_rgb, rgb_to_hls\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "import aeon\n",
    "import datajoint as dj\n",
    "from aeon.schema.schemas import social02\n",
    "from aeon.dj_pipeline.analysis.block_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load data.\"\"\"\n",
    "\n",
    "# Allow reading (on Unix-like OS) of .pkl files written on Windows\n",
    "@contextmanager\n",
    "def set_windows_path_as_posix():\n",
    "    windows_backup = pathlib.WindowsPath\n",
    "    try:\n",
    "        pathlib.WindowsPath = pathlib.PosixPath\n",
    "        yield\n",
    "    finally:\n",
    "        pathlib.WindowsPath = windows_backup\n",
    "\n",
    "def load_data():\n",
    "    global \\\n",
    "        roots, \\\n",
    "        blocks_df_2024_01_31, \\\n",
    "        blocks_df_2024_02_14, \\\n",
    "        blocks_df_2024_02_16, \\\n",
    "        blocks_df_2024_02_25, \\\n",
    "        blocks_df_2024_02_29\n",
    "    global \\\n",
    "        skipped_blocks_2024_01_31, \\\n",
    "        skipped_blocks_2024_02_14, \\\n",
    "        skipped_blocks_2024_02_16, \\\n",
    "        skipped_blocks_2024_02_25, \\\n",
    "        skipped_blocks_2024_02_29\n",
    "    roots = [\n",
    "        Path(f\"{root_prefix}/aeon/data/raw/AEON3/social0.2\"),\n",
    "        Path(f\"{root_prefix}/aeon/data/raw/AEON4/social0.2\"),\n",
    "    ]\n",
    "\n",
    "    blocks_df_2024_01_31 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-01-31_2024-02-14.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_14 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-14_2024-02-16.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_16 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-16_2024-02-23.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_25 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-25_2024-02-28.pkl\"\n",
    "        )\n",
    "    )\n",
    "    blocks_df_2024_02_29 = pd.read_pickle(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/social02_2024-02-29_2024-03-02.pkl\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    skipped_blocks_2024_01_31 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-01-31_2024-02-14.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_14 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-14_2024-02-16.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_16 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-16_2024-02-23.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_25 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-25_2024-02-28.npy\"\n",
    "        )\n",
    "    )\n",
    "    skipped_blocks_2024_02_29 = np.load(\n",
    "        Path(\n",
    "            f\"{root_prefix}/aeon/code/scratchpad/jai/social02/skipped_blocks_2024-02-29_2024-03-02.npy\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "root_prefix = \"Z:\" if os.name == \"nt\" else \"/ceph/aeon\"\n",
    "if root_prefix == \"/ceph/aeon\":\n",
    "    with set_windows_path_as_posix():\n",
    "        load_data()\n",
    "else:\n",
    "    load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Clean data.\"\"\"\n",
    "\n",
    "# Concatenate loaded data\n",
    "blocks_df = pd.concat(\n",
    "    [\n",
    "        blocks_df_2024_01_31,\n",
    "        blocks_df_2024_02_14,\n",
    "        blocks_df_2024_02_16,\n",
    "        blocks_df_2024_02_25,\n",
    "        blocks_df_2024_02_29,\n",
    "    ]\n",
    ")\n",
    "skipped_blocks = np.concatenate(\n",
    "    [\n",
    "        skipped_blocks_2024_01_31,\n",
    "        skipped_blocks_2024_02_14,\n",
    "        skipped_blocks_2024_02_16,\n",
    "        skipped_blocks_2024_02_25,\n",
    "        skipped_blocks_2024_02_29,\n",
    "    ]\n",
    ")\n",
    "# Clean indices\n",
    "blocks_df.reset_index(inplace=True, drop=True)\n",
    "# Remove skipped blocks (blocks with few pellets)\n",
    "good_blocks_df = blocks_df[~skipped_blocks].reset_index(drop=True)\n",
    "# Make paths consistent with my ceph network map\n",
    "good_blocks_df[\"root\"] = (\n",
    "    good_blocks_df[\"root\"]\n",
    "    .apply(lambda path: Path(str(path).replace(\"S:\", \"Z:\")))\n",
    "    .apply(lambda path: Path(str(path).replace(\"Z:\\\\\", root_prefix)))\n",
    ")\n",
    "good_blocks_df[\"sleap_model_dir\"] = (\n",
    "    good_blocks_df[\"sleap_model_dir\"]\n",
    "    .apply(lambda path: Path(str(path).replace(\"S:\", \"Z:\")))\n",
    "    .apply(lambda path: Path(str(path).replace(\"Z:\\\\\", root_prefix)))\n",
    ")\n",
    "# Round timestamps to nearest ms\n",
    "good_blocks_df[\"start\"] = good_blocks_df[\"start\"].apply(\n",
    "    lambda x: x.round(\"ms\"))\n",
    "good_blocks_df[\"end\"] = good_blocks_df[\"end\"].apply(lambda x: x.round(\"ms\"))\n",
    "good_blocks_df[\"block_duration\"].apply(lambda x: x.round(\"ms\"))\n",
    "# Create df we can iterate through (pandas doesn't like format of \"cum_wheel_dist\" col for some reason)\n",
    "good_blocks_df_cp = good_blocks_df.drop(columns=[\"cum_wheel_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"See percentage of 'good' blocks (> 3 pellets).\"\"\"\n",
    "\n",
    "pct_blocks_foraging = len(good_blocks_df_cp) / len(blocks_df)\n",
    "print(f\"{len(good_blocks_df_cp)=}\\n{len(good_blocks_df)=}\\n{pct_blocks_foraging=:.3f}\")\n",
    "display(good_blocks_df_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"View a particular block.\"\"\"\n",
    "\n",
    "b_i = 125\n",
    "block = good_blocks_df_cp.iloc[b_i]\n",
    "print(block)\n",
    "# Example for getting cum_wheel_dist\n",
    "# good_blocks_df[\"cum_wheel_dist\"].iloc[b_i]  # have to use `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Standardize subject colors, patch colors, and markers.\"\"\"\n",
    "\n",
    "subject_colors = plotly.colors.qualitative.Plotly\n",
    "subject_colors_dict = {\n",
    "    \"BAA-1104045\": subject_colors[0],\n",
    "    \"BAA-1104047\": subject_colors[1],\n",
    "    \"BAA-1104048\": subject_colors[2],\n",
    "    \"BAA-1104049\": subject_colors[3],\n",
    "}\n",
    "patch_colors = plotly.colors.qualitative.Dark2\n",
    "patch_markers = [\n",
    "    \"circle\",\n",
    "    \"bowtie\",\n",
    "    \"square\",\n",
    "    \"hourglass\",\n",
    "    \"diamond\",\n",
    "    \"cross\",\n",
    "    \"x\",\n",
    "    \"triangle\",\n",
    "    \"star\",\n",
    "]\n",
    "patch_markers_symbols = [\"●\", \"⧓\", \"■\", \"⧗\", \"♦\", \"✖\", \"×\", \"▲\", \"★\"]\n",
    "patch_markers_dict = {\n",
    "    marker: symbol for marker, symbol in zip(patch_markers, patch_markers_symbols)\n",
    "}\n",
    "patch_markers_linestyles = [\"solid\", \"dash\", \"dot\", \"dashdot\", \"longdashdot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Patch stats: mean, next to boxplots of each pellet threshold per patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patches = len(block.patch_info)\n",
    "pellet_info = block.pellet_info.sort_values(\"time\").iloc[\n",
    "    :-n_patches\n",
    "]  # drop updates for each patch at new block\n",
    "display(pellet_info)\n",
    "display(block.patch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pellet_info = pd.DataFrame(index=np.arange(\n",
    "    n_patches), columns=pellet_info.columns)\n",
    "mean_pellet_info[\"time\"] = block.start\n",
    "mean_pellet_info[\"id\"] = \"mean\"\n",
    "for i, patch in enumerate(block.patch_info.index):\n",
    "    mean_pellet_info.loc[i, \"patch\"] = patch\n",
    "    mean_pellet_info.loc[i, \"threshold\"] = (\n",
    "        block.patch_info.loc[patch, \"mean\"] +\n",
    "        block.patch_info.loc[patch, \"offset\"]\n",
    "    )\n",
    "    mean_pellet_info.loc[i, \"patch\"] = patch\n",
    "pellet_info_plus = pd.concat(\n",
    "    (mean_pellet_info, pellet_info)).reset_index(drop=True)\n",
    "pellet_info_plus[\"norm_time\"] = (\n",
    "    (pellet_info_plus[\"time\"] - pellet_info_plus[\"time\"].iloc[0])\n",
    "    / (pellet_info_plus[\"time\"].iloc[-1] - pellet_info_plus[\"time\"].iloc[0])\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pellet_info_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_colors = [\"#0A0A0A\"] + subject_colors[\n",
    "    0: len(block.subjects)\n",
    "]  # subject colors + mean color\n",
    "\n",
    "fig = px.box(\n",
    "    pellet_info_plus.sort_values(\"patch\"),\n",
    "    x=\"patch\",\n",
    "    y=\"threshold\",\n",
    "    color=\"id\",\n",
    "    hover_data=[\"norm_time\"],\n",
    "    color_discrete_sequence=box_colors,\n",
    "    # notched=True,\n",
    "    points=\"all\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Patch Stats: Patch Means and Sampled Threshold Values\", \n",
    "    xaxis_title=\"Patch\", \n",
    "    yaxis_title=\"Threshold (cm)\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Animal weight: over time, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = aeon.load(block.root, social02.Environment.SubjectWeight, block.start, block.end)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    weights,\n",
    "    x=weights.index,\n",
    "    y=\"weight\",\n",
    "    color=\"subject_id\",\n",
    "    color_discrete_map=subject_colors_dict,\n",
    "    markers=True\n",
    ")\n",
    "\n",
    "fig.update_traces(line=dict(width=3), marker=dict(size=8))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Weights\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Weight (g)\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Animal position: (x, y) over time, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get pose data.\"\"\"\n",
    "\n",
    "# Change model root path to my network mapped ceph path\n",
    "social02.CameraTop.Pose._model_root = Path(\n",
    "    f\"{root_prefix}/aeon/data/processed\")\n",
    "pose_df = aeon.load(block.root, social02.CameraTop.Pose, block.start, block.end)\n",
    "pose_df = pose_df.groupby(\"class\").resample(\"100ms\").first().droplevel(\"class\")\n",
    "pose_df.index = pose_df.index.round(\"100ms\")\n",
    "pose_df = social02.CameraTop.Pose.class_int2str(pose_df, block.sleap_model_dir)\n",
    "# Simplify to centroid only.\n",
    "centroid_df = pose_df[pose_df[\"part\"] == \"centroid\"].drop(columns=[\"part\", \"part_likelihood\"])\n",
    "# centroid_df[\"x\"], centroid_df[\"y\"] = (\n",
    "#     centroid_df[\"x\"].astype(np.int32),\n",
    "#     centroid_df[\"y\"].astype(np.int32),\n",
    "# )\n",
    "centroid_df[\"class\"] = centroid_df[\"class\"].astype(\"string\")\n",
    "centroid_df.sort_index(inplace=True)\n",
    "display(centroid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create function for generating arrays of hex color values from a single initial hex color.\"\"\"\n",
    "\n",
    "\n",
    "def gen_hex_grad(hex_col, vals, min_l=0.3):\n",
    "    \"\"\"Generates an array of hex color values based on a gradient defined by unit-normalized values.\"\"\"\n",
    "    # Convert hex to rgb to hls\n",
    "    h, l, s = rgb_to_hls(\n",
    "        *[int(hex_col.lstrip(\"#\")[i: i + 2], 16) / 255 for i in (0, 2, 4)]\n",
    "    )\n",
    "    grad = np.empty(shape=(len(vals),), dtype=\"<U10\")  # init grad\n",
    "    for i, val in enumerate(vals):\n",
    "        cur_l = (l * val) + (\n",
    "            min_l * (1 - val)\n",
    "        )  # get cur lightness relative to `hex_col`\n",
    "        cur_l = max(min(cur_l, l), min_l)  # set min, max bounds\n",
    "        cur_rgb_col = hls_to_rgb(h, cur_l, s)  # convert to rgb\n",
    "        cur_hex_col = \"#%02x%02x%02x\" % tuple(\n",
    "            int(c * 255) for c in cur_rgb_col\n",
    "        )  # convert to hex\n",
    "        grad[i] = cur_hex_col\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create position over time scatter plot.\"\"\"\n",
    "\n",
    "fig = go.Figure()\n",
    "for id_i, (id_val, id_grp) in enumerate(centroid_df.groupby(\"class\")):\n",
    "    norm_time = (\n",
    "        (id_grp.index - id_grp.index[0]) / (id_grp.index[-1] - id_grp.index[0])\n",
    "    ).values.round(3)\n",
    "    colors = gen_hex_grad(subject_colors[id_i], norm_time)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"x\"],\n",
    "            y=id_grp[\"y\"],\n",
    "            mode=\"markers\",\n",
    "            name=id_val,\n",
    "            marker={\n",
    "                # \"opacity\": norm_time,\n",
    "                \"color\": colors,\n",
    "                \"size\": 4,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "fig.update_layout(\n",
    "    title=\"Position Tracking over Time\",\n",
    "    xaxis_title=\"X Coordinate\",\n",
    "    yaxis_title=\"Y Coordinate\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Animal position: (x, y) heatmap, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(arr, kernel):\n",
    "    \"\"\"Performs \"valid\" 2d convolution using numpy `as_strided` and `einsum`\"\"\"\n",
    "    out_shape = tuple(np.subtract(arr.shape, kernel.shape) + 1)\n",
    "    sub_mat_shape = kernel.shape + out_shape\n",
    "    # Create \"new view\" of `arr` as submatrices at which kernel will be applied\n",
    "    sub_mats = as_strided(arr, shape=sub_mat_shape, strides=(arr.strides * 2))\n",
    "    out = np.einsum(\"ij, ijkl -> kl\", kernel, sub_mats)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create position heatmaps per subject.\"\"\"\n",
    "\n",
    "max_x, max_y = centroid_df[\"x\"].max(), centroid_df[\"y\"].max()\n",
    "for id_i, (id_val, id_grp) in enumerate(centroid_df.groupby(\"class\")):\n",
    "    # <s Add counts of x,y points to a grid that will be used for heatmap\n",
    "    img_grid = np.zeros((max_x + 1, max_y + 1))\n",
    "    points, counts = np.unique(\n",
    "        id_grp[[\"x\", \"y\"]].values, return_counts=True, axis=0)\n",
    "    for point, count in zip(points, counts):\n",
    "        img_grid[point[0], point[1]] = count\n",
    "    img_grid /= img_grid.max()  # normalize\n",
    "    # /s>\n",
    "    # <s Smooth `img_grid`\n",
    "    # Mice can go ~450 cm/s, we've downsampled to 10 frames/s, we have 200 px / 1000 cm,\n",
    "    # so 45 cm/frame ~= 9 px/frame\n",
    "    win_sz = 9  # in pixels  (ensure odd for centering)\n",
    "    kernel = np.ones((win_sz, win_sz)) / win_sz**2  # moving avg kernel\n",
    "    img_grid_p = np.pad(\n",
    "        img_grid, win_sz // 2, mode=\"edge\"\n",
    "    )  # pad for full output from convolution\n",
    "    img_grid_smooth = conv2d(img_grid_p, kernel)\n",
    "    # /s>\n",
    "    fig = px.imshow(\n",
    "        img_grid_smooth.T,\n",
    "        zmin=0,\n",
    "        zmax=(img_grid_smooth.max() / 1000),\n",
    "        x=np.arange(img_grid.shape[0]),\n",
    "        y=np.arange(img_grid.shape[1]),\n",
    "        labels=dict(x=\"X\", y=\"Y\", color=\"Norm Freq / 1e3\"),\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    fig.update_layout(title=f\"Position Heatmap ({id_val})\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Animal position: ethogram, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "exp_start = pd.Timestamp(\"2024-01-31\")\n",
    "metadata = (\n",
    "    aeon.load(block.root, social02.Metadata, exp_start, block.end).iloc[0].metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up\n",
    "patch_radius, gate_radius = 120, 30\n",
    "patches = list(block.patch_info.index)\n",
    "rois = patches + [\"Nest\", \"Gate\", \"Corridor\"]  # ROIs: patches, nest, gate, corridor\n",
    "roi_colors = plotly.colors.qualitative.Dark2\n",
    "roi_colors_dict = {roi : roi_c for (roi, roi_c) in zip(rois, roi_colors)}\n",
    "pos_eth_df = pd.DataFrame(columns=([\"Subject\"] + rois), index=centroid_df.index)  # df to create eth fig\n",
    "pos_eth_df[\"Subject\"] = centroid_df[\"class\"]\n",
    "\n",
    "arena_center = tuple(map(int, tuple(metadata.ActiveRegion.ArenaCenter.values())[0:2]))\n",
    "arena_inner_radius = int(metadata.ActiveRegion.ArenaInnerRadius)\n",
    "arena_outer_radius = int(metadata.ActiveRegion.ArenaOuterRadius)\n",
    "\n",
    "# For each ROI, compute if within ROI\n",
    "for roi in rois:\n",
    "    if roi == \"Corridor\":  # special case for corridor, based on between inner and outer radius\n",
    "        dist = np.linalg.norm((np.vstack((centroid_df[\"x\"], centroid_df[\"y\"])).T) - arena_center, axis=1)\n",
    "        pos_eth_df[roi] = (dist >= arena_inner_radius) & (dist <= arena_outer_radius)\n",
    "    elif roi == \"Nest\":  # special case for nest, based on 4 corners\n",
    "        nest_corners = metadata.ActiveRegion.NestRegion.ArrayOfPoint\n",
    "        nest_br_x, nest_br_y = int(nest_corners[0][\"X\"]), int(nest_corners[0][\"Y\"])\n",
    "        nest_bl_x, nest_bl_y = int(nest_corners[1][\"X\"]), int(nest_corners[1][\"Y\"])\n",
    "        nest_tl_x, nest_tl_y = int(nest_corners[2][\"X\"]), int(nest_corners[2][\"Y\"])\n",
    "        nest_tr_x, nest_tr_y = int(nest_corners[3][\"X\"]), int(nest_corners[3][\"Y\"])\n",
    "        pos_eth_df[roi] = (\n",
    "            (centroid_df[\"x\"] <= nest_br_x) & (centroid_df[\"y\"] >= nest_br_y)\n",
    "            & (centroid_df[\"x\"] >= nest_bl_x) & (centroid_df[\"y\"] >= nest_bl_y)\n",
    "            & (centroid_df[\"x\"] >= nest_tl_x) & (centroid_df[\"y\"] <= nest_tl_y)\n",
    "            & (centroid_df[\"x\"] <= nest_tr_x) & (centroid_df[\"y\"] <= nest_tr_y)\n",
    "        )\n",
    "    else:\n",
    "        roi_radius = gate_radius if roi ==\"Gate\" else patch_radius\n",
    "        # Get ROI coords\n",
    "        roi_x, roi_y = tuple(map(int, tuple(metadata.Devices[roi + \"Rfid\"].Location.values())[0:2]))\n",
    "        # Check if in ROI\n",
    "        dist = np.linalg.norm((np.vstack((centroid_df[\"x\"], centroid_df[\"y\"])).T) - (roi_x, roi_y), axis=1)\n",
    "        pos_eth_df[roi] = dist < roi_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "\n",
    "# Melt df to a single \"Loc\" column that contains loc for current time (row)\n",
    "pos_eth_df = pos_eth_df.iloc[::100]  # downsample to 10s bins\n",
    "melted_df = pos_eth_df.reset_index().melt(id_vars=[\"time\", \"Subject\"], var_name=\"Loc\", value_name=\"Val\")\n",
    "melted_df = melted_df[melted_df[\"Val\"]]\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter(\n",
    "    melted_df, \n",
    "    x=\"time\", \n",
    "    y=\"Subject\", \n",
    "    color=\"Loc\",\n",
    "    color_discrete_map=roi_colors_dict,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Position Ethogram\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Subject\",\n",
    "    width=1000,\n",
    "    height=250,\n",
    "    yaxis=dict(\n",
    "        categoryorder=\"total ascending\",\n",
    "        categoryarray=sorted(melted_df[\"Subject\"].unique()),\n",
    "        tickmode=\"array\",\n",
    "        tickvals=sorted(melted_df[\"Subject\"].unique()),\n",
    "        ticktext=sorted(melted_df[\"Subject\"].unique()),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Animal behavior: ethogram, per subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Cumulative pellet count over time, per subject, markered by patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_helper(group):\n",
    "    group[\"counter\"] = np.arange(len(group)) + 1\n",
    "    return group\n",
    "\n",
    "cum_pel_ct = (\n",
    "    pellet_info.groupby(\"id\", group_keys=False)\n",
    "    .apply(cumsum_helper)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "cum_pel_ct = cum_pel_ct.merge(\n",
    "    mean_pellet_info[[\"patch\", \"threshold\"]].rename(\n",
    "        columns={\"threshold\": \"mean_thresh\"}\n",
    "    ),\n",
    "    on=\"patch\",\n",
    "    how=\"left\",\n",
    ")\n",
    "cum_pel_ct[\"patch_label\"] = cum_pel_ct.apply(\n",
    "    lambda row: f\"{row['patch']} μ: {row['mean_thresh']}\", axis=1\n",
    ")\n",
    "cum_pel_ct[\"norm_thresh_val\"] = (\n",
    "    (cum_pel_ct[\"threshold\"] - cum_pel_ct[\"threshold\"].min())\n",
    "    / (cum_pel_ct[\"threshold\"].max() - cum_pel_ct[\"threshold\"].min())\n",
    ").round(3)\n",
    "display(cum_pel_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for id_val, id_grp in cum_pel_ct.groupby(\"id\"):\n",
    "    # Add lines by subject\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"time\"],\n",
    "            y=id_grp[\"counter\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=2, color=subject_colors_dict[id_val]),\n",
    "            name=id_val,\n",
    "        )\n",
    "    )\n",
    "for patch_i, (patch_val, patch_grp) in enumerate(cum_pel_ct.groupby(\"patch_label\")):\n",
    "    # Add markers by patch\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=patch_grp[\"time\"],\n",
    "            y=patch_grp[\"counter\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                symbol=patch_markers[patch_i],\n",
    "                color=gen_hex_grad(subject_colors[-1], patch_grp[\"norm_thresh_val\"]),\n",
    "                size=8,\n",
    "            ),\n",
    "            name=patch_val,\n",
    "            customdata=np.stack((patch_grp[\"threshold\"],), axis=-1),\n",
    "            hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Pellet Count per Subject\", xaxis_title=\"Time\", yaxis_title=\"Count\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a2. Cumulative pellet count over time, per subject-patch (one line per combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for id_val, id_grp in cum_pel_ct.groupby(\"id\"):\n",
    "    for patch_i, (patch_val, patch_grp) in enumerate(id_grp.groupby(\"patch\")):\n",
    "        cur_p = f\"P{patch_i+1}\"\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=patch_grp[\"time\"],\n",
    "                y=np.arange(1, (len(patch_grp) + 1)),\n",
    "                mode=\"lines+markers\",\n",
    "                line=dict(width=2, color=subject_colors_dict[id_val]),\n",
    "                marker=dict(\n",
    "                    symbol=patch_markers[patch_i],\n",
    "                    color=gen_hex_grad(subject_colors[-1], patch_grp[\"norm_thresh_val\"]),\n",
    "                    size=8,\n",
    "                ),\n",
    "                name=f\"{subj} - {cur_p}: μ: {block.patch_info['mean'][patch_val]}\",\n",
    "                customdata=np.stack((patch_grp[\"threshold\"],), axis=-1),\n",
    "                hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(title=\"Cumulative Pellet Count per Subject-Patch\", xaxis_title=\"Time\", yaxis_title=\"Count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Pellet delivery over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for id_i, (id_val, id_grp) in enumerate(cum_pel_ct.groupby(\"id\")):\n",
    "    # Add lines by subject\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"time\"],\n",
    "            y=id_grp[\"patch_label\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(width=2, color=subject_colors_dict[id_val]),\n",
    "            marker=dict(\n",
    "                symbol=patch_markers[0],\n",
    "                color=gen_hex_grad(subject_colors[id_i], id_grp[\"norm_thresh_val\"]),\n",
    "                size=8,\n",
    "            ),\n",
    "            name=id_val,\n",
    "            customdata=np.stack((id_grp[\"threshold\"],), axis=-1),\n",
    "            hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pellet Delivery Over Time\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Patch\",\n",
    "    yaxis={\n",
    "        \"categoryorder\": \"array\",\n",
    "        \"categoryarray\": cum_pel_ct.sort_values(\"mean_thresh\")[\n",
    "            \"patch_label\"\n",
    "        ].unique(),  # sort y-axis by patch threshold mean\n",
    "    },\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Pellet threshold vals over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for id_val, id_grp in cum_pel_ct.groupby(\"id\"):\n",
    "    # Add lines by subject\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=id_grp[\"time\"],\n",
    "            y=id_grp[\"threshold\"],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=2, color=subject_colors_dict[id_val]),\n",
    "            name=id_val,\n",
    "        )\n",
    "    )\n",
    "for patch_i, (patch_val, patch_grp) in enumerate(cum_pel_ct.groupby(\"patch_label\")):\n",
    "    # Add markers by patch\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=patch_grp[\"time\"],\n",
    "            y=patch_grp[\"threshold\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                symbol=patch_markers[patch_i],\n",
    "                color=\"black\",\n",
    "                size=8\n",
    "            ),\n",
    "            name=patch_val,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pellet Thresholds\", xaxis_title=\"Time\", yaxis_title=\"Threshold (cm)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cumulative wheel distance over time, per patch, per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_wheel_dist = good_blocks_df[\"cum_wheel_dist\"].iloc[b_i]\n",
    "patches = block.patch_info.index\n",
    "\n",
    "fig = go.Figure()\n",
    "for subj_i, subj in enumerate(block.subjects):\n",
    "    for patch_i, p in enumerate(patches):\n",
    "        cur_cum_wheel_dist = cum_wheel_dist[p][subj]\n",
    "        cur_p = f\"P{patch_i+1}\"\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cur_cum_wheel_dist.index,\n",
    "                y=cur_cum_wheel_dist,\n",
    "                mode=\"lines\",  # +  markers\",\n",
    "                line=dict(width=2, color=subject_colors[subj_i], dash=patch_markers_linestyles[patch_i]),\n",
    "                name=f\"{subj} - {cur_p}: μ: {block.patch_info['mean'][p]}\",\n",
    "                #legendgroup=subj,\n",
    "                #showlegend=False,\n",
    "            )\n",
    "        )\n",
    "        # Add markers for each pellet\n",
    "        cur_cum_pel_ct = pd.merge_asof(\n",
    "            cum_pel_ct[(cum_pel_ct[\"id\"] == subj) &\n",
    "                       (cum_pel_ct[\"patch\"] == p)],\n",
    "            cur_cum_wheel_dist.reset_index(name=\"cum_wheel_dist\"),\n",
    "            on=\"time\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=pd.Timedelta(\"0.1s\"),\n",
    "        )\n",
    "        if not cur_cum_pel_ct.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cur_cum_pel_ct[\"time\"],\n",
    "                    y=cur_cum_pel_ct[\"cum_wheel_dist\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        symbol=patch_markers[patch_i],\n",
    "                        color=gen_hex_grad(subject_colors[-1], cur_cum_pel_ct[\"norm_thresh_val\"]),\n",
    "                        size=8,\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    #name=cur_cum_pel_ct[\"patch_label\"].iloc[0],\n",
    "                    #legendgroup=subj,\n",
    "                    #legendgrouptitle_text=subj,\n",
    "                    customdata=np.stack(\n",
    "                        (cur_cum_pel_ct[\"threshold\"],), axis=-1),\n",
    "                    hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "                )\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Wheel Distance\", xaxis_title=\"Time\", yaxis_title=\"Distance (cm)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Patch Preference: Cumulative, normalized, by wheel_distance and in_patch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using DJ.\"\"\"\n",
    "\n",
    "key = {\"experiment_name\": \"social0.2-aeon3\", \"block_start\": \"2024-02-11 13:36:10\"}\n",
    "block_patches = (BlockAnalysis.Patch & key).fetch(as_dict=True)\n",
    "block_subjects = (BlockAnalysis.Subject & key).fetch(as_dict=True)\n",
    "subject_names = [s[\"subject_name\"] for s in block_subjects]\n",
    "patch_names = [p[\"patch_name\"] for p in block_patches]\n",
    "# Construct subject position dataframe\n",
    "subjects_positions_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            {\"subject_name\": [s[\"subject_name\"]] * len(s[\"position_timestamps\"])}\n",
    "            | {\n",
    "                k: s[k]\n",
    "                for k in (\n",
    "                    \"position_timestamps\",\n",
    "                    \"position_x\",\n",
    "                    \"position_y\",\n",
    "                    \"position_likelihood\",\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        for s in block_subjects\n",
    "    ]\n",
    ")\n",
    "subjects_positions_df.set_index(\"position_timestamps\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_patch_radius = 130  # pixels\n",
    "pref_attrs = [\"cum_dist\", \"cum_time\", \"cum_pref_dist\", \"cum_pref_time\"]\n",
    "cols = [\n",
    "    s + \"_\" + p + \"_\" + a\n",
    "    for s in subject_names\n",
    "    for p in patch_names\n",
    "    for a in pref_attrs\n",
    "]\n",
    "all_subj_patch_pref = pd.DataFrame(columns=cols)\n",
    "for patch in block_patches:\n",
    "    cum_wheel_dist = pd.Series(\n",
    "        index=patch[\"wheel_timestamps\"], data=patch[\"wheel_cumsum_distance_travelled\"]\n",
    "    )\n",
    "    # Assign pellets and wheel timestamps to subjects\n",
    "    if len(block_subjects) == 1:  # TODO implement for single subject\n",
    "        pass\n",
    "    else:\n",
    "        # Assign id based on which subject was closest to patch at time of event\n",
    "        # Get distance-to-patch at each wheel ts and pel del ts, organized by subject\n",
    "        # Get patch x,y from metadata patch rfid loc\n",
    "        patch_center = (\n",
    "            streams.RfidReader * streams.RfidReader.Attribute\n",
    "            & key\n",
    "            & f\"rfid_reader_name LIKE '%{patch['patch_name']}%'\"\n",
    "            & \"attribute_name = 'Location'\"\n",
    "        ).fetch1(\"attribute_value\")\n",
    "        patch_center = (int(patch_center[\"X\"]), int(patch_center[\"Y\"]))\n",
    "        subjects_xy = subjects_positions_df[[\"position_x\", \"position_y\"]].values\n",
    "        dist_to_patch = np.sqrt(\n",
    "            np.sum((subjects_xy - patch_center) ** 2, axis=1).astype(float)\n",
    "        )\n",
    "        dist_to_patch_df = subjects_positions_df[[\"subject_name\"]].copy()\n",
    "        dist_to_patch_df[\"dist_to_patch\"] = dist_to_patch\n",
    "        dist_to_patch_wheel_ts_id_df = pd.DataFrame(\n",
    "            index=cum_wheel_dist.index, columns=subject_names\n",
    "        )\n",
    "        dist_to_patch_pel_ts_id_df = pd.DataFrame(\n",
    "            index=patch[\"pellet_timestamps\"], columns=subject_names\n",
    "        )\n",
    "        for subject_name in subject_names:\n",
    "            # Find closest match between pose_df indices and wheel indices\n",
    "            if not dist_to_patch_wheel_ts_id_df.empty:\n",
    "                dist_to_patch_wheel_ts_subj = pd.merge_asof(\n",
    "                    left=pd.DataFrame(\n",
    "                        dist_to_patch_wheel_ts_id_df[subject_name].copy()\n",
    "                    ).reset_index(names=\"time\"),\n",
    "                    right=dist_to_patch_df[\n",
    "                        dist_to_patch_df[\"subject_name\"] == subject_name\n",
    "                    ]\n",
    "                    .copy()\n",
    "                    .reset_index(names=\"time\"),\n",
    "                    on=\"time\",\n",
    "                    # left_index=True,\n",
    "                    # right_index=True,\n",
    "                    direction=\"nearest\",\n",
    "                    tolerance=pd.Timedelta(\"100ms\"),\n",
    "                )\n",
    "                dist_to_patch_wheel_ts_id_df[subject_name] = (\n",
    "                    dist_to_patch_wheel_ts_subj[\"dist_to_patch\"].values\n",
    "                )\n",
    "            # Find closest match between pose_df indices and pel indices\n",
    "            if not dist_to_patch_pel_ts_id_df.empty:\n",
    "                dist_to_patch_pel_ts_subj = pd.merge_asof(\n",
    "                    left=pd.DataFrame(\n",
    "                        dist_to_patch_pel_ts_id_df[subject_name].copy()\n",
    "                    ).reset_index(names=\"time\"),\n",
    "                    right=dist_to_patch_df[\n",
    "                        dist_to_patch_df[\"subject_name\"] == subject_name\n",
    "                    ]\n",
    "                    .copy()\n",
    "                    .reset_index(names=\"time\"),\n",
    "                    on=\"time\",\n",
    "                    # left_index=True,\n",
    "                    # right_index=True,\n",
    "                    direction=\"nearest\",\n",
    "                    tolerance=pd.Timedelta(\"200ms\"),\n",
    "                )\n",
    "                dist_to_patch_pel_ts_id_df[subject_name] = dist_to_patch_pel_ts_subj[\n",
    "                    \"dist_to_patch\"\n",
    "                ].values\n",
    "        # Get closest subject to patch at each wheel timestep\n",
    "        cum_wheel_dist_subj_df = pd.DataFrame(\n",
    "            index=cum_wheel_dist.index, columns=subject_names, data=0.0\n",
    "        )\n",
    "        closest_subjects = dist_to_patch_wheel_ts_id_df.idxmin(axis=1)\n",
    "        wheel_dist = cum_wheel_dist.diff().fillna(cum_wheel_dist.iloc[0])\n",
    "        # Assign wheel dist to closest subject for each wheel timestep\n",
    "        for subject_name in subject_names:\n",
    "            subj_idxs = cum_wheel_dist_subj_df[closest_subjects == subject_name].index\n",
    "            cum_wheel_dist_subj_df.loc[subj_idxs, subject_name] = wheel_dist[subj_idxs]\n",
    "        cum_wheel_dist_subj_df = cum_wheel_dist_subj_df.cumsum(axis=0)\n",
    "        # In patch time\n",
    "        in_patch = dist_to_patch_wheel_ts_id_df < in_patch_radius\n",
    "        # Fill in `all_subj_patch_pref`\n",
    "        for subject_name in subject_names:\n",
    "            all_subj_patch_pref[\n",
    "                subject_name + \"_\" + patch[\"patch_name\"] + \"_\" + \"cum_dist\"\n",
    "            ] = cum_wheel_dist_subj_df[subject_name].values\n",
    "            dt = (in_patch.index[1] - in_patch.index[0]) / 1e6  # ms\n",
    "            all_subj_patch_pref[\n",
    "                subject_name + \"_\" + patch[\"patch_name\"] + \"_\" + \"cum_time\"\n",
    "            ] = (in_patch[subject_name].cumsum().values * dt).astype(\n",
    "                int\n",
    "            )  # ms\n",
    "# Now that we have computed all individual patch and subject values, we iterate again through\n",
    "# patches and subjects to compute preference scores\n",
    "for subject_name in subject_names:\n",
    "    # Get sum of subj cum wheel dists and cum in patch time\n",
    "    dist_cols = [\n",
    "        col\n",
    "        for col in all_subj_patch_pref.columns\n",
    "        if col.startswith(subject_name) and col.endswith(\"cum_dist\")\n",
    "    ]\n",
    "    all_cum_dist = np.sum(all_subj_patch_pref[dist_cols].iloc[-1])\n",
    "    time_cols = [\n",
    "        col\n",
    "        for col in all_subj_patch_pref.columns\n",
    "        if col.startswith(subject_name) and col.endswith(\"cum_time\")\n",
    "    ]\n",
    "    all_cum_time = np.sum(all_subj_patch_pref[time_cols].iloc[-1])\n",
    "    for patch in block_patches:\n",
    "        all_subj_patch_pref[\n",
    "            subject_name + \"_\" + patch[\"patch_name\"] + \"_\" + \"cum_pref_dist\"\n",
    "        ] = (\n",
    "            all_subj_patch_pref[\n",
    "                subject_name + \"_\" + patch[\"patch_name\"] + \"_\" + \"cum_dist\"\n",
    "            ]\n",
    "            / all_cum_dist\n",
    "        )\n",
    "        all_subj_patch_pref[\n",
    "            subject_name + \"_\" + patch[\"patch_name\"] + \"_\" + \"cum_pref_time\"\n",
    "        ] = (\n",
    "            all_subj_patch_pref[\n",
    "                subject_name + \"_\" + patch[\"patch_name\"] + \"_\" + \"cum_time\"\n",
    "            ]\n",
    "            / all_cum_time\n",
    "        )\n",
    "\n",
    "all_subj_patch_pref[\"time\"] = cum_wheel_dist.index\n",
    "display(all_subj_patch_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wheel dist pref figure\n",
    "\n",
    "# For subject, for patch, plot cum_pref_dist\n",
    "\n",
    "fig = go.Figure()\n",
    "for subj_i, subj in enumerate(subject_names):\n",
    "    for patch_i, p in enumerate(patch_names):\n",
    "        cur_pref = all_subj_patch_pref[f\"{subj}_{p}_cum_pref_dist\"]\n",
    "        cur_p = f\"P{patch_i+1}\"\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=all_subj_patch_pref[\"time\"],\n",
    "                y=cur_pref,\n",
    "                mode=\"lines\",  # +  markers\",\n",
    "                line=dict(\n",
    "                    width=2,\n",
    "                    color=subject_colors[subj_i],\n",
    "                    dash=patch_markers_linestyles[patch_i],\n",
    "                ),\n",
    "                name=f\"{subj} - {cur_p}: μ: {block.patch_info['mean'][p]}\",\n",
    "            )\n",
    "        )\n",
    "        # Add markers for each pellet\n",
    "        cur_cum_pel_ct = pd.merge_asof(\n",
    "            cum_pel_ct[(cum_pel_ct[\"id\"] == subj) & (cum_pel_ct[\"patch\"] == p)],\n",
    "            all_subj_patch_pref,\n",
    "            on=\"time\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=pd.Timedelta(\"0.1s\"),\n",
    "        )\n",
    "        if not cur_cum_pel_ct.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cur_cum_pel_ct[\"time\"],\n",
    "                    y=cur_cum_pel_ct[f\"{subj}_{p}_cum_pref_dist\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        symbol=patch_markers[patch_i],\n",
    "                        color=gen_hex_grad(\n",
    "                            subject_colors[-1], cur_cum_pel_ct[\"norm_thresh_val\"]\n",
    "                        ),\n",
    "                        size=8,\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    customdata=np.stack((cur_cum_pel_ct[\"threshold\"],), axis=-1),\n",
    "                    hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "                )\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Patch Preference - Wheel Distance\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Pref Index\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-patch time pref figure\n",
    "\n",
    "# For subject, for patch, plot cum_pref_time\n",
    "\n",
    "fig = go.Figure()\n",
    "for subj_i, subj in enumerate(subject_names):\n",
    "    for patch_i, p in enumerate(patch_names):\n",
    "        cur_pref = all_subj_patch_pref[f\"{subj}_{p}_cum_pref_time\"]\n",
    "        cur_p = f\"P{patch_i+1}\"\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=all_subj_patch_pref[\"time\"],\n",
    "                y=cur_pref,\n",
    "                mode=\"lines\",  # +  markers\",\n",
    "                line=dict(\n",
    "                    width=2,\n",
    "                    color=subject_colors[subj_i],\n",
    "                    dash=patch_markers_linestyles[patch_i],\n",
    "                ),\n",
    "                name=f\"{subj} - {cur_p}: μ: {block.patch_info['mean'][p]}\",\n",
    "            )\n",
    "        )\n",
    "        # Add markers for each pellet\n",
    "        cur_cum_pel_ct = pd.merge_asof(\n",
    "            cum_pel_ct[(cum_pel_ct[\"id\"] == subj) & (cum_pel_ct[\"patch\"] == p)],\n",
    "            all_subj_patch_pref,\n",
    "            on=\"time\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=pd.Timedelta(\"0.1s\"),\n",
    "        )\n",
    "        if not cur_cum_pel_ct.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=cur_cum_pel_ct[\"time\"],\n",
    "                    y=cur_cum_pel_ct[f\"{subj}_{p}_cum_pref_time\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        symbol=patch_markers[patch_i],\n",
    "                        color=gen_hex_grad(\n",
    "                            subject_colors[-1], cur_cum_pel_ct[\"norm_thresh_val\"]\n",
    "                        ),\n",
    "                        size=8,\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    customdata=np.stack((cur_cum_pel_ct[\"threshold\"],), axis=-1),\n",
    "                    hovertemplate=\"Threshold: %{customdata[0]:.2f} cm\",\n",
    "                )\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Patch Preference - Patch Time\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Pref Index\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Plots (per experiment and room)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Threshold vals per block per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only blocks with more than 15 pellets\n",
    "\n",
    "pel_thresh = 15\n",
    "foraging_blocks = good_blocks_df_cp[\n",
    "    good_blocks_df_cp[\"pellet_info\"].apply(len) > pel_thresh\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column \"block_type\" with values [\"presocial\", \"social\", \"postsocial\"]\n",
    "\n",
    "mask_social = foraging_blocks[\"subjects\"].apply(len) > 1\n",
    "subj_str = foraging_blocks[\"subjects\"].apply(str)\n",
    "presocial_condition = foraging_blocks[mask_social].groupby(subj_str)[\n",
    "    \"start\"].min()\n",
    "postsocial_condition = foraging_blocks[mask_social].groupby(subj_str)[\n",
    "    \"end\"].max()\n",
    "\n",
    "\n",
    "def assign_block_type(row):\n",
    "    if len(row[\"subjects\"]) > 1:\n",
    "        return \"social\"\n",
    "    else:\n",
    "        subj = row[\"subjects\"][0]\n",
    "        idx = next(\n",
    "            iter([idx for idx in presocial_condition.index if subj in idx]), None\n",
    "        )\n",
    "        if idx is not None:\n",
    "            if row[\"start\"] < presocial_condition[idx]:\n",
    "                return \"presocial\"\n",
    "            elif row[\"start\"] > postsocial_condition[idx]:\n",
    "                return \"postsocial\"\n",
    "\n",
    "\n",
    "foraging_blocks[\"block_type\"] = foraging_blocks.apply(\n",
    "    assign_block_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold vals obtained from halfway thru block (lower better, obvs)\n",
    "\n",
    "fig = go.Figure()\n",
    "legend_added = set()  # legend only for unique subjs\n",
    "learning_threshold_vals = pd.DataFrame(columns=[\"threshold_vals\", \"id\"])\n",
    "block_type_markers = {\n",
    "    \"presocial\": patch_markers[0],\n",
    "    \"social\": patch_markers[1],\n",
    "    \"postsocial\": patch_markers[2],\n",
    "}\n",
    "for block_i, block in enumerate(foraging_blocks.itertuples()):\n",
    "    n_pellets = len(block.pellet_info)\n",
    "    pellet_info = block.pellet_info.sort_values(\"time\")\n",
    "    pellet_info_post = pellet_info.iloc[\n",
    "        (n_pellets // 2) :\n",
    "    ]  # halfway point (in terms of pellets obtained)\n",
    "    # Get threshold vals, per subject.\n",
    "    for subj_val, subj_grp in pellet_info_post.groupby(\"id\"):\n",
    "        # Add threshold_vals, id as row to `learning_threshold_vals`.\n",
    "        new_row = pd.DataFrame(columns=[\"threshold_vals\", \"id\"], index=[block.Index])\n",
    "        new_row[\"threshold_vals\"], new_row[\"id\"] = (\n",
    "            [subj_grp[\"threshold\"].values],\n",
    "            subj_val,\n",
    "        )\n",
    "        learning_threshold_vals = pd.concat((learning_threshold_vals, new_row))\n",
    "        # subj_val\n",
    "        grouping_factor = f\"{patch_markers_dict.get(block_type_markers[block.block_type])} {\n",
    "            subj_val} {block.block_type}\"\n",
    "        show_in_legend = grouping_factor not in legend_added\n",
    "        # If not, add it and set the flag to False for subsequent rows with the same ID\n",
    "        if show_in_legend:\n",
    "            legend_added.add(grouping_factor)\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=new_row.loc[block.Index, \"threshold_vals\"],\n",
    "                x=[block.Index] * len(new_row.loc[block.Index, \"threshold_vals\"]),\n",
    "                name=grouping_factor,\n",
    "                legendgroup=grouping_factor,\n",
    "                boxpoints=\"all\",\n",
    "                # jitter=0.5,\n",
    "                marker={\n",
    "                    \"color\": subject_colors_dict[subj_val],\n",
    "                    \"symbol\": block_type_markers[block.block_type],\n",
    "                },\n",
    "                showlegend=show_in_legend,  # legend only for unique subjs\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Pellet Thresholds\",\n",
    "    xaxis_title=\"Block Index\",\n",
    "    yaxis_title=\"Threshold (cm)\",\n",
    ")\n",
    "fig.update_layout(legend_tracegroupgap=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Patch preference per block per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch preference by wheel dist spun from halfway through block\n",
    "\n",
    "pp_overall = pd.DataFrame(\n",
    "    columns=[\"one_best_patch\", \"two_best_patches\", \"id\", \"block_type\"]\n",
    ")  # e.g. easy vs. (medium + hard); (easy + medium) vs. hard\n",
    "\n",
    "for block_i, block in enumerate(foraging_blocks.itertuples()):\n",
    "    easy_p, med_p, hard_p = block.patch_info.sort_values(\"mean\").index\n",
    "    n_pellets = len(block.pellet_info)\n",
    "    pellet_info = block.pellet_info.sort_values(\"time\")\n",
    "    halfway_ts = pellet_info[\"time\"].iloc[n_pellets // 2]\n",
    "    cum_wheel_dist = good_blocks_df[\"cum_wheel_dist\"].loc[block.Index]\n",
    "    for subj in block.subjects:\n",
    "        easy_dist = cum_wheel_dist[easy_p][subj]\n",
    "        easy_dist = (\n",
    "            easy_dist[easy_dist.index > halfway_ts].iloc[-1]\n",
    "            - easy_dist[easy_dist.index > halfway_ts].iloc[0]\n",
    "        )\n",
    "        easy_dist = 1 if easy_dist < 0 else easy_dist\n",
    "        med_dist = cum_wheel_dist[med_p][subj]\n",
    "        med_dist = (\n",
    "            med_dist[med_dist.index > halfway_ts].iloc[-1]\n",
    "            - med_dist[med_dist.index > halfway_ts].iloc[0]\n",
    "        )\n",
    "        med_dist = 1 if med_dist < 0 else med_dist\n",
    "        hard_dist = cum_wheel_dist[hard_p][subj]\n",
    "        hard_dist = (\n",
    "            hard_dist[hard_dist.index > halfway_ts].iloc[-1]\n",
    "            - hard_dist[hard_dist.index > halfway_ts].iloc[0]\n",
    "        )\n",
    "        hard_dist = 1 if hard_dist < 0 else hard_dist\n",
    "        new_row = pd.DataFrame(\n",
    "            columns=[\"one_best_patch\", \"two_best_patches\"], index=[block.Index]\n",
    "        )\n",
    "        new_row[\"one_best_patch\"] = np.round(\n",
    "            (easy_dist / (easy_dist + med_dist + hard_dist)), 3\n",
    "        )\n",
    "        new_row[\"two_best_patches\"] = np.round(\n",
    "            ((easy_dist + med_dist) / (easy_dist + med_dist + hard_dist)), 3\n",
    "        )\n",
    "        new_row[\"id\"] = subj\n",
    "        new_row[\"block_type\"] = block.block_type\n",
    "        pp_overall = pd.concat((pp_overall, new_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for block_type in block_type_markers.keys():\n",
    "    for id, group in pp_overall[pp_overall[\"block_type\"] == block_type].groupby(\"id\"):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=group.index,\n",
    "                y=group[\"one_best_patch\"],\n",
    "                mode=\"markers\",\n",
    "                name=block_type,\n",
    "                legendgroup=id,\n",
    "                legendgrouptitle_text=id,\n",
    "                marker={\"color\": subject_colors_dict[id]},\n",
    "                marker_symbol=block_type_markers[block_type],\n",
    "            )\n",
    "        )\n",
    "fig.update_layout(\n",
    "    title=\"Patch Preference: Easy Only\",\n",
    "    xaxis_title=\"Block Index\",\n",
    "    yaxis_title=\"Preference\",\n",
    "    legend_tracegroupgap=0,\n",
    ")\n",
    "fig.update_traces(\n",
    "    legendgrouptitle_font_size=12,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pp_overall,\n",
    "    x=pp_overall.index,\n",
    "    y=[\"one_best_patch\"],\n",
    "    color=\"id\",\n",
    "    symbol=\"block_type\",\n",
    "    title=\"Patch Preference: Easy Only\",\n",
    "    labels={\"index\": \"Block Index\", \"value\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"\")\n",
    "fig.for_each_trace(lambda trace: setattr(\n",
    "    trace, \"name\", trace.name.replace(\",\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pp_overall,\n",
    "    x=pp_overall.index,\n",
    "    y=[\"two_best_patches\"],\n",
    "    color=\"id\",\n",
    "    symbol=\"block_type\",\n",
    "    title=\"Patch Preference: Easy + Medium\",\n",
    "    labels={\"index\": \"Block Index\", \"value\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"\")\n",
    "fig.for_each_trace(lambda trace: setattr(\n",
    "    trace, \"name\", trace.name.replace(\",\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Patch Preference by Block Type (presocial, social, postsocial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    pp_overall,\n",
    "    x=\"block_type\",\n",
    "    y=\"one_best_patch\",\n",
    "    color=\"id\",\n",
    "    points=\"all\",\n",
    "    title=\"Patch Preference: Easy Only by Block Type\",\n",
    "    labels={\"block_type\": \"Block Type\", \"one_best_patch\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"ID\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    pp_overall,\n",
    "    x=\"block_type\",\n",
    "    y=\"two_best_patches\",\n",
    "    color=\"id\",\n",
    "    points=\"all\",\n",
    "    title=\"Patch Preference: Easy + Medium by Block Type\",\n",
    "    labels={\"block_type\": \"Block Type\", \"two_best_patches\": \"Preference\"},\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"ID\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Patch Preference Difference between First- and Second-Half of Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Cumulative Wheel Distance by Patch Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Cumulative Wheel Distance by Patch ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (WIP) Correct ID swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are times when the same ID is assigned to multiple animals in the same frame\n",
    "# Try to assign the row with duplicated ID with lower likelihood to another ID\n",
    "centroid_df_cp = centroid_df.reset_index().copy()\n",
    "classes = np.array(centroid_df_cp[\"class\"].unique())\n",
    "# Mask for rows with multiple assignments of the same ID at the same time\n",
    "many_to_one_mask = centroid_df_cp.groupby([\"time\", \"class\"]).transform(\"size\") > 1\n",
    "duplicated_data = centroid_df_cp.loc[many_to_one_mask]\n",
    "# Indices for rows with lower likelihood\n",
    "low_likelihood_idx = duplicated_data.loc[\n",
    "    ~duplicated_data.index.isin(\n",
    "        duplicated_data.groupby([\"time\", \"class\"])[\"class_likelihood\"].idxmax()\n",
    "    )\n",
    "].index\n",
    "# This assigns another class randomly (in 2-animal case, it's the other animal, but in >2-animal case, it may assign duplicate IDs again)\n",
    "centroid_df_cp.loc[low_likelihood_idx, \"class\"] = centroid_df_cp.loc[\n",
    "    low_likelihood_idx\n",
    "].apply(lambda x: np.random.choice(classes[classes != x[\"class\"]]), axis=1)\n",
    "centroid_df_cp.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on a smaller subset of data\n",
    "centroid_df_cp = centroid_df_cp.loc[\"2024-02-18 11:00:00\":\"2024-02-18 11:05:00\"].copy()\n",
    "# Compute instantaneous speed\n",
    "centroid_df_cp[\"speed\"] = (\n",
    "    centroid_df_cp.groupby(\"class\")[[\"x\", \"y\"]].diff().apply(\n",
    "        np.linalg.norm, axis=1)\n",
    "    / centroid_df_cp.reset_index()\n",
    "    .groupby(\"class\")[\"time\"]\n",
    "    .diff()\n",
    "    .dt.total_seconds()\n",
    "    .values\n",
    ")\n",
    "speed_threshold = 500\n",
    "classes = centroid_df_cp[\"class\"].unique()\n",
    "timestamps = centroid_df_cp.index.unique()  # assuming timestamps are sorted\n",
    "speed_mask = (np.isfinite(centroid_df_cp[\"speed\"].values)) & (\n",
    "    centroid_df_cp[\"speed\"] > speed_threshold\n",
    ")\n",
    "dtypes_dict = centroid_df_cp.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "while speed_mask.any():  # while there are speed violations\n",
    "    # work on \"windows\" of 2 consecutive violations\n",
    "    first_two_violations = centroid_df_cp[speed_mask].index.unique().sort_values()[\n",
    "        :2]\n",
    "    if len(first_two_violations) > 1:\n",
    "        start_window, end_window = pd.to_datetime(first_two_violations)\n",
    "        swap_window = centroid_df_cp.loc[start_window:end_window]\n",
    "    else:  # last violation\n",
    "        start_window = first_two_violations.iloc[0]\n",
    "        swap_window = centroid_df_cp.loc[start_window:]\n",
    "    for curr_timestamp in swap_window.index.unique():\n",
    "        # use previous rows to correct id assignment based on speed\n",
    "        prev_timestamp = timestamps[np.where(\n",
    "            timestamps == curr_timestamp)[0][0] - 1]\n",
    "        prev_rows = centroid_df_cp.loc[prev_timestamp]\n",
    "        curr_rows = centroid_df_cp.loc[curr_timestamp]\n",
    "        if isinstance(prev_rows, pd.Series):\n",
    "            prev_rows = prev_rows.to_frame().T.astype(dtypes_dict)\n",
    "        if isinstance(curr_rows, pd.Series):\n",
    "            curr_rows = curr_rows.to_frame().T.astype(dtypes_dict)\n",
    "        prev_rows = prev_rows.reset_index().rename(columns={\"index\": \"time\"})\n",
    "        curr_rows = curr_rows.reset_index().rename(columns={\"index\": \"time\"})\n",
    "        # initialise np array to store the hungarian cost matrix\n",
    "        cost_matrix = np.zeros((len(prev_rows), len(curr_rows)))\n",
    "        for prev_row in prev_rows.itertuples():\n",
    "            for curr_row in curr_rows.itertuples():\n",
    "                # Calculate speed\n",
    "                x_diff = curr_row.x - prev_row.x\n",
    "                y_diff = curr_row.y - prev_row.y\n",
    "                distance = np.sqrt(x_diff**2 + y_diff**2)\n",
    "                time_diff = (curr_row.time - prev_row.time).total_seconds()\n",
    "                cost_matrix[prev_row.Index, curr_row.Index] = (\n",
    "                    distance / time_diff if time_diff != 0 else np.nan\n",
    "                )\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        if len(prev_rows) < len(curr_rows):\n",
    "            classes_to_assign = classes.copy()\n",
    "            swap_order = {\n",
    "                prev_rows.loc[r, \"class\"]: c for r, c in zip(row_ind, col_ind)\n",
    "            }\n",
    "            for id, new in swap_order.items():\n",
    "                # get the index of ID\n",
    "                old = np.where(classes_to_assign == id)[0][0]\n",
    "                if old != new:\n",
    "                    # swap the values\n",
    "                    classes_to_assign[new], classes_to_assign[old] = (\n",
    "                        classes_to_assign[old],\n",
    "                        classes_to_assign[new],\n",
    "                    )\n",
    "            centroid_df_cp.loc[curr_timestamp, \"class\"] = classes_to_assign[\n",
    "                : len(curr_rows)\n",
    "            ]\n",
    "        else:\n",
    "            curr_rows.loc[col_ind,\n",
    "                          \"class\"] = prev_rows.loc[row_ind, \"class\"].values\n",
    "            curr_rows = curr_rows.loc[col_ind].set_index(\"time\", drop=True)\n",
    "            centroid_df_cp.loc[curr_timestamp, \"class\"] = prev_rows.loc[\n",
    "                row_ind, \"class\"\n",
    "            ].values\n",
    "    # recompute speed and speed_mask\n",
    "    centroid_df_cp[\"speed\"] = (\n",
    "        centroid_df_cp.groupby(\"class\")[[\"x\", \"y\"]].diff().apply(\n",
    "            np.linalg.norm, axis=1)\n",
    "        / centroid_df_cp.reset_index()\n",
    "        .groupby(\"class\")[\"time\"]\n",
    "        .diff()\n",
    "        .dt.total_seconds()\n",
    "        .values\n",
    "    )\n",
    "    speed_mask = (np.isfinite(centroid_df_cp[\"speed\"].values)) & (\n",
    "        centroid_df_cp[\"speed\"] > speed_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final speed\n",
    "centroid_df_cp[\"speed\"] = (\n",
    "    centroid_df_cp.groupby(\"class\")[[\"x\", \"y\"]].diff().apply(np.linalg.norm, axis=1)\n",
    "    / centroid_df_cp.reset_index()\n",
    "    .groupby(\"class\")[\"time\"]\n",
    "    .diff()\n",
    "    .dt.total_seconds()\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "data = centroid_df_cp.loc[\"2024-02-18 11:00:00\":\"2024-02-18 11:01:31.860000134\"]\n",
    "classes = data[\"class\"].unique()\n",
    "for class_ in classes:\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "            x=data[data[\"class\"] == class_].index,\n",
    "            y=data[data[\"class\"] == class_][\"x\"],\n",
    "            mode=\"markers\",\n",
    "            name=str(class_),  # Use the class as the name of the trace\n",
    "            marker=dict(color=subject_colors_dict[class_]),\n",
    "            hovertemplate=\"Speed: %{text}\",\n",
    "            text=data[data[\"class\"] == class_][\"speed\"].tolist(),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "            x=data[data[\"class\"] == class_].index,\n",
    "            y=data[data[\"class\"] == class_][\"y\"],\n",
    "            mode=\"markers\",\n",
    "            name=str(class_),  # Use the class as the name of the trace\n",
    "            marker=dict(color=subject_colors_dict[class_]),\n",
    "            hovertemplate=\"Speed: %{text}\",\n",
    "            text=data[data[\"class\"] == class_][\"speed\"].tolist(),\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "fig.update_yaxes(title_text=\"x position\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"y position\", row=2, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "data = centroid_df.loc[\"2024-02-18 11:00:00\":\"2024-02-18 11:01:31.860000134\"].copy()\n",
    "# Compute speed\n",
    "data[\"speed\"] = (\n",
    "    data.groupby(\"class\")[[\"x\", \"y\"]].diff().apply(np.linalg.norm, axis=1)\n",
    "    / data.reset_index().groupby(\"class\")[\"time\"].diff().dt.total_seconds().values\n",
    ")\n",
    "classes = data[\"class\"].unique()\n",
    "for class_ in classes:\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "            x=data[data[\"class\"] == class_].index,\n",
    "            y=data[data[\"class\"] == class_][\"x\"],\n",
    "            mode=\"markers\",\n",
    "            name=str(class_),  # Use the class as the name of the trace\n",
    "            marker=dict(color=subject_colors_dict[class_]),\n",
    "            hovertemplate=\"Speed: %{text}\",\n",
    "            text=data[data[\"class\"] == class_][\"speed\"].tolist(),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.append_trace(\n",
    "        go.Scatter(\n",
    "            x=data[data[\"class\"] == class_].index,\n",
    "            y=data[data[\"class\"] == class_][\"y\"],\n",
    "            mode=\"markers\",\n",
    "            name=str(class_),  # Use the class as the name of the trace\n",
    "            marker=dict(color=subject_colors_dict[class_]),\n",
    "            hovertemplate=\"Speed: %{text}\",\n",
    "            text=data[data[\"class\"] == class_][\"speed\"].tolist(),\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "fig.update_yaxes(title_text=\"x position\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"y position\", row=2, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions to retrieve and show single frame. \"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from aeon.io.video import frames\n",
    "\n",
    "\n",
    "def get_single_frame(\n",
    "    root: str | os.PathLike,\n",
    "    video_reader: aeon.io.reader.Video,\n",
    "    time: pd.Timestamp,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Retrieve a single frame from the given root directory,\n",
    "    Video reader, and time.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path where epoch data\n",
    "            is stored.\n",
    "        video_reader (aeon.io.reader.Video): The Video reader.\n",
    "        time (pd.Timestamp): The timestamp of the frame to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The raw frame.\n",
    "    \"\"\"\n",
    "    vdata = aeon.load(\n",
    "        root, video_reader, start=time, end=time + pd.Timedelta(seconds=1)\n",
    "    )\n",
    "    vframe = frames(vdata.iloc[:1])\n",
    "    return np.squeeze(list(vframe))\n",
    "\n",
    "\n",
    "def plot_overlay(\n",
    "    img: np.ndarray,\n",
    "    pose: pd.DataFrame = None,\n",
    "    roi_coords: \"list[list[tuple[int, int]]]\" = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Overlay any pose data and/or ROI points on a frame (image).\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray): The raw frame.\n",
    "        pose (pandas.DataFrame): The pose data with \"class\" as a grouping column.\n",
    "        roi_coords (list[list[tuple[int, int]]]): A list of lists of tuples\n",
    "            representing the ROI x, y coordinates.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig = px.imshow(img)\n",
    "    if pose is not None:\n",
    "        scatter = px.scatter(\n",
    "            pose,\n",
    "            x=\"x\",\n",
    "            y=\"y\",\n",
    "            color=\"class\",\n",
    "            opacity=0.8,\n",
    "        )\n",
    "        for trace in scatter.data:\n",
    "            fig.add_trace(trace)\n",
    "    if roi_coords is not None:\n",
    "        for roi_coord in roi_coords:\n",
    "            pts = roi_coord + [roi_coord[0]]\n",
    "            xs, ys = zip(*pts)\n",
    "            fig.add_scatter(x=xs, y=ys, fill=\"toself\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_single_frame(\n",
    "    roots[0], social02.CameraTop.Video, pd.Timestamp(\"2024-02-18 11:00:00\")\n",
    ")\n",
    "plot_overlay(\n",
    "    img, pose=centroid_df_cp.loc[\"2024-02-18 11:00:00\":\"2024-02-18 11:01:31.860000134\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

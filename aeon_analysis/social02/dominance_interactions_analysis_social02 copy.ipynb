{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datajoint as dj\n",
    "import aeon\n",
    "from aeon.io import api\n",
    "from aeon.schema.schemas import social02\n",
    "from aeon.dj_pipeline.analysis.block_analysis import * \n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as sp\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import timedelta, datetime\n",
    "from scipy import stats\n",
    "from shapely.geometry import Point, Polygon\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment to analyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\"experiment_name\": \"social0.2-aeon3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena = 'AEON3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load social interaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace with revised csv path\n",
    "base_path = '/ceph/aeon/aeon/code/scratchpad/Orsi/'\n",
    "\n",
    "tube_test_path = f'all_tube_test_videos/{arena}_tube_tests_revised_final.csv'\n",
    "fights_path = f'all_fighting_videos/{arena}_fights.csv'\n",
    "chasing_path = f'all_chasing_videos/{arena}_chases.csv'\n",
    "\n",
    "# Open CSV containing tube test data.\n",
    "tube_test_df = pd.read_csv(base_path + tube_test_path)\n",
    "# Open CSV containing fighting data.\n",
    "fights_df = pd.read_csv(base_path + fights_path)\n",
    "# Open CSV containing chasing data.\n",
    "chasing_df = pd.read_csv(base_path + chasing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up social interaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the start and end timestamps to datetime\n",
    "chasing_df['start_timestamp'] = pd.to_datetime(chasing_df['start_timestamp'], format='%Y-%m-%dT%H-%M-%S')\n",
    "chasing_df['end_timestamp'] = pd.to_datetime(chasing_df['end_timestamp'], format='%Y-%m-%dT%H-%M-%S')\n",
    "\n",
    "fights_df['start_timestamp'] = pd.to_datetime(fights_df['start_timestamp'], format='%Y-%m-%dT%H-%M-%S')\n",
    "fights_df['end_timestamp'] = pd.to_datetime(fights_df['end_timestamp'], format='%Y-%m-%dT%H-%M-%S')\n",
    "\n",
    "tube_test_df['start_timestamp'] = pd.to_datetime(tube_test_df['start_timestamp'], format='%Y-%m-%dT%H-%M-%S')\n",
    "tube_test_df['end_timestamp'] = pd.to_datetime(tube_test_df['end_timestamp'], format='%Y-%m-%dT%H-%M-%S')\n",
    "\n",
    "# Add a 'behavior_type' column to each data frame\n",
    "chasing_df['behavior_type'] = 'chasing'\n",
    "fights_df['behavior_type'] = 'fighting'\n",
    "tube_test_df['behavior_type'] = 'tube_test'\n",
    "\n",
    "#remane colunms to domiant_id\n",
    "chasing_df.rename(columns={'chaser_id': 'dominant_id'}, inplace=True)\n",
    "tube_test_df.rename(columns={'winner_id': 'dominant_id'}, inplace=True)\n",
    "fights_df['dominant_id'] = fights_df.get('dominant_id', 'NaN')\n",
    "\n",
    "# Combine the data frames\n",
    "combined_df = pd.concat([chasing_df, fights_df, tube_test_df])\n",
    "# Replace NaN values in 'dominant_id' with a string 'NaN'\n",
    "combined_df['dominant_id'] = combined_df['dominant_id'].fillna('NaN')\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add pre/post tubetest data manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data\n",
    "pre_tube_test = {\n",
    "    'behavior_type': ['pre_tube_test'] * 10,\n",
    "    'dominant_id': ['BAA-1104045'] * 2 + ['BAA-1104047'] * 8\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "pre_tube_test = pd.DataFrame(pre_tube_test)\n",
    "\n",
    "\n",
    "# Create the data\n",
    "post_tube_test = {\n",
    "    'behavior_type': ['pre_tube_test'] * 10,\n",
    "    'dominant_id': ['BAA-1104045'] * 1 + ['BAA-1104047'] * 9\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "post_tube_test = pd.DataFrame(post_tube_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata like info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get start an edn as first and last block start\n",
    "first_block_start = (BlockAnalysis() & key).fetch()['block_start'][0]\n",
    "last_block_start= (BlockAnalysis() & key).fetch()['block_start'][-1]\n",
    "# Calculate the start/end of the same day\n",
    "experiment_start = datetime(first_block_start.year, first_block_start.month, first_block_start.day, 0, 0, 0)\n",
    "experiment_end = datetime(last_block_start.year, last_block_start.month, last_block_start.day+1, 0, 0, 0)\n",
    "experiment_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: find out where to get this from data, now its manual\n",
    "pre_solo_start = experiment_start\n",
    "pre_solo_end = datetime.strptime('2024-02-09 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "social_start =  datetime.strptime('2024-02-09 00:00:00', '%Y-%m-%d %H:%M:%S') \n",
    "social_end = datetime.strptime('2024-02-24 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "post_solo_start = datetime.strptime('2024-02-25 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "post_solo_end = experiment_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids of the animals\n",
    "unique_ids = np.unique(combined_df['dominant_id'])\n",
    "unique_ids = unique_ids[unique_ids != 'NaN']\n",
    "unique_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define light cycle periods\n",
    "night_start = '08:00'\n",
    "night_end = '19:00'\n",
    "twilight_start = '07:00'\n",
    "twilight_end = '08:00'\n",
    "dawn_start = '19:00'\n",
    "dawn_end = '20:00'\n",
    "day_start = '20:00'\n",
    "day_end = '07:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metadata base on fist solo block using api\n",
    "metadata = (\n",
    "    api.load(f'/ceph/aeon/aeon/data/raw/{arena}/social0.2', social02.Metadata, experiment_start, first_block_start).iloc[0].metadata\n",
    ")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting style settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for color mapping\n",
    "id_color_map = {\n",
    "    'NaN': 'grey',\n",
    "    unique_ids[1]: 'purple',\n",
    "    unique_ids[0]: 'green'\n",
    "} \n",
    "behaviour_map = {\n",
    "    'chasing': 'blue',\n",
    "    'fighting': 'red',\n",
    "    'tube_test': 'orange'\n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Temporal pattern and stability of dominance interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the raster plot\n",
    "fig = px.scatter(\n",
    "    combined_df,\n",
    "    x='start_timestamp',\n",
    "    y='behavior_type',\n",
    "    color='dominant_id',\n",
    "    title='Behavior Raster Plot',\n",
    "    labels={'start_timestamp': 'Time', 'behavior_type': 'Behavior Type'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Set x-axis limits\n",
    "fig.update_xaxes(range=[social_start, social_end])\n",
    "# Set x-axis limits\n",
    "fig.update_yaxes(range=[-1.5, 2.5])  # Example date range\n",
    "\n",
    "# Iterate over each day in the two-week period\n",
    "# Iterate over each day in the two-week period\n",
    "current_day = social_start\n",
    "while current_day < social_end:\n",
    "    # Define the start and end times for each period\n",
    "    night_start_time = current_day.replace(hour=int(night_start.split(':')[0]), minute=int(night_start.split(':')[1]))\n",
    "    night_end_time = current_day.replace(hour=int(night_end.split(':')[0]), minute=int(night_end.split(':')[1]))\n",
    "    twilight_start_time = current_day.replace(hour=int(twilight_start.split(':')[0]), minute=int(twilight_start.split(':')[1]))\n",
    "    twilight_end_time = current_day.replace(hour=int(twilight_end.split(':')[0]), minute=int(twilight_end.split(':')[1]))\n",
    "    dawn_start_time = current_day.replace(hour=int(dawn_start.split(':')[0]), minute=int(dawn_start.split(':')[1]))\n",
    "    dawn_end_time = current_day.replace(hour=int(dawn_end.split(':')[0]), minute=int(dawn_end.split(':')[1]))\n",
    "    day_start_time = current_day.replace(hour=int(day_start.split(':')[0]), minute=int(day_start.split(':')[1]))\n",
    "    \n",
    "    # Calculate day_end_time correctly\n",
    "    if int(day_end.split(':')[0]) < int(day_start.split(':')[0]):\n",
    "        day_end_time = current_day + timedelta(days=1)\n",
    "        day_end_time = day_end_time.replace(hour=int(day_end.split(':')[0]), minute=int(day_end.split(':')[1]))\n",
    "    else:\n",
    "        day_end_time = current_day.replace(hour=int(day_end.split(':')[0]), minute=int(day_end.split(':')[1]))\n",
    "\n",
    "    # Add horizontal lines for light and dark periods\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=twilight_start_time,\n",
    "        x1=twilight_end_time,\n",
    "        y0=-1,\n",
    "        y1=-1,\n",
    "        line=dict(color=\"gray\", width=4)\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=night_start_time,\n",
    "        x1=night_end_time,\n",
    "        y0=-1,\n",
    "        y1=-1,\n",
    "        line=dict(color=\"black\", width=4)\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=dawn_start_time,\n",
    "        x1=dawn_end_time,\n",
    "        y0=-1,\n",
    "        y1=-1,\n",
    "        line=dict(color=\"gray\", width=4)\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=day_start_time,\n",
    "        x1=day_end_time,\n",
    "        y0=-1,\n",
    "        y1=-1,\n",
    "        line=dict(color=\"white\", width=4)\n",
    "    )\n",
    "    \n",
    "    # Move to the next day\n",
    "    current_day += timedelta(days=1)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of time bins\n",
    "time_bins = pd.date_range(start=social_start, end=social_end, freq='24h')\n",
    "\n",
    "# Bin the start_timestamp into the created time bins\n",
    "combined_df['time_bin'] = pd.cut(combined_df['start_timestamp'], bins=time_bins)\n",
    "\n",
    "# Calculate the number of interactions for each behavior in each time bin\n",
    "interaction_counts = combined_df.groupby(['time_bin', 'behavior_type']).size().reset_index(name='total_interactions')\n",
    "\n",
    "# Convert the time_bin column to strings\n",
    "# Extract the start time of each bin\n",
    "interaction_counts['time_bin_start'] = interaction_counts['time_bin'].apply(lambda x: x.left)\n",
    "\n",
    "# Convert the start time to a string format\n",
    "interaction_counts['time_bin_start'] = interaction_counts['time_bin_start'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# Create the line plot\n",
    "fig = px.line(\n",
    "    interaction_counts,\n",
    "    x='time_bin_start',\n",
    "    y='total_interactions',\n",
    "    color='behavior_type',\n",
    "    title='Number of Interactions Over Time for Each Behavior',\n",
    "    labels={'time_bin_start': 'Time Bin', 'total_interactions': 'Number of Interactions'},\n",
    "    color_discrete_map=behaviour_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of winning for chasing\n",
    "chaser_counts_chasing = chasing_df['dominant_id'].value_counts(normalize=True).reset_index()\n",
    "chaser_counts_chasing.columns = ['dominant_id', 'p_wins']\n",
    "chaser_counts_chasing['behavior_type'] = 'Chasing'\n",
    "\n",
    "# Calculate the fraction of winning for tube test\n",
    "chaser_counts_tube_test = tube_test_df['dominant_id'].value_counts(normalize=True).reset_index()\n",
    "chaser_counts_tube_test.columns = ['dominant_id', 'p_wins']\n",
    "chaser_counts_tube_test['behavior_type'] = 'Tube Test'\n",
    "\n",
    "# Calculate the fraction of winning for pre tube test\n",
    "chaser_counts_pre_tube_test = pre_tube_test['dominant_id'].value_counts(normalize=True).reset_index()\n",
    "chaser_counts_pre_tube_test.columns = ['dominant_id', 'p_wins']\n",
    "chaser_counts_pre_tube_test['behavior_type'] = 'Pre Tube Test'\n",
    "\n",
    "# Calculate the fraction of winning for post tube test\n",
    "chaser_counts_post_tube_test = post_tube_test['dominant_id'].value_counts(normalize=True).reset_index()\n",
    "chaser_counts_post_tube_test.columns = ['dominant_id', 'p_wins']\n",
    "chaser_counts_post_tube_test['behavior_type'] = 'Post Tube Test'\n",
    "\n",
    "# Combine the data\n",
    "combined_counts = pd.concat([\n",
    "    chaser_counts_chasing, \n",
    "    chaser_counts_tube_test, \n",
    "    chaser_counts_pre_tube_test, \n",
    "    chaser_counts_post_tube_test\n",
    "])\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = px.scatter(\n",
    "    combined_counts,\n",
    "    x='behavior_type',\n",
    "    y='p_wins',\n",
    "    color='dominant_id',\n",
    "    title='Dominance per Behavior Type and Dominant ID',\n",
    "    labels={'behavior_type': 'Behavior Type', 'p_wins': 'Proportion of wins'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[0, 1])  # Example date range\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate te number of winning events over all events for every 42h time bin and plot over time\n",
    "# Create a list of time bins\n",
    "time_bins = pd.date_range(start=social_start, end=social_end, freq='24h')\n",
    "\n",
    "# Bin the start_timestamp into the created time bins\n",
    "tube_test_df['time_bin'] = pd.cut(tube_test_df['start_timestamp'], bins=time_bins)\n",
    "\n",
    "# Calculate the number of winning events and total events in each time bin and id\n",
    "winning_counts = tube_test_df.groupby(['time_bin', 'dominant_id']).size().reset_index(name='total_events')\n",
    "\n",
    "# Calculate the fraction of winning events for each dominant_id in each time bin\n",
    "winning_counts['fraction_winning'] = winning_counts.groupby('time_bin')['total_events'].transform(lambda x: x / x.sum())\n",
    "\n",
    "# Create a new column for day numbers starting from 1\n",
    "winning_counts['day_number'] = winning_counts['time_bin'].cat.codes + 1\n",
    "\n",
    "# Create the line plot for total events\n",
    "fig = px.line(\n",
    "    winning_counts,\n",
    "    x='day_number',\n",
    "    y='total_events',\n",
    "    color='dominant_id',\n",
    "    title='Winning Events Over Time (Tube test)',\n",
    "    labels={'day_number': 'Day Number', 'total_events': 'Winning Events'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Create the line plot for fraction of winning events\n",
    "fig = px.line(\n",
    "    winning_counts,\n",
    "    x='day_number',\n",
    "    y='fraction_winning',\n",
    "    color='dominant_id',\n",
    "    title='Fraction of Winning Events Over Time (Tube test)',\n",
    "    labels={'day_number': 'Day Number', 'fraction_winning': 'Proportion of Winning Events'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Create a list of time bins\n",
    "time_bins = pd.date_range(start=social_start, end=social_end, freq='24h')\n",
    "\n",
    "# Bin the start_timestamp into the created time bins\n",
    "chasing_df['time_bin'] = pd.cut(chasing_df['start_timestamp'], bins=time_bins)\n",
    "\n",
    "# Calculate the number of winning events and total events in each time bin and id\n",
    "winning_counts = chasing_df.groupby(['time_bin', 'dominant_id']).size().reset_index(name='total_events')\n",
    "\n",
    "# Calculate the fraction of winning events for each dominant_id in each time bin\n",
    "winning_counts['fraction_winning'] = winning_counts.groupby('time_bin')['total_events'].transform(lambda x: x / x.sum())\n",
    "\n",
    "# Create a new column for day numbers starting from 1\n",
    "winning_counts['day_number'] = winning_counts['time_bin'].cat.codes + 1\n",
    "\n",
    "# Create the line plot for total events\n",
    "fig = px.line(\n",
    "    winning_counts,\n",
    "    x='day_number',\n",
    "    y='total_events',\n",
    "    color='dominant_id',\n",
    "    title='Winning Events Over Time (Chasing)',\n",
    "    labels={'day_number': 'Day Number', 'total_events': 'Winning Events'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Create the line plot for fraction of winning events\n",
    "fig = px.line(\n",
    "    winning_counts,\n",
    "    x='day_number',\n",
    "    y='fraction_winning',\n",
    "    color='dominant_id',\n",
    "    title='Fraction of Winning Events Over Time (Chasing)',\n",
    "    labels={'day_number': 'Day Number', 'fraction_winning': 'Proportion of Winning Events'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate te number of winning events over all events for every 42h time bin and plot over time\n",
    "# Create a list of time bins\n",
    "time_bins = pd.date_range(start=social_start, end=social_end, freq='24h')\n",
    "# Bin the start_timestamp into the created time bins\n",
    "tube_test_df['time_bin'] = pd.cut(tube_test_df['start_timestamp'], bins=time_bins)\n",
    "# Calculate the number of winning events and total events in each time bin and id\n",
    "winning_counts = tube_test_df.groupby(['time_bin', 'dominant_id']).size().reset_index(name='total_events')\n",
    "# Calculate the fraction of winning events for each dominant_id in each time bin\n",
    "winning_counts['fraction_winning'] = winning_counts.groupby('time_bin')['total_events'].transform(lambda x: x / x.sum())\n",
    "\n",
    "# Convert the time_bin column to strings\n",
    "winning_counts['time_bin'] = winning_counts['time_bin'].astype(str)\n",
    "\n",
    "\n",
    "# Create the line plot\n",
    "fig = px.line(\n",
    "    winning_counts,\n",
    "    x='time_bin',\n",
    "    y='total_events',\n",
    "    color = 'dominant_id',\n",
    "    title='Winning Events Over Time (Tube test)',\n",
    "    labels={'time_bin': 'Time Bin', 'total_events': 'Winning Events'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Create the line plot\n",
    "fig = px.line(\n",
    "    winning_counts,\n",
    "    x='time_bin',\n",
    "    y='fraction_winning',\n",
    "    color = 'dominant_id',\n",
    "    title='Fraction of Winning Events Over Time (Tube test)',\n",
    "    labels={'time_bin': 'Time Bin', 'fraction_winning': 'Proportion of Winning Events'},\n",
    "    color_discrete_map=id_color_map\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Chasing speed and dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: we should do id swapping cleaning bfore calculating this (hope is that it doesnt matter much cuz two animals are pretty close to each other and synchronised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get this data if already calcuklated, if not calcualte here, but will ake a while\n",
    "chasing_speed_data = pd.read_csv(base_path + '/all_chasing_videos/chasing_speed.csv')\n",
    "chasing_speed_data\n",
    "\n",
    "if chasing_speed_data.empty:\n",
    "    print('No chasing speed data available')\n",
    "    #get centroid data during chasing events\n",
    "    block_subjects = (\n",
    "        BlockAnalysis.Subject.proj('position_x', 'position_y', 'position_timestamps')\n",
    "        & key\n",
    "        & f'block_start >= \"{social_start}\"'\n",
    "        & f'block_start <= \"{social_end}\"'\n",
    "    )\n",
    "    block_subjects_dict = block_subjects.fetch(as_dict=True)\n",
    "    \n",
    "    # Convert chasing_df timestamps to datetime\n",
    "    chasing_df['start_timestamp'] = pd.to_datetime(chasing_df['start_timestamp'])\n",
    "    chasing_df['end_timestamp'] = pd.to_datetime(chasing_df['end_timestamp'])\n",
    "\n",
    "    # Initialize an empty list to store the filtered position data\n",
    "    filtered_positions = []\n",
    "\n",
    "    # Loop through each row in chasing_df so we only get position that are within a chase\n",
    "    for _, row in chasing_df.iterrows():\n",
    "        start_time = row['start_timestamp']\n",
    "        end_time = row['end_timestamp']\n",
    "        \n",
    "        # Filter the position data for each subject\n",
    "        for s in block_subjects_dict:\n",
    "            # Convert position timestamps to datetime\n",
    "            position_timestamps = pd.to_datetime(s['position_timestamps'])\n",
    "            \n",
    "            # Filter based on the start and end timestamps\n",
    "            mask = (position_timestamps >= start_time) & (position_timestamps <= end_time)\n",
    "            \n",
    "            # Create a DataFrame for the filtered data\n",
    "            filtered_data = pd.DataFrame(\n",
    "        {\n",
    "                    \"subject_name\": [s[\"subject_name\"]] * sum(mask),\n",
    "                    \"position_timestamps\": position_timestamps[mask],\n",
    "                    \"position_x\": pd.Series(s[\"position_x\"])[mask].values,\n",
    "                    \"position_y\": pd.Series(s[\"position_y\"])[mask].values,\n",
    "                    \"start_time\": [start_time] * sum(mask),\n",
    "                    \"end_time\": [end_time] * sum(mask)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Append the filtered data to the list\n",
    "            filtered_positions.append(filtered_data)\n",
    "\n",
    "    # Concatenate the list of filtered data into a single DataFrame\n",
    "    subjects_positions_df = pd.concat(filtered_positions)\n",
    "    \n",
    "    # Calculate the avg speed of each chasing event\n",
    "    # calculate the distance travelled by each subject and divide by the duration of chase\n",
    "    subjects_positions_df[\"speed\"] = (\n",
    "        subjects_positions_df.groupby(\"subject_name\")[[\"position_x\", \"position_y\"]].diff().apply(np.linalg.norm, axis=1)\n",
    "        / subjects_positions_df.reset_index()\n",
    "        .groupby(\"subject_name\")[\"position_timestamps\"]\n",
    "        .diff()\n",
    "        .dt.total_seconds()\n",
    "        .values\n",
    "    )\n",
    "    chasing_speed_data = subjects_positions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of nans, unrealistically high speeds and infs\n",
    "cm2px = 5.4 \n",
    "max_speed_threshold = 100 * cm2px # in cm/s\n",
    "chasing_speed_data = chasing_speed_data[chasing_speed_data['speed'] < max_speed_threshold]\n",
    "chasing_speed_data = chasing_speed_data[~chasing_speed_data['speed'].isna()]\n",
    "chasing_speed_data = chasing_speed_data[~chasing_speed_data['speed'].isin([np.inf, -np.inf])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average speed per chase\n",
    "# Step 1: Group speed_df by 'chase_id' and 'subject_name' to calculate avg speed per subject per chase\n",
    "avg_speed_per_subject = (\n",
    "    chasing_speed_data.groupby(['start_time', 'subject_name'])['speed']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'speed': 'avg_speed_per_subject'})\n",
    ")\n",
    "\n",
    "# Step 2: Now, group again by 'chase_id' to average over the subjects' average speeds\n",
    "avg_speed_per_chase = (\n",
    "    avg_speed_per_subject.groupby('start_time')['avg_speed_per_subject']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'avg_speed_per_subject': 'avg_speed_per_chase'})\n",
    ")\n",
    "avg_speed_per_chase.rename(columns={'start_time': 'start_timestamp'}, inplace=True)\n",
    "\n",
    "#merge back inot chase df\n",
    "chasing_df['start_timestamp'] = pd.to_datetime(chasing_df['start_timestamp'])\n",
    "avg_speed_per_chase['start_timestamp'] = pd.to_datetime(avg_speed_per_chase['start_timestamp'])\n",
    "avg_chasing_speed_df = chasing_df.merge(avg_speed_per_chase, on='start_timestamp', how='left')\n",
    "#get rid of rows whre missings speed\n",
    "avg_chasing_speed_df = avg_chasing_speed_df[~avg_chasing_speed_df['avg_speed_per_chase'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the speed of chases per chaser id\n",
    "# Initialize the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for dominant_id in avg_chasing_speed_df['dominant_id'].unique():\n",
    "    if pd.isna(dominant_id):\n",
    "        color = 'gray'  # Assign a default color for NaN values\n",
    "    else:\n",
    "        color = id_color_map.get(dominant_id, 'black')  # Fallback to black if the id is not in the map\n",
    "    \n",
    "    dominant_df = avg_chasing_speed_df[avg_chasing_speed_df['dominant_id'] == dominant_id]\n",
    "    fig.add_trace(go.Box(\n",
    "        x=dominant_df['dominant_id'],\n",
    "        y=dominant_df['avg_speed_per_chase'],\n",
    "        name=str(dominant_id),  # Convert NaN to string to display properly\n",
    "        boxpoints='all',  # Show individual points\n",
    "        jitter=0.3,  # Add some jitter to avoid overlap\n",
    "        pointpos=-1.8,  # Position of the individual points (to the right of the box)\n",
    "        marker=dict(color=color)\n",
    "    ))\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Average Speed of Chases per Chaser ID',\n",
    "    xaxis_title='Chaser ID',\n",
    "    yaxis_title='Average Speed',\n",
    "    boxmode='group',  # Group box plots by chaser ID\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Filter data for the two chaser IDs\n",
    "chaser1_speeds = avg_chasing_speed_df[avg_chasing_speed_df['dominant_id'] == unique_ids[0]]['avg_speed_per_chase']\n",
    "chaser2_speeds = avg_chasing_speed_df[avg_chasing_speed_df['dominant_id'] == unique_ids[1]]['avg_speed_per_chase']\n",
    "\n",
    "# Perform the t-test\n",
    "t_stat, p_value_ttest = stats.ttest_ind(chaser1_speeds, chaser2_speeds, equal_var=False)\n",
    "\n",
    "\n",
    "# Add annotations for statistical test results\n",
    "fig.add_annotation(\n",
    "    x=0.5, y=1.05, xref='paper', yref='paper',\n",
    "    text=f\"T-test p-value: {p_value_ttest:.3f}\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12, color='black'),\n",
    "    align='center'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dominance and foraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign dominant id\n",
    "# Calculate the frequency of each dominant_id in combined_df\n",
    "dominant_id_counts = combined_df['dominant_id'].value_counts()\n",
    "# Identify the dominant_id with the highest frequency\n",
    "dominant_id = dominant_id_counts.idxmax()\n",
    "subordinate_id = unique_ids[0] if unique_ids[0] != dominant_id else unique_ids[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get foraging data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pellet data\n",
    "foraging_query = (\n",
    "    BlockSubjectAnalysis.Patch.proj('pellet_count', 'pellet_timestamps', 'patch_threshold')\n",
    "    & {\"spinnaker_video_source_name\": \"CameraTop\"} #this is the video source name which we rstrict once we selected tuff to keep in table\n",
    "    & key)\n",
    "\n",
    "# Fetch the data\n",
    "pellet_data = foraging_query.fetch()\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each entry in the pellet_data array\n",
    "for entry in pellet_data:\n",
    "    experiment_name = entry[0]\n",
    "    block_start = entry[1]\n",
    "    patch_name = entry[2]\n",
    "    subject_id = entry[3]\n",
    "    pellet_count = entry[4]\n",
    "    pellet_timestamps = entry[5]\n",
    "    patch_threshold =  entry[6]\n",
    "\n",
    "    \n",
    "    # For each pellet timestamp, create a dictionary and append to the list\n",
    "    for pellet_timestamp, threshold in zip(pellet_timestamps, patch_threshold):\n",
    "        pellet_timestamp = pd.to_datetime(pellet_timestamp)\n",
    "        # Determine the period based on the timestamp\n",
    "        if pre_solo_start <= pellet_timestamp <= pre_solo_end:\n",
    "            period = 'pre_solo'\n",
    "        elif social_start <= pellet_timestamp <= social_end:\n",
    "            period = 'social'\n",
    "        elif post_solo_start <= pellet_timestamp <= post_solo_end:\n",
    "            period = 'post_solo'\n",
    "        else:\n",
    "            ValueError(f\"Timestamp {pellet_timestamp} does not fall within any period\")\n",
    "\n",
    "        data.append({\n",
    "            'time': pellet_timestamp,\n",
    "            'subject_id': subject_id,\n",
    "            'threshold': threshold,\n",
    "            'rank': 'dominant' if subject_id == dominant_id else 'subordinate',\n",
    "            'period': period\n",
    "        })\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "pellet_df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'time' column to datetime\n",
    "pellet_df['time'] = pd.to_datetime(pellet_df['time'])\n",
    "\n",
    "# data cleaning: filter out pellets that are less than 2s after previos pellet for teh subject\n",
    "pellet_df['time_diff'] = pellet_df.groupby('subject_id')['time'].diff()\n",
    "pellet_df['time_diff'] = pellet_df['time_diff'].dt.total_seconds()\n",
    "pellet_df = pellet_df[pellet_df['time_diff'] > 2]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(pellet_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raster_plot(df, id_color_map):\n",
    "    # Create subplots: two for pre_solo, two for post_solo, and one for social\n",
    "    fig = make_subplots(\n",
    "        rows=5, cols=1, shared_xaxes=False,\n",
    "        subplot_titles=(f'Pre Solo - {unique_ids[0]}', f'Pre Solo - {unique_ids[1]}', f'Post Solo - {unique_ids[0]}', f'Post Solo - {unique_ids[1]}', 'Social')\n",
    "    )\n",
    "\n",
    "    # Filter the DataFrame for pre_solo, post_solo, and social periods\n",
    "    pre_solo_df = df[df['period'] == 'pre_solo']\n",
    "    post_solo_df = df[df['period'] == 'post_solo']\n",
    "    social_df = df[df['period'] == 'social']\n",
    "\n",
    "    # Create scatter plots for each period if the DataFrame is not empty\n",
    "    if not pre_solo_df.empty:\n",
    "        for subject_id in pre_solo_df['subject_id'].unique():\n",
    "            subject_df = pre_solo_df[pre_solo_df['subject_id'] == subject_id]\n",
    "            pre_solo_scatter = px.scatter(\n",
    "                subject_df,\n",
    "                x='time',\n",
    "                y='subject_id',\n",
    "                color='subject_id',\n",
    "                labels={'time': 'Time'},\n",
    "                color_discrete_map=id_color_map\n",
    "            ).data[0]\n",
    "            pre_solo_scatter.showlegend = False\n",
    "            row = 1 if subject_id == unique_ids[0] else 2\n",
    "            fig.add_trace(pre_solo_scatter, row=row, col=1)\n",
    "\n",
    "    if not post_solo_df.empty:\n",
    "        for subject_id in post_solo_df['subject_id'].unique():\n",
    "            subject_df = post_solo_df[post_solo_df['subject_id'] == subject_id]\n",
    "            post_solo_scatter = px.scatter(\n",
    "                subject_df,\n",
    "                x='time',\n",
    "                y='subject_id',\n",
    "                color='subject_id',\n",
    "                labels={'time': 'Time'},\n",
    "                color_discrete_map=id_color_map\n",
    "            ).data[0]\n",
    "            post_solo_scatter.showlegend = False\n",
    "            row = 3 if subject_id == unique_ids[0] else 4\n",
    "            fig.add_trace(post_solo_scatter, row=row, col=1)\n",
    "        \n",
    "    if not social_df.empty:\n",
    "        for subject_id in social_df['subject_id'].unique():\n",
    "            subject_df = social_df[social_df['subject_id'] == subject_id]\n",
    "            social_scatter = px.scatter(\n",
    "                subject_df,\n",
    "                x='time',\n",
    "                y='subject_id',\n",
    "                color='subject_id',\n",
    "                labels={'time': 'Time'},\n",
    "                color_discrete_map=id_color_map\n",
    "            ).data[0]\n",
    "            fig.add_trace(social_scatter, row=5, col=1)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text='Pellet Raster Plots',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    # Remove y-axis labels\n",
    "    for i in range(1, 6):\n",
    "        fig.update_yaxes(title_text='', row=i, col=1)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# Create the raster plot for pre_solo, post_solo, and social periods\n",
    "create_raster_plot(pellet_df, id_color_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aeon)",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

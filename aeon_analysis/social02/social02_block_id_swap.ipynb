{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from aeon.dj_pipeline import acquisition, fetch_stream, streams, tracking\n",
    "from aeon.dj_pipeline.analysis import block_analysis\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-04 11:02:59,724][WARNING]: MySQL server has gone away. Reconnecting to the server.\n"
     ]
    }
   ],
   "source": [
    "# choose one block key\n",
    "key = {\"experiment_name\": \"social0.2-aeon3\",\n",
    "       \"block_start\": \"2024-02-11 13:36:10\"}\n",
    "block_start, block_end = (block_analysis.Block & key).fetch1(\n",
    "    \"block_start\", \"block_end\")\n",
    "\n",
    "chunk_restriction = acquisition.create_chunk_restriction(\n",
    "    key[\"experiment_name\"], block_start, block_end\n",
    ")\n",
    "\n",
    "# retrieve `pos_df` for ALL subjects in this block\n",
    "pos_query = (\n",
    "    streams.SpinnakerVideoSource\n",
    "    * tracking.SLEAPTracking.PoseIdentity.proj(\"identity_name\", anchor_part=\"part_name\")\n",
    "    * tracking.SLEAPTracking.Part\n",
    "    & key\n",
    "    & {\n",
    "        \"spinnaker_video_source_name\": \"CameraTop\",\n",
    "    }\n",
    "    & chunk_restriction\n",
    ")\n",
    "all_pos_df = fetch_stream(pos_query).sort_index()[block_start:block_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Standardize subject colors for plotting\"\"\"\n",
    "\n",
    "subject_colors = px.colors.qualitative.Plotly\n",
    "subject_colors_dict = {\n",
    "    name: subject_colors[i]\n",
    "    for i, name in enumerate(all_pos_df[\"identity_name\"].unique())\n",
    "}\n",
    "\n",
    "\n",
    "def plot_xy(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"Plot the x and y positions of each subject.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with columns ``x``,\n",
    "            ``y``, and ``identity_name``.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs.Figure: Plotly figure object with\n",
    "            x and y positions of each subject.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "    names = df[\"identity_name\"].unique()\n",
    "    for identity_name in names:\n",
    "        data = df[df[\"identity_name\"] == identity_name]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index,\n",
    "                y=data[\"x\"],\n",
    "                mode=\"markers\",\n",
    "                name=identity_name,  # Use the class as the name of the trace\n",
    "                marker=dict(color=subject_colors_dict[identity_name], symbol=\"circle\"),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index,\n",
    "                y=data[\"y\"],\n",
    "                mode=\"markers\",\n",
    "                name=identity_name,  # Use the class as the name of the trace\n",
    "                marker=dict(color=subject_colors_dict[identity_name], symbol=\"square\"),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "    fig.update_yaxes(title_text=\"x position\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"y position\", row=2, col=1)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def resolve_duplicate_identities(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reassign ID of the row with duplicated ID and lower likelihood.\n",
    "\n",
    "    This function checks for duplicated ``identity_name`` for each\n",
    "    unique DatetimeIndex, and randomly assigns another\n",
    "    ``identity_name`` from the available identity names in the\n",
    "    DataFrame to the row having duplicated identity and lower\n",
    "    likelihood. This function is useful in a 2-subject case, but\n",
    "    is not guaranteed to work in a >2-subject case.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with columns\n",
    "            ``identity_name`` and ``likelihood``.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame without duplicate identities\n",
    "            per unique DatetimeIndex.\n",
    "    \"\"\"\n",
    "    df_cp = df.reset_index().copy()\n",
    "    names = df_cp[\"identity_name\"].unique()\n",
    "    # Mask for rows with multiple assignments of the same ID at the same time\n",
    "    many_to_one_mask = df_cp.groupby([\"time\", \"identity_name\"]).transform(\"size\") > 1\n",
    "    duplicated_data = df_cp.loc[many_to_one_mask]\n",
    "    # Indices for rows with lower likelihood\n",
    "    low_likelihood_idx = duplicated_data.loc[\n",
    "        ~duplicated_data.index.isin(\n",
    "            duplicated_data.groupby([\"time\", \"identity_name\"])[\"likelihood\"].idxmax()\n",
    "        )\n",
    "    ].index\n",
    "    # This assigns another class randomly (in 2-animal case, it's the other animal,\n",
    "    # but in >2-animal case, it may assign duplicate IDs again)\n",
    "    df_cp.loc[low_likelihood_idx, \"identity_name\"] = df_cp.loc[\n",
    "        low_likelihood_idx\n",
    "    ].apply(lambda x: np.random.choice(names[names != x[\"identity_name\"]]), axis=1)\n",
    "    return df_cp.set_index(\"time\")\n",
    "\n",
    "\n",
    "def compute_class_speed(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Compute the instantaneous speed of each class.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with columns ``x``,\n",
    "            ``y``, ``identity_name``, and DatetimeIndex ``time``.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: Series with the instantaneous speed of each class.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.groupby(\"identity_name\")[[\"x\", \"y\"]].diff().apply(np.linalg.norm, axis=1)\n",
    "        / df.reset_index()\n",
    "        .groupby(\"identity_name\")[\"time\"]\n",
    "        .diff()\n",
    "        .dt.total_seconds()\n",
    "        .values\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_speed_mask(df: pd.DataFrame, threshold: float) -> pd.Series:\n",
    "    \"\"\"Compute the boolean mask of rows with ``speed`` exceeding threshold.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with columns ``speed``.\n",
    "        threshold (float): Speed threhold.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: Boolean mask of rows with ``speed`` greater\n",
    "            than threshold.\n",
    "    \"\"\"\n",
    "    speed_mask = (np.isfinite(df[\"speed\"].values)) & (df[\"speed\"] > threshold)\n",
    "    # select only rows when more than 1 subject has speed > threshold\n",
    "    speed_mask &= speed_mask.groupby(level=0).transform(\"sum\") > 1\n",
    "    return speed_mask\n",
    "\n",
    "\n",
    "def resolve_swapped_identities(\n",
    "    df: pd.DataFrame, threshold: float = 700.0, max_window_length: int = 6\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reassign ID of the row with identity swaps.\n",
    "\n",
    "    This function attempts to identify windows of identity swaps\n",
    "    based on pairs of speed \"violations\". The windows are incremented\n",
    "    by a factor of 2 each iteration, starting at a minimum\n",
    "    of 3s, up to the maximum duration specified by ``max_window_length``\n",
    "    seconds. Within each window, the identity of the subjects are\n",
    "    randomly assigned to the other subject's identity. This method\n",
    "    will not resolve all identity swaps, especially if the swaps occur\n",
    "    for extended durations. It also does not account for more than\n",
    "    2 subjects.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with columns ``x``,\n",
    "            ``y``, ``identity_name``, and DatetimeIndex ``time``.\n",
    "        threshold (float): Speed threshold. Default is 700.0.\n",
    "        max_window_length (int): Maximum duration in seconds for swapping\n",
    "            identities. Potential swaps spanning longer durations will be\n",
    "            ignored. Default is 6 seconds.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with resolved identity swaps within\n",
    "            the specified ``max_window_length``.\n",
    "    \"\"\"\n",
    "    df[\"speed\"] = compute_class_speed(df)\n",
    "    speed_mask = compute_speed_mask(df, threshold=threshold)\n",
    "    names = df[\"identity_name\"].unique()\n",
    "    timedelta = 3\n",
    "    iter = 0\n",
    "    # limit swap window duration to 3 * 2**(max_iter) = max_window_length seconds\n",
    "    max_iter = np.sqrt((max_window_length // 3) / 2)\n",
    "    while speed_mask.sum() > 2 and iter <= max_iter:\n",
    "        print(f\"Iteration {iter}: {speed_mask.sum()\n",
    "                                   } rows with speed > {threshold}\")\n",
    "        q = deque(df[speed_mask].index.unique())\n",
    "        while q:\n",
    "            start = q.popleft()\n",
    "            try:\n",
    "                end = q[0]\n",
    "            except IndexError:\n",
    "                break\n",
    "            # compute timedelta between start and end\n",
    "            # ignore if timedelta is more than t seconds\n",
    "            if (end - start) > pd.Timedelta(timedelta, unit=\"s\"):\n",
    "                continue\n",
    "            end = q.popleft()\n",
    "            # ``end`` needs to be exclusive\n",
    "            end = df.index[df.index < end].max()\n",
    "            df.loc[start:end, \"identity_name\"] = df.loc[start:end].apply(\n",
    "                lambda x: np.random.choice(names[names != x[\"identity_name\"]]), axis=1\n",
    "            )\n",
    "        # recompute speed and speed_mask\n",
    "        df[\"speed\"] = compute_class_speed(df)\n",
    "        speed_mask = compute_speed_mask(df, threshold=threshold)\n",
    "        # update timedelta\n",
    "        timedelta *= 2\n",
    "        # update iter count\n",
    "        iter += 1\n",
    "    return df.drop(columns=[\"speed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Resolve duplicate identities\n",
    "all_pos_df1 = resolve_duplicate_identities(all_pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 35282 rows with speed > 700.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Resolve swapped identities\n",
    "all_pos_df2 = resolve_swapped_identities(all_pos_df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEON\n",
    "#### create training dataset from aeon raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "import warnings\n",
    "import aeon\n",
    "import aeon.io.api as aeon_api\n",
    "\n",
    "from aeon.schema.schemas import exp02, social02\n",
    "from aeon.analysis.utils import *\n",
    "from dotmap import DotMap\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def get_experiment_times(\n",
    "    root: str | os.PathLike, start_time: pd.Timestamp, end_time: pd.Timestamp\n",
    ") -> DotMap:\n",
    "    \"\"\"\n",
    "    Retrieve experiment start and stop times from environment states\n",
    "    (i.e. times outside of maintenance mode) occurring within the\n",
    "    given start and end times.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path where epoch data is stored.\n",
    "        start_time (pandas.Timestamp): Start time.\n",
    "        end_time (pandas.Timestamp): End time.\n",
    "\n",
    "    Returns:\n",
    "        DotMap: A DotMap object containing two keys: 'start' and 'stop',\n",
    "        corresponding to pairs of experiment start and stop times.\n",
    "\n",
    "    Notes:\n",
    "    This function uses the last 'Maintenance' event (if available, otherwise\n",
    "    `end_time`) as the last 'Experiment' stop time. If the first retrieved state\n",
    "    is 'Maintenance' (e.g. 'Experiment' mode entered before `start_time`),\n",
    "    `start_time` is used as the first 'Experiment' start time.\n",
    "    \"\"\"\n",
    "\n",
    "    experiment_times = DotMap()\n",
    "    env_states = aeon.load(\n",
    "        root,\n",
    "        social02.Environment.EnvironmentState,\n",
    "        # aeon.io.reader.Csv(\"Environment_EnvironmentState_*\", [\"state\"]),\n",
    "        start_time,\n",
    "        end_time,\n",
    "    )\n",
    "    if env_states.empty:\n",
    "        warnings.warn(\n",
    "            \"The environment state df is empty. \"\n",
    "            \"Using input `start_time` and `end_time` as experiment times.\"\n",
    "        )\n",
    "        experiment_times.start = [start_time]\n",
    "        experiment_times.stop = [end_time]\n",
    "        return experiment_times\n",
    "    if env_states[\"state\"].iloc[-1] != \"Maintenance\":\n",
    "        warnings.warn(\n",
    "            \"No 'Maintenance' event at the end of the search range. \"\n",
    "            \"Using input `end_time` as last experiment stop time.\"\n",
    "        )\n",
    "        # Pad with a \"Maintenance\" event at the end\n",
    "        env_states = pd.concat(\n",
    "            [\n",
    "                env_states,\n",
    "                pd.DataFrame(\n",
    "                    \"Maintenance\",\n",
    "                    index=[end_time],\n",
    "                    columns=env_states.columns,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    # Use the last \"Maintenance\" event as end time\n",
    "    end_time = (env_states[env_states.state == \"Maintenance\"]).index[-1]\n",
    "    env_states = env_states[~env_states.index.duplicated(keep=\"first\")]\n",
    "    # Retain only events between visit start and stop times\n",
    "    env_states = env_states.iloc[\n",
    "        env_states.index.get_indexer([start_time], method=\"bfill\")[\n",
    "            0\n",
    "        ] : env_states.index.get_indexer([end_time], method=\"ffill\")[0]\n",
    "        + 1\n",
    "    ]\n",
    "    # Retain only events where state changes (experiment-maintenance pairs)\n",
    "    env_states = env_states[env_states[\"state\"].ne(env_states[\"state\"].shift())]\n",
    "    if env_states[\"state\"].iloc[0] == \"Maintenance\":\n",
    "        warnings.warn(\n",
    "            \"No 'Experiment' event at the start of the search range. \"\n",
    "            \"Using input `end_time` as last experiment stop time.\"\n",
    "        )\n",
    "        # Pad with an \"Experiment\" event at the start\n",
    "        env_states = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(\n",
    "                    \"Experiment\",\n",
    "                    index=[start_time],\n",
    "                    columns=env_states.columns,\n",
    "                ),\n",
    "                env_states,\n",
    "            ]\n",
    "        )\n",
    "    experiment_times.start = env_states[\n",
    "        env_states[\"state\"] == \"Experiment\"\n",
    "    ].index.values\n",
    "    experiment_times.stop = env_states[\n",
    "        env_states[\"state\"] == \"Maintenance\"\n",
    "    ].index.values\n",
    "\n",
    "    return experiment_times\n",
    "\n",
    "\n",
    "def exclude_maintenance_data(\n",
    "    data: pd.DataFrame, experiment_times: DotMap\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Excludes rows not in experiment times (i.e., corresponding to maintenance times)\n",
    "    from the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The data to filter. Expected to have a pandas.DateTimeIndex.\n",
    "        experiment_times (DotMap): A DotMap object containing experiment start and stop times.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing filtered data.\n",
    "    \"\"\"\n",
    "    filtered_data = pd.concat(\n",
    "        [\n",
    "            data.loc[start:stop]\n",
    "            for start, stop in zip(experiment_times.start, experiment_times.stop)\n",
    "        ]\n",
    "    )\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def get_raw_tracking_data(\n",
    "    root: str | os.PathLike,\n",
    "    subj_id: str,\n",
    "    start: pd.Timestamp,\n",
    "    end: pd.Timestamp,\n",
    "    source_reader: aeon.io.reader.Video = exp02.CameraTop.Video,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve pos tracking and video data and assigns subject ID.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path, or prioritised sequence of paths, where epoch data is stored.\n",
    "        subj_id (str): The subject ID string to be assigned.\n",
    "        start (pandas.Timestamp): The left bound of the time range to extract.\n",
    "        end (pandas.Timestamp): The right bound of the time range to extract.\n",
    "        source_reader (aeon.io.reader.Video, optional): The frame source reader. Default is exp02.CameraTop.Video.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "\n",
    "    subj_video = aeon_api.load(root, source_reader, start=start, end=end)\n",
    "    subj_pos = aeon_api.load(root, exp02.CameraTop.Position, start=start, end=end)\n",
    "    # replace \"raw\" in root with \"processed\"\n",
    "    processed_root = root.replace(\"raw\", \"processed\")\n",
    "    if subj_video.empty:\n",
    "        subj_video = aeon_api.load(processed_root, source_reader, start=start, end=end)\n",
    "        warnings.warn(\"subj_video is empty, retrieving data from processed\")\n",
    "    if subj_pos.empty:\n",
    "        subj_pos = aeon_api.load(\n",
    "            processed_root, exp02.CameraTop.Position, start=start, end=end\n",
    "        )\n",
    "        warnings.warn(\"subj_pos is empty, retrieving data from processed\")\n",
    "    subj_data = pd.merge_asof(\n",
    "        subj_video,\n",
    "        subj_pos,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        direction=\"nearest\",\n",
    "        tolerance=pd.Timedelta(\"1ms\"),\n",
    "    )[[\"x\", \"y\", \"id\", \"area\", \"_frame\", \"_path\"]]\n",
    "    subj_data.dropna(inplace=True)\n",
    "    subj_data[\"id\"] = subj_id\n",
    "\n",
    "    return subj_data\n",
    "\n",
    "\n",
    "def sample_n_from_bins(\n",
    "    subj_data: pd.DataFrame,\n",
    "    n_samples: int = 1,\n",
    "    n_bins: int = 50,\n",
    "    range: npt.ArrayLike = [[0, 1440], [0, 1080]],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uniformly samples n number of data from x number of bins.\n",
    "\n",
    "    Args:\n",
    "        subj_data (pandas.DataFrame): A pandas DataFrame containing pos tracking and video data, and subject ID.\n",
    "        n_samples (int, optional): The number of samples to take from each bin. Default is 1.\n",
    "        n_bins (int, optional): The number of bins to use for sampling. Default is 50.\n",
    "        range (list of lists, optional): The leftmost and rightmost edges of the bins along each dimension\n",
    "            (if not specified explicitly in the bins parameters): [[xmin, xmax], [ymin, ymax]]. All values\n",
    "            outside of this range will be considered outliers and not tallied in the histogram. Default is\n",
    "            [[0, 1440], [0, 1080]].\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing uniformly-sampled pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "\n",
    "    hist_data = stats.binned_statistic_2d(\n",
    "        subj_data.x,\n",
    "        subj_data.y,\n",
    "        values=subj_data,\n",
    "        statistic=\"count\",\n",
    "        bins=n_bins,\n",
    "        range=range,\n",
    "    )\n",
    "    subj_data[\"bin\"] = hist_data.binnumber\n",
    "    sampled_data = (\n",
    "        subj_data.groupby([\"bin\"]).sample(n=n_samples, replace=True).drop_duplicates()\n",
    "    )\n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "def create_session_dataset(\n",
    "    session: dict,\n",
    "    subj_ids: list = None,\n",
    "    plot_dist: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataset for a given session dict.\n",
    "    Args:\n",
    "        session (dict): A dictionary containing the root path, subject IDs, and their start and end times.\n",
    "        subj_ids (list, optional): A list of subject ids. If None, all subjects are selected.\n",
    "        plot_dist (bool, optional): Whether to plot the 1d and 2d histograms of x, y pos tracking for each subject.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas dataframe containing uniformly-sampled pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "    all_subj_data = pd.DataFrame()\n",
    "    if not subj_ids:\n",
    "        subj_ids = session[\"subjects\"].keys()\n",
    "    for subj in subj_ids:\n",
    "        subj_dict = {\n",
    "            \"id\": subj,\n",
    "            \"root\": session.get(\"root\", session[\"subjects\"][subj].get(\"root\")),\n",
    "            \"start\": session[\"subjects\"][subj][\"start\"],\n",
    "            \"end\": session[\"subjects\"][subj][\"end\"],\n",
    "        }\n",
    "        subj_data = (\n",
    "            create_subject_dataset(\n",
    "                subj_dict,\n",
    "                min_area=500,\n",
    "                n_samples=4,\n",
    "                n_bins=10,\n",
    "            )  # sample fewer points for manual annotation\n",
    "            if \"multi_\" in subj\n",
    "            else create_subject_dataset(\n",
    "                subj_dict,\n",
    "            )\n",
    "        )\n",
    "        all_subj_data = pd.concat([all_subj_data, subj_data])\n",
    "    if plot_dist:\n",
    "        fig = plot_position_histograms(all_subj_data)\n",
    "        fig.show()\n",
    "    return all_subj_data\n",
    "\n",
    "\n",
    "def plot_position_histograms(data: pd.DataFrame, n_bins: int = 50) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plots the 1d and 2d histograms of x, y pos tracking for each subject in a given DataFrame.\n",
    "    Args:\n",
    "        data (pandas.DataFrame): A pandas DataFrame containing x, y pos tracking and subject ID(s).\n",
    "        n_bins (int, optional): The number of bins to use for plotting histograms. Default is 50.\n",
    "    Returns:\n",
    "        matplotlib.pyplot: A plot containing 1d and 2d histograms of x, y pos tracking for each subject.\n",
    "    \"\"\"\n",
    "    subj_ids = data[\"id\"].unique()\n",
    "    fig, ax = plt.subplots(2, len(subj_ids))\n",
    "    n_bins = 50\n",
    "    if len(subj_ids) == 1:\n",
    "        data[[\"x\", \"y\"]].plot.hist(bins=n_bins, alpha=0.5, ax=ax[0], title=subj_ids[0])\n",
    "        ax[1].hist2d(\n",
    "            data.x,\n",
    "            data.y,\n",
    "            bins=(n_bins, n_bins),\n",
    "            cmap=plt.cm.jet,\n",
    "        )\n",
    "    else:\n",
    "        for i, subj_id in enumerate(subj_ids):\n",
    "            subj_data = data[data[\"id\"] == subj_id]\n",
    "            subj_data[[\"x\", \"y\"]].plot.hist(\n",
    "                bins=n_bins, alpha=0.5, ax=ax[0, i], title=subj_id\n",
    "            )\n",
    "            ax[1, i].hist2d(\n",
    "                subj_data.x, subj_data.y, bins=(n_bins, n_bins), cmap=plt.cm.jet\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_subject_dataset(\n",
    "    subject: dict,\n",
    "    min_area: float = None,\n",
    "    n_samples: int = 1,\n",
    "    n_bins: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataset for a given subject dict.\n",
    "\n",
    "    Args:\n",
    "        subject (dict): A dictionary containing the root path, subject ID, and their start and end times.\n",
    "        min_area (float, optional): The minimum area of the subject to be included in the dataset. Default is None.\n",
    "        n_samples (int, optional): The number of samples to take from each bin. Default is 1.\n",
    "        n_bins (int, optional): The number of bins to use for sampling. Default is 50.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing uniformly-sampled pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "    subj_data = get_raw_tracking_data(\n",
    "        subject[\"root\"],\n",
    "        subject[\"id\"],\n",
    "        subject[\"start\"],\n",
    "        subject[\"end\"],\n",
    "    )\n",
    "    if min_area:\n",
    "        subj_data = subj_data[subj_data.area >= min_area]  # when animals fuse\n",
    "    subj_data = sample_n_from_bins(subj_data, n_samples=n_samples, n_bins=n_bins)\n",
    "    return subj_data\n",
    "\n",
    "\n",
    "def create_fully_labelled_dataset(session: dict, subj_ids: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a fully labelled dataset for all or selected subjects of\n",
    "    a given session dict. Useful to \"bookmark\" frames for use with SLEAP's\n",
    "    predict \"only-labeled-frames\" option.\n",
    "\n",
    "    Args:\n",
    "        session (dict): A session dictionary.\n",
    "        subj_ids (list, optional): A list of subject ids. If None, all\n",
    "            subjects are selected.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing pos tracking,\n",
    "            video data, and subject ID.\n",
    "    \"\"\"\n",
    "    all_subj_data = pd.DataFrame()\n",
    "    if not subj_ids:\n",
    "        subj_ids = session[\"subjects\"].keys()\n",
    "        subj_ids = [subj for subj in subj_ids if \"multi_\" not in subj]\n",
    "    for subj in subj_ids:\n",
    "        root = session.get(\"root\", session[\"subjects\"][subj].get(\"root\"))\n",
    "        subj_data = get_raw_tracking_data(\n",
    "            root,\n",
    "            subj,\n",
    "            session[\"subjects\"][subj][\"start\"],\n",
    "            session[\"subjects\"][subj][\"end\"],\n",
    "            source_reader=exp02.CameraTop.Video,\n",
    "        )\n",
    "        all_subj_data = pd.concat([all_subj_data, subj_data])\n",
    "\n",
    "    return all_subj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries for each session\n",
    "aeon2 = {\n",
    "    \"root\": \"/ceph/aeon/aeon/data/raw/AEON2/experiment0.2/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1101818\": {\n",
    "            \"start\": pd.Timestamp(\"2022-06-23 08:39:04.261089801\"),\n",
    "            \"end\": pd.Timestamp(\"2022-06-23 11:14:46.121759892\"),\n",
    "        },\n",
    "        \"BAA-1101819\": {\n",
    "            \"start\": pd.Timestamp(\"2022-06-21 13:28:10.593659878\"),\n",
    "            \"end\": pd.Timestamp(\"2022-06-21 16:34:29.241280079\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"BAA-1101818_819\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Z:\\aeon\\data\\raw\\AEON2\\experiment0.2\\2022-06-22T08-51-10\\CameraTop\\CameraTop_2022-06-22T11-00-00.avi\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-03 16:40:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-03 16:55:00\"),\n",
    "        },\n",
    "        \"AEON3_TP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-03 17:01:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-03 17:22:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-03 17:23:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-03 17:43:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3_NTP_TP_local\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-03T17-00-00_multianimal.avi\"\n",
    "    ],\n",
    "    # multianimal \"2023-03-03 17:23:00\" \"2023-03-03 17:43:00\"\n",
    "}\n",
    "\n",
    "aeon3b = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-16 15:05:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-16 15:44:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-16 16:00:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-16 16:36:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-16 16:37:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-16 17:19:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_NTP_TP_local\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-16T16-00-00_multianimal.avi\",\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-16T17-00-00_multianimal.avi\",\n",
    "    ],\n",
    "    # multianimal \"2023-03-16 16:37:00\" \"2023-03-16 17:19:00\"\n",
    "}\n",
    "\n",
    "aeon3b_pattern = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 09:40:40\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:07:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:10:44\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:46:30\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:50:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 11:22:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 11:23:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 12:31:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_local\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-29T11-00-00_TP1TP2.avi\",  # TP1 and TP2: 11:22:37 - 11:22:57\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-29T11-00-00_multianimal.avi\",  # all mice: 11:23:30 - 12:31:00\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-29T12-00-00_multianimal.avi\",  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_nest = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 09:40:40\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:07:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:10:44\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:46:30\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:50:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 11:22:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 11:23:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 12:31:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"nest_coords\": [\n",
    "        (1223, 475),\n",
    "        (1223, 588),\n",
    "        (1352, 479),\n",
    "        (1352, 581),\n",
    "    ],\n",
    "    \"session\": \"AEON3B_pattern_local_nest\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Y:\\ProjectAeon\\sleap_tracking\\CameraNest_2023-03-29T11-12-00_pattern_nest.avi\"  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_tattoo = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {  # BAA-1103352\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 16:13:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 17:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {  # BAA-1103353\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 17:04\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 18:04\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {  # BAA-1103351\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 18:08:19\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 18:38:52\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 18:41:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 19:12:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_tattoo\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Y:\\ProjectAeon\\sleap_tracking\\CameraTop_2023-06-16T18-19-00_pattern_tattoo.avi\",  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_tattoo2 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/multianimal-test/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {  # BAA-1103352\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 16:28:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 17:01:57\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {  # CAA-1120139\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 17:06:22\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 17:34:52\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {  # BAA-1103351\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 15:36:19\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 16:16:19\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 17:37:08\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 18:10:13\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_tattoo2\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Y:\\ProjectAeon\\sleap_tracking\\CameraTop_2023-07-04T17-18-00_pattern_tattoo.avi\",  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_tattoo3 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/multianimal-test/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {  # BAA-1103352\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 16:28:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 17:01:57\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {  # BAA-1103369\n",
    "            \"start\": pd.Timestamp(\"2023-07-28 14:24:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-28 15:15:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {  # BAA-1103351\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 15:36:19\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 16:16:19\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-07-28 15:21:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-28 16:18:00\"),\n",
    "        },\n",
    "        \"multi_animal2\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-01 10:19:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-01 11:07:00\"),\n",
    "        },\n",
    "        \"multi_animal3\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-03 10:40:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-03 11:28:00\"),\n",
    "        },\n",
    "        \"multi_animal4\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-08 14:14:10.119999886\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-08 15:01:32.288000107\"),\n",
    "        },\n",
    "        \"multi_animal5\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-11 11:54:01.340000153\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-11 13:20:36.303999901\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_tattoo3\",\n",
    "}\n",
    "\n",
    "social_01 = {\n",
    "    \"subjects\": {\n",
    "        \"CAA-1120747\": {  # CAA-1120747\n",
    "            \"root\": \"Z:/aeon/data/raw/AEON4/social0.1/\",\n",
    "            \"start\": pd.Timestamp(\"2023-11-27 13:00:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-11-27 14:00:00\"),\n",
    "        },\n",
    "        \"CAA-1120746\": {  # CAA-1120746\n",
    "            \"root\": \"Z:/aeon/data/raw/AEON3/social0.1/\",\n",
    "            \"start\": pd.Timestamp(\"2023-11-22 12:00:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-11-22 13:00:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"social_01\",\n",
    "}\n",
    "\n",
    "aeon3_social_dev_b5350ff = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/model-training/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104047\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:14:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:45:00\"),\n",
    "        },\n",
    "        \"BAA-1104045\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:50:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 17:20:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 15:37:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:09:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon3_social_dev_b5350ff\",\n",
    "}\n",
    "\n",
    "aeon4_social_dev_b5350ff = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON4/model-training/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104049\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:46:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 17:15:00\"),\n",
    "        },\n",
    "        \"BAA-1104048\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:10:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:39:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 15:21:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:07:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon4_social_dev_b5350ff\",\n",
    "}\n",
    "\n",
    "aeon4_social_dev_b5350ff2 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON4/model-training/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104049\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 20:33:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 21:13:00\"),\n",
    "        },\n",
    "        \"BAA-1104048\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 19:47:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 20:27:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 19:12:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 19:43:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon4_social_dev_b5350ff2\",\n",
    "}\n",
    "\n",
    "aeon3_social_dev_b5350ff2 = {\n",
    "    \"root\": \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104047\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-02-05 15:44:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-02-05 17:00:00\"),\n",
    "        },\n",
    "        \"BAA-1104045\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-31 11:29:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-31 13:00:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon3_social_dev_b5350ff2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-31 11:28:45.543519974</th>\n",
       "      <td>BAA-1104045</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>Remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 22:36:53.196512222</th>\n",
       "      <td>BAA-1104045</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>Remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-02 00:15:06.000000000</th>\n",
       "      <td>BAA-1104045</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>Remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-03 16:28:29.139999866</th>\n",
       "      <td>BAA-1104045</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>Exit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-05 15:43:11.581535816</th>\n",
       "      <td>BAA-1104047</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>Remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08 14:49:41.552000046</th>\n",
       "      <td>BAA-1104047</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>Exit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08 14:56:42.000000000</th>\n",
       "      <td>test</td>\n",
       "      <td>740000.000000</td>\n",
       "      <td>Enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08 15:03:59.465536118</th>\n",
       "      <td>test</td>\n",
       "      <td>740000.000000</td>\n",
       "      <td>Remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08 15:07:03.751999855</th>\n",
       "      <td>test</td>\n",
       "      <td>740000.000000</td>\n",
       "      <td>Exit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08 15:07:19.808000088</th>\n",
       "      <td>Test2</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>Enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-09 16:16:32.599999905</th>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-09 16:24:25.992000103</th>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Exit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-09 16:25:49.935999870</th>\n",
       "      <td>BAA-1104045</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>Enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-09 16:26:07.579999924</th>\n",
       "      <td>BAA-1104047</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>Enter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id         weight   event\n",
       "time                                                             \n",
       "2024-01-31 11:28:45.543519974  BAA-1104045      29.100000  Remain\n",
       "2024-02-01 22:36:53.196512222  BAA-1104045      29.100000  Remain\n",
       "2024-02-02 00:15:06.000000000  BAA-1104045      29.100000  Remain\n",
       "2024-02-03 16:28:29.139999866  BAA-1104045      29.100000    Exit\n",
       "2024-02-05 15:43:11.581535816  BAA-1104047      33.200001  Remain\n",
       "2024-02-08 14:49:41.552000046  BAA-1104047      30.400000    Exit\n",
       "2024-02-08 14:56:42.000000000         test  740000.000000   Enter\n",
       "2024-02-08 15:03:59.465536118         test  740000.000000  Remain\n",
       "2024-02-08 15:07:03.751999855         test  740000.000000    Exit\n",
       "2024-02-08 15:07:19.808000088        Test2      74.000000   Enter\n",
       "2024-02-09 16:16:32.599999905         test       1.000000   Enter\n",
       "2024-02-09 16:24:25.992000103         test       1.000000    Exit\n",
       "2024-02-09 16:25:49.935999870  BAA-1104045      29.600000   Enter\n",
       "2024-02-09 16:26:07.579999924  BAA-1104047      31.100000   Enter"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load subject states\n",
    "# aeon3_social_dev_b5350ff[\"root\"].replace(\"Z:\", \"/ceph/aeon\")\n",
    "aeon_api.load(\n",
    "    \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "    aeon.io.reader.Subject(\n",
    "        \"Environment_SubjectState_*\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment states\n",
    "aeon_api.load(\n",
    "    aeon4_social_dev_b5350ff2[\"root\"],\n",
    "    aeon.io.reader.Csv(\"Environment_EnvironmentState_*\", [\"state\"]),\n",
    "    pd.Timestamp(\"2024-01-21 20:28:14.791999817\"),\n",
    "    pd.Timestamp(\"2024-01-21 21:14:02.607999802\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>area</th>\n",
       "      <th>_frame</th>\n",
       "      <th>_path</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAA-1104045</th>\n",
       "      <td>1126</td>\n",
       "      <td>1126</td>\n",
       "      <td>1126</td>\n",
       "      <td>1126</td>\n",
       "      <td>1126</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAA-1104047</th>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x     y  area  _frame  _path   bin\n",
       "id                                                \n",
       "BAA-1104045  1126  1126  1126    1126   1126  1126\n",
       "BAA-1104047   981   981   981     981    981   981"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract single + multi-animal frames as a single csv\n",
    "all_subj_data = create_session_dataset(aeon3_social_dev_b5350ff2)\n",
    "all_subj_data.to_csv(f'{aeon3_social_dev_b5350ff2[\"session\"]}.csv')\n",
    "all_subj_data.groupby([\"id\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fully labelled datasets for SLEAP model validation\n",
    "single_animal_data = create_fully_labelled_dataset(\n",
    "    aeon4_social_dev_b5350ff2,\n",
    "    subj_ids=[\n",
    "        subj\n",
    "        for subj in aeon4_social_dev_b5350ff2[\"subjects\"].keys()\n",
    "        if \"multi_\" not in subj\n",
    "    ],\n",
    ")\n",
    "single_animal_data.to_csv(\n",
    "    f'{aeon4_social_dev_b5350ff2[\"session\"]}_single_animal_frames.csv'\n",
    ")\n",
    "multi_animal_data = create_fully_labelled_dataset(\n",
    "    aeon4_social_dev_b5350ff2,\n",
    "    subj_ids=[\n",
    "        subj\n",
    "        for subj in aeon4_social_dev_b5350ff2[\"subjects\"].keys()\n",
    "        if \"multi_\" in subj\n",
    "    ],\n",
    ")\n",
    "multi_animal_data.to_csv(\n",
    "    f'{aeon4_social_dev_b5350ff2[\"session\"]}_multi_animal_frames.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve timestamps with temporal discontinuities for RETRAINING\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def adjust_ids(group, classes):\n",
    "    if len(group[\"id\"].unique()) != 2:\n",
    "        # Get the id of the row with the higher class_likelihood\n",
    "        max_id = group.loc[group[\"class_likelihood\"].idxmax(), \"id\"]\n",
    "        # Set the id of the row with the lower class_likelihood to the id that's not max_id\n",
    "        group.loc[group[\"class_likelihood\"].idxmin(), \"id\"] = [\n",
    "            id for id in classes if id != max_id\n",
    "        ][0]\n",
    "    return group\n",
    "\n",
    "\n",
    "# load SLEAP Pose data\n",
    "root = \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\"\n",
    "start_time = pd.Timestamp(\"2024-02-09 17:00\")\n",
    "end_time = pd.Timestamp(\"2024-02-09 18:00\")\n",
    "exp_times = get_experiment_times(root, start_time, end_time)\n",
    "pos = aeon_api.load(root, social02.CameraTop.Pose, start=start_time, end=end_time)\n",
    "pos = exclude_maintenance_data(pos, exp_times)\n",
    "pos[\"class\"] = pos[\"class\"].astype(int)\n",
    "classes = [\n",
    "    \"BAA-1104045\",\n",
    "    \"BAA-1104047\",\n",
    "]  # from SLEAP model config # AEON3[\"BAA-1104045\", \"BAA-1104047\"] # AEON4[\"BAA-1104048\", \"BAA-1104049\"]\n",
    "# assign subject IDs\n",
    "pos[\"id\"] = pos[\"class\"].map(lambda x: classes[x])\n",
    "pos_sorted = pos.sort_values(by=[\"class\", pos.index.name])\n",
    "pos_sorted[\"dist\"] = (\n",
    "    pos_sorted.groupby(\"class\")[[\"x\", \"y\"]]\n",
    "    .diff()\n",
    "    .apply(lambda x: np.linalg.norm(x), axis=1)\n",
    ")\n",
    "# set 100 as threshold for temporal discontinuities\n",
    "violations = pos_sorted[pos_sorted[\"dist\"] > 100]\n",
    "sampled_violations = (\n",
    "    violations.groupby(\"class\")\n",
    "    .apply(sample_n_from_bins, n_samples=2, n_bins=10, include_groups=False)\n",
    "    .reset_index()\n",
    "    .set_index(\"time\")\n",
    "    .sort_index()\n",
    ")\n",
    "# retrieve frames with temporal discontinuities\n",
    "top_frames = aeon_api.load(\n",
    "    root, social02.CameraTop.Video, time=sampled_violations.index.unique()\n",
    ")\n",
    "# merge frames with pose data\n",
    "top_frames_pos = pos[[\"id\", \"x\", \"y\", \"class_likelihood\"]].merge(\n",
    "    top_frames, left_index=True, right_index=True, how=\"inner\"\n",
    ")\n",
    "top_frames_pos = top_frames_pos.reset_index()\n",
    "top_frames_pos = (\n",
    "    top_frames_pos.groupby(\"time\")[top_frames_pos.columns]\n",
    "    .apply(adjust_ids, classes=classes)\n",
    "    .set_index(\"time\")\n",
    ")\n",
    "top_frames_pos.to_csv(\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/aeon3_social_02_retrain.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import sleap\n",
    "import numpy as np\n",
    "\n",
    "from sleap.io.pathutils import fix_path_separator\n",
    "from sleap.gui.suggestions import VideoFrameSuggestions\n",
    "from sleap.nn.config import *\n",
    "from sleap.nn.inference import main as sleap_track\n",
    "from sleap.nn.inference import TopDownMultiClassPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_tracks(labels: sleap.Labels) -> sleap.Labels:\n",
    "    \"\"\"\n",
    "    Removes instances from SLEAP Labels object where track = None.\n",
    "\n",
    "    Args:\n",
    "        labels (sleap.Labels): A SLEAP Labels object.\n",
    "    Returns:\n",
    "        sleap.Labels: A SLEAP Labels object with only tracked instances in each frame.\n",
    "    \"\"\"\n",
    "    lfs = [lf.remove_untracked() for lf in labels.labeled_frames]\n",
    "    return sleap.Labels(\n",
    "        labeled_frames=lfs,\n",
    "        videos=labels.videos,\n",
    "        skeletons=labels.skeletons,\n",
    "        tracks=labels.tracks,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_slp_dataset(\n",
    "    subj_data: pd.DataFrame, skeleton: sleap.Skeleton\n",
    ") -> sleap.Labels:\n",
    "    \"\"\"\n",
    "    Generates .slp dataset for a given session dict.\n",
    "\n",
    "    Args:\n",
    "        subj_data (pandas.DataFrame): A pandas DataFrame containing the labeled data for a given session.\n",
    "        skeleton (sleap.Skeleton): A sleap Skeleton object.\n",
    "    Returns:\n",
    "        sleap.Labels: A SLEAP Labels object containing labeled frames.\n",
    "    \"\"\"\n",
    "\n",
    "    # create tracks dictionary from subj_ids that are not multi_animal\n",
    "    tracks_dict = {\n",
    "        subj: sleap.Track(spawned_on=0, name=subj)\n",
    "        for subj in subj_data[\"id\"].unique()\n",
    "        if \"multi_\" not in subj\n",
    "    }\n",
    "\n",
    "    lfs = []\n",
    "\n",
    "    # create video dictionary from new labels\n",
    "    videos_dict = {\n",
    "        video: sleap.Video.from_filename(video, grayscale=True)\n",
    "        for video in subj_data._path.unique()\n",
    "    }\n",
    "\n",
    "    # for each unique frame, create a new labeled frame\n",
    "    for _, row in subj_data.drop_duplicates(subset=[\"_path\", \"_frame\"]).iterrows():\n",
    "        instances = []\n",
    "        if \"multi_\" in row.id:\n",
    "            # duplicate instance for each track\n",
    "            for track in tracks_dict.keys():\n",
    "                instances.append(\n",
    "                    sleap.Instance(\n",
    "                        skeleton=skeleton,\n",
    "                        track=tracks_dict[track],\n",
    "                        points={\"centroid\": sleap.instance.Point(row.x, row.y)},\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            # create a new instance for each row\n",
    "            instances += [\n",
    "                (\n",
    "                    sleap.Instance(\n",
    "                        skeleton=skeleton,\n",
    "                        track=tracks_dict[inst.id],\n",
    "                        points={\"centroid\": sleap.instance.Point(inst.x, inst.y)},\n",
    "                    )\n",
    "                )\n",
    "                for _, inst in subj_data[\n",
    "                    (subj_data[\"_path\"] == row._path)\n",
    "                    & (subj_data[\"_frame\"] == row._frame)\n",
    "                ].iterrows()\n",
    "            ]\n",
    "        # create a new labeled frame\n",
    "        lf = sleap.instance.LabeledFrame(\n",
    "            video=videos_dict[row._path],\n",
    "            frame_idx=row._frame,\n",
    "            instances=instances,\n",
    "        )\n",
    "        lfs.append(lf)\n",
    "\n",
    "    return sleap.Labels(labeled_frames=lfs)\n",
    "\n",
    "\n",
    "def update_slp_video_paths(\n",
    "    labels: \"sleap.Labels\", old_path: str, new_path: str\n",
    ") -> sleap.Labels:\n",
    "    \"\"\"\n",
    "    Updates video paths in a SLEAP labels object (e.g., to move training from local to remote machine).\n",
    "\n",
    "    Args:\n",
    "        labels (sleap.Labels): A SLEAP Labels object.\n",
    "        old_path (str): Old path to video files.\n",
    "        new_path (str): New path to video files.\n",
    "\n",
    "    Returns:\n",
    "        sleap.Labels: A SLEAP Labels object with updated video paths.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    videos = [\n",
    "        sleap.Video.from_filename(\n",
    "            fix_path_separator(vid.filename).replace(old_path, new_path), grayscale=True\n",
    "        )\n",
    "        for vid in labels.videos\n",
    "    ]\n",
    "\n",
    "    lfs = []\n",
    "    for lf in labels.labeled_frames:\n",
    "        lf = sleap.instance.LabeledFrame(\n",
    "            video=videos[labels.videos.index(lf.video)],\n",
    "            frame_idx=lf.frame_idx,\n",
    "            instances=lf.instances,\n",
    "        )\n",
    "        lfs.append(lf)\n",
    "\n",
    "    return sleap.Labels(\n",
    "        labeled_frames=lfs,\n",
    "        videos=videos,\n",
    "        skeletons=labels.skeletons,\n",
    "        tracks=labels.tracks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new skeleton\n",
    "skeleton = sleap.Skeleton()\n",
    "skeleton.add_node(\"centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate slp retrain dataset\n",
    "subj_data = pd.read_csv(\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/aeon3_social_02_retrain.csv\"\n",
    ")\n",
    "labels = generate_slp_dataset(subj_data, skeleton)\n",
    "sleap.Labels.save_file(\n",
    "    labels,\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/aeon3_social_02_retrain.slp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate slp training dataset for all subjects\n",
    "subj_data = pd.read_csv(f'{aeon3_social_dev_b5350ff2[\"session\"]}.csv')\n",
    "labels = generate_slp_dataset(subj_data, skeleton)\n",
    "sleap.Labels.save_file(labels, f'{aeon3_social_dev_b5350ff2[\"session\"]}.slp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate separate single, multi-animal .slp datasets for prediction/evaluation\n",
    "# single-animal frames are GT for evaluation\n",
    "# multi-animal frames are labelled to be used as bookmarks for prediction\n",
    "csv_files = [\n",
    "    f'{aeon4_social_dev_b5350ff2[\"session\"]}_single_animal_frames.csv',\n",
    "    f'{aeon4_social_dev_b5350ff2[\"session\"]}_multi_animal_frames.csv',\n",
    "]\n",
    "for csv_file in csv_files:\n",
    "    subj_data = pd.read_csv(csv_file)\n",
    "    labels = generate_slp_dataset(aeon4_social_dev_b5350ff2, subj_data, skeleton)\n",
    "    labels = update_slp_video_paths(labels=labels, old_path=\"Z:\", new_path=\"/ceph/aeon\")\n",
    "    sleap.Labels.save_file(labels, f\"{Path(csv_file).stem}_ceph.slp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial parameters\n",
    "subj_id = f'{aeon3b_pattern_tattoo3[\"session\"]}'\n",
    "run_name_centroid = f\"{subj_id}_topdown_top.centroid\"\n",
    "run_name_centered_instance = f\"{subj_id}_topdown_top.centered_instance_multiclass\"\n",
    "root = \"/ceph/aeon/aeon/code/scratchpad/sleap/tail_pattern/\"\n",
    "runs_folder = root + \"models/\"\n",
    "predictions_folder = root + \"predictions/\"\n",
    "groundtruth_folder = root + \"groundtruth/\"\n",
    "\n",
    "try:\n",
    "    skeleton\n",
    "except NameError:\n",
    "    # create new skeleton\n",
    "    skeleton = sleap.Skeleton()\n",
    "    skeleton.add_node(\"centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update local video paths to ceph\n",
    "new_labels = update_slp_video_paths(\n",
    "    labels=sleap.load_file(f\"{subj_id}.slp\"), old_path=\"Z:\", new_path=\"/ceph/aeon\"\n",
    ")\n",
    "sleap.Labels.save_file(new_labels, f\"{root}{subj_id}.slp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into train/val/test\n",
    "labels = sleap.load_file(f\"{root}{subj_id}.slp\")\n",
    "\n",
    "# generate a 0.8/0.1/0.1 train/val/test split\n",
    "labels_train, labels_val_test = labels.split(n=0.8)\n",
    "labels_val, labels_test = labels_val_test.split(n=0.5)\n",
    "\n",
    "# Save with images\n",
    "labels_train.save(f\"{root}{subj_id}.train.pkg.slp\")  # , with_images=True)\n",
    "labels_val.save(f\"{root}{subj_id}.val.pkg.slp\")  # , with_images=True)\n",
    "labels_test.save(f\"{root}{subj_id}.test.pkg.slp\")  # , with_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid model\n",
    "# initalise default training job config\n",
    "cfg = TrainingJobConfig()\n",
    "cfg.data.labels.training_labels = f\"{root}{subj_id}.train.pkg.slp\"\n",
    "cfg.data.labels.validation_labels = f\"{root}{subj_id}.val.pkg.slp\"\n",
    "cfg.data.labels.test_labels = f\"{root}{subj_id}.test.pkg.slp\"\n",
    "\n",
    "# preprocessing and training params\n",
    "cfg.data.preprocessing.input_scaling = 0.75  # 0.5\n",
    "cfg.data.instance_cropping.center_on_part = \"centroid\"\n",
    "cfg.data.instance_cropping.crop_size = 96  # set crop size manually\n",
    "cfg.optimization.augmentation_config.rotate = True\n",
    "cfg.optimization.epochs = 600  # 200\n",
    "cfg.optimization.batch_size = 4\n",
    "\n",
    "cfg.optimization.initial_learning_rate = 0.0001\n",
    "cfg.optimization.learning_rate_schedule.reduce_on_plateau = True\n",
    "cfg.optimization.learning_rate_schedule.reduction_factor = 0.5\n",
    "cfg.optimization.learning_rate_schedule.plateau_min_delta = 1e-06\n",
    "cfg.optimization.learning_rate_schedule.plateau_patience = 20  # 5\n",
    "cfg.optimization.learning_rate_schedule.plateau_cooldown = 3\n",
    "cfg.optimization.learning_rate_schedule.min_learning_rate = 1e-08\n",
    "\n",
    "cfg.optimization.early_stopping.stop_training_on_plateau = True\n",
    "cfg.optimization.early_stopping.plateau_min_delta = 1e-08\n",
    "cfg.optimization.early_stopping.plateau_patience = 30  # 20\n",
    "\n",
    "# configure nn and model\n",
    "cfg.model.backbone.unet = UNetConfig(\n",
    "    max_stride=16,\n",
    "    filters=16,\n",
    "    filters_rate=2.00,\n",
    "    output_stride=2,\n",
    "    # up_interpolate=True, # save computations but may lower accuracy\n",
    ")\n",
    "cfg.model.heads.centroid = CentroidsHeadConfig(\n",
    "    anchor_part=\"centroid\", sigma=2.5, output_stride=2\n",
    ")\n",
    "\n",
    "# configure outputs\n",
    "cfg.outputs.run_name = run_name_centroid\n",
    "cfg.outputs.save_outputs = True\n",
    "cfg.outputs.runs_folder = runs_folder\n",
    "cfg.outputs.save_visualizations = True\n",
    "cfg.outputs.checkpointing.initial_model = True\n",
    "cfg.outputs.checkpointing.best_model = True\n",
    "\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)\n",
    "trainer.setup()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part detection model: centered instance + multi-class\n",
    "# initalise default training job config\n",
    "cfg = TrainingJobConfig()\n",
    "\n",
    "# update path to 0.8/0.1/0.1 train/val/test split\n",
    "cfg.data.labels.training_labels = f\"{root}{subj_id}.train.pkg.slp\"\n",
    "cfg.data.labels.validation_labels = f\"{root}{subj_id}.val.pkg.slp\"\n",
    "cfg.data.labels.test_labels = f\"{root}{subj_id}.test.pkg.slp\"\n",
    "cfg.data.labels.skeletons = [skeleton]  # load skeleton\n",
    "\n",
    "# preprocessing and training params\n",
    "cfg.data.preprocessing.input_scaling = 1.0\n",
    "cfg.data.instance_cropping.center_on_part = \"centroid\"\n",
    "cfg.data.instance_cropping.crop_size = 96  # set crop size manually\n",
    "cfg.optimization.augmentation_config.rotate = True\n",
    "cfg.optimization.epochs = 600\n",
    "cfg.optimization.batch_size = 8  # 4\n",
    "\n",
    "cfg.optimization.initial_learning_rate = 0.0001\n",
    "cfg.optimization.learning_rate_schedule.reduce_on_plateau = True\n",
    "cfg.optimization.learning_rate_schedule.reduction_factor = 0.1  # 0.5\n",
    "cfg.optimization.learning_rate_schedule.plateau_min_delta = 1e-08  # 1e-06\n",
    "cfg.optimization.learning_rate_schedule.plateau_patience = 20  # 5\n",
    "cfg.optimization.learning_rate_schedule.plateau_cooldown = 3\n",
    "cfg.optimization.learning_rate_schedule.min_learning_rate = 1e-08\n",
    "\n",
    "cfg.optimization.early_stopping.stop_training_on_plateau = True\n",
    "cfg.optimization.early_stopping.plateau_min_delta = 1e-08\n",
    "cfg.optimization.early_stopping.plateau_patience = 30  # 20\n",
    "\n",
    "# configure nn and model\n",
    "cfg.model.backbone.unet = UNetConfig(\n",
    "    max_stride=16,  # 32,\n",
    "    output_stride=2,  # 4,\n",
    "    filters=16,  # 24,\n",
    "    filters_rate=1.5,\n",
    "    # up_interpolate=True, # save computations but may lower accuracy\n",
    ")\n",
    "confmaps = CenteredInstanceConfmapsHeadConfig(\n",
    "    anchor_part=\"centroid\",\n",
    "    sigma=1.5,  # 2.5,\n",
    "    output_stride=2,  # 4,\n",
    "    loss_weight=1.0,\n",
    ")\n",
    "# load labels.slp to get track names\n",
    "labels = sleap.load_file(f\"{root}{subj_id}.slp\")\n",
    "class_vectors = ClassVectorsHeadConfig(\n",
    "    classes=[track.name for track in labels.tracks],\n",
    "    output_stride=2,  # 16, #4,\n",
    "    num_fc_layers=3,\n",
    "    num_fc_units=256,\n",
    "    global_pool=True,\n",
    "    loss_weight=0.01,  # TODO: try 1.0\n",
    ")\n",
    "cfg.model.heads.multi_class_topdown = MultiClassTopDownConfig(\n",
    "    confmaps=confmaps, class_vectors=class_vectors\n",
    ")\n",
    "\n",
    "# configure outputs\n",
    "cfg.outputs.run_name = run_name_centered_instance\n",
    "cfg.outputs.save_outputs = True\n",
    "cfg.outputs.runs_folder = runs_folder\n",
    "cfg.outputs.save_visualizations = True\n",
    "cfg.outputs.checkpointing.initial_model = True\n",
    "cfg.outputs.checkpointing.best_model = True\n",
    "\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)\n",
    "\n",
    "trainer.setup()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume training\n",
    "# Load config.\n",
    "model_path = \"models/AEON3_NTP_TP_local_topdown_top.centroid/\"\n",
    "cfg = sleap.load_config(model_path)\n",
    "\n",
    "# Create and initialize the trainer.\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)\n",
    "trainer.setup()\n",
    "\n",
    "# Replace the randomly initialized weights with the saved weights.\n",
    "trainer.keras_model.load_weights(f\"{model_path}best_model.h5\")\n",
    "\n",
    "trainer.config.optimization.epochs = 200\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.keras_model.outputs[0].shape)  # confmaps\n",
    "print(trainer.keras_model.outputs[1].shape)  # id part"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial parameters\n",
    "subj_id = f'{aeon3b_pattern_tattoo3[\"session\"]}'\n",
    "run_name_centroid = f\"{subj_id}_topdown_top.centroid\"\n",
    "run_name_centered_instance = f\"{subj_id}_topdown_top.centered_instance_multiclass\"\n",
    "root = \"/ceph/aeon/aeon/code/scratchpad/sleap/tail_pattern/\"\n",
    "runs_folder = root + \"models/\"\n",
    "predictions_folder = root + \"predictions/\"\n",
    "groundtruth_folder = root + \"groundtruth/\"\n",
    "\n",
    "print(run_name_centroid, run_name_centered_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a single multi-animal video\n",
    "subj_idx = 0\n",
    "video_idx = 0\n",
    "\n",
    "multi_subj_ids = [\n",
    "    subj_id\n",
    "    for subj_id in aeon3b_pattern_tattoo3[\"subjects\"].keys()\n",
    "    if \"multi_\" in subj_id\n",
    "]\n",
    "\n",
    "# select one multi-animal session only\n",
    "input_file = f'{root}{aeon3b_pattern_tattoo3[\"session\"]}_{multi_subj_ids[subj_idx]}.slp'\n",
    "\n",
    "# infer on user-labeled frames on the first video only\n",
    "output_file_pr = f\"{predictions_folder}{subj_id}_{multi_subj_ids[subj_idx]}_pr.slp\"\n",
    "sleap_track(\n",
    "    [\n",
    "        input_file,\n",
    "        \"--model\",\n",
    "        f\"{runs_folder}{run_name_centroid}\",\n",
    "        \"--model\",\n",
    "        f\"{runs_folder}{run_name_centered_instance}\",\n",
    "        \"--only-labeled-frames\",\n",
    "        \"--video.index\",\n",
    "        str(video_idx),\n",
    "        \"--output\",\n",
    "        output_file_pr,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 100 suggestions based on low-scoring frames to be proofread\n",
    "labels_pr = sleap.load_file(output_file_pr)\n",
    "output_file_low_gt = (\n",
    "    f\"{groundtruth_folder}{subj_id}_1_{multi_subj_ids[subj_idx]}_low_gt.slp\"\n",
    ")\n",
    "labels_missing = sleap.Labels(\n",
    "    [label for label in labels_pr.labels if label.n_predicted_instances < 3]\n",
    ")\n",
    "suggestions = VideoFrameSuggestions.suggest(\n",
    "    labels=labels_missing,\n",
    "    params=dict(\n",
    "        videos=[labels_missing.videos[video_idx]],\n",
    "        method=\"prediction_score\",\n",
    "        score_limit=0.5,\n",
    "        instance_limit_lower=1,\n",
    "        instance_limit_upper=3,\n",
    "    ),\n",
    ")\n",
    "\n",
    "if len(suggestions) > 100:\n",
    "    suggestions = random.sample(suggestions, 100)\n",
    "\n",
    "lfs = []\n",
    "for suggestion in suggestions:\n",
    "    matching_frames = labels_missing.find(\n",
    "        video=labels_missing.videos[video_idx], frame_idx=suggestion.frame_idx\n",
    "    )\n",
    "    if matching_frames:\n",
    "        lf = matching_frames[0]\n",
    "        instances = []\n",
    "        for instance in lf.instances_to_show:\n",
    "            instances.append(\n",
    "                sleap.Instance(\n",
    "                    skeleton=instance.skeleton,\n",
    "                    track=instance.track,\n",
    "                    points={\n",
    "                        \"centroid\": sleap.instance.Point(\n",
    "                            instance.points[0].x, instance.points[0].y\n",
    "                        )\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        lfs.append(\n",
    "            sleap.instance.LabeledFrame(\n",
    "                video=lf.video,\n",
    "                frame_idx=lf.frame_idx,\n",
    "                instances=instances,\n",
    "            )\n",
    "        )\n",
    "sleap.Labels.save_file(sleap.Labels(labeled_frames=lfs), output_file_low_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 100 random consecutive frames as ground truth data for evaluation\n",
    "output_file_rand_gt = (\n",
    "    f\"{groundtruth_folder}{subj_id}_{multi_subj_ids[subj_idx]}_rand_gt.slp\"\n",
    ")\n",
    "random_frame_from = True\n",
    "consecutive = True\n",
    "num_frames = 100  # 3000 = 1min\n",
    "\n",
    "if consecutive:\n",
    "    frame_from = (\n",
    "        random.randint(0, len(labels_pr.labeled_frames) - num_frames)\n",
    "        if random_frame_from\n",
    "        else 0\n",
    "    )\n",
    "    selected_frame_idx = list(range(frame_from, frame_from + num_frames))\n",
    "else:\n",
    "    selected_frame_idx = random.sample(range(len(labels_pr.labeled_frames)), num_frames)\n",
    "\n",
    "sfs = []\n",
    "for idx in selected_frame_idx:\n",
    "    sf = labels_pr.labeled_frames[idx]\n",
    "    instances = []\n",
    "    for instance in sf.instances_to_show:\n",
    "        instances.append(\n",
    "            sleap.Instance(\n",
    "                skeleton=instance.skeleton,\n",
    "                track=instance.track,\n",
    "                points={\n",
    "                    \"centroid\": sleap.instance.Point(\n",
    "                        instance.points[0].x, instance.points[0].y\n",
    "                    )\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    sfs.append(\n",
    "        sleap.instance.LabeledFrame(\n",
    "            video=sf.video,\n",
    "            frame_idx=sf.frame_idx,\n",
    "            instances=instances,\n",
    "        )\n",
    "    )\n",
    "\n",
    "sleap.Labels.save_file(sleap.Labels(labeled_frames=sfs), output_file_rand_gt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAA-1104045 Accuracy: 0.977\n",
      "BAA-1104047 Accuracy: 0.84\n",
      "ID accuracy: 0.907\n",
      "Total tracks: 179343\n",
      "Tracks identified: 179454\n",
      "Tracks correctly identified: 162630\n"
     ]
    }
   ],
   "source": [
    "# evaluate single-animal predictions with ground truth data\n",
    "gt_file = \"/ceph/aeon/aeon/code/scratchpad/sleap/social_dev_b5350ff/predictions/aeon3_social_dev_b5350ff_single_animal_frames_ceph.slp\"\n",
    "pr_file = \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/predictions/aeon3_social_dev_b5350ff_single_animal_frames_ceph_pr.slp\"\n",
    "labels_gt = sleap.load_file(gt_file)\n",
    "labels_pr = sleap.load_file(pr_file)\n",
    "metrics = sleap.nn.evals.evaluate(labels_gt, labels_pr, oks_scale=96)\n",
    "framepairs = sleap.nn.evals.find_frame_pairs(labels_gt, labels_pr)\n",
    "matches = sleap.nn.evals.match_frame_pairs(framepairs, scale=96)\n",
    "positive_pairs = matches[0]\n",
    "false_negatives = matches[1]\n",
    "track_names = [track.name for track in labels_gt.tracks]\n",
    "correct_id = {track_name: [] for track_name in track_names}\n",
    "for positive_pair in positive_pairs:\n",
    "    gt = (\n",
    "        positive_pair[0]\n",
    "        if isinstance(positive_pair[1], sleap.PredictedInstance)\n",
    "        else positive_pair[1]\n",
    "    )\n",
    "    correct_id[gt.track.name].append(\n",
    "        positive_pair[0].track.name == positive_pair[1].track.name\n",
    "    )\n",
    "track_sums = 0\n",
    "track_lens = 0\n",
    "for track in track_names:\n",
    "    track_sums += sum(correct_id[track])\n",
    "    track_lens += len(correct_id[track])\n",
    "    print(\n",
    "        f\"{track} Accuracy: {round(sum(correct_id[track]) / len(correct_id[track]), 3)}\"\n",
    "    )\n",
    "print(\"ID accuracy:\", round(track_sums / track_lens, 3))\n",
    "print(\"Total tracks:\", len(labels_gt.all_instances))\n",
    "print(\"Tracks identified:\", len(labels_pr.all_instances))\n",
    "print(\"Tracks correctly identified:\", track_sums)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:06:00.867119: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-02-15 10:06:00.867151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hpc-gw1): /proc/driver/nvidia/version does not exist\n",
      "2024-02-15 10:06:00.867452: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max instances set, limiting instances to 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:06:21.137575: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm6ucnd1f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:06:33.817603: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-02-15 10:06:33.817809: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2024-02-15 10:06:34.119018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 2517 nodes (2419), 4209 edges (4105), time = 133.61ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 3.514ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export model\n",
    "predictor = TopDownMultiClassPredictor.from_trained_models(\n",
    "    centroid_model_path=\"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON4/models/aeon4_social_dev_b5350ff2_retrain_ceph_topdown_top.centroid\",\n",
    "    confmap_model_path=\"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON4/models/aeon4_social_dev_b5350ff2_retrain_ceph_topdown_top.centered_instance_multiclass\",\n",
    "    resize_input_layer=False,  # SLEAP 1.3.0+\n",
    ")\n",
    "\n",
    "predictor.export_model(\n",
    "    \"/ceph/aeon/aeon/data/processed/test-node1/4546247/2024-02-13T17-00-00/topdown-multianimal-id-133/\",\n",
    "    max_instances=2,\n",
    "    unrag_outputs=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0e3000693f8b9aa662d7863f075a07b6f4295c6c6941a96ccabdea0fbe2a07d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEON\n",
    "#### create training dataset from aeon raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "import warnings\n",
    "import aeon\n",
    "import aeon.io.api as aeon_api\n",
    "\n",
    "from aeon.schema.schemas import exp02, social02\n",
    "from aeon.analysis.utils import *\n",
    "from dotmap import DotMap\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def get_experiment_times(\n",
    "    root: str | os.PathLike, start_time: pd.Timestamp, end_time: pd.Timestamp\n",
    ") -> DotMap:\n",
    "    \"\"\"\n",
    "    Retrieve experiment start and stop times from environment states\n",
    "    (i.e. times outside of maintenance mode) occurring within the\n",
    "    given start and end times.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path where epoch data is stored.\n",
    "        start_time (pandas.Timestamp): Start time.\n",
    "        end_time (pandas.Timestamp): End time.\n",
    "\n",
    "    Returns:\n",
    "        DotMap: A DotMap object containing two keys: 'start' and 'stop',\n",
    "        corresponding to pairs of experiment start and stop times.\n",
    "\n",
    "    Notes:\n",
    "    This function uses the last 'Maintenance' event (if available, otherwise\n",
    "    `end_time`) as the last 'Experiment' stop time. If the first retrieved state\n",
    "    is 'Maintenance' (e.g. 'Experiment' mode entered before `start_time`),\n",
    "    `start_time` is used as the first 'Experiment' start time.\n",
    "    \"\"\"\n",
    "\n",
    "    experiment_times = DotMap()\n",
    "    env_states = aeon.load(\n",
    "        root,\n",
    "        social02.Environment.EnvironmentState,\n",
    "        # aeon.io.reader.Csv(\"Environment_EnvironmentState_*\", [\"state\"]),\n",
    "        start_time,\n",
    "        end_time,\n",
    "    )\n",
    "    if env_states.empty:\n",
    "        warnings.warn(\n",
    "            \"The environment state df is empty. \"\n",
    "            \"Using input `start_time` and `end_time` as experiment times.\"\n",
    "        )\n",
    "        experiment_times.start = [start_time]\n",
    "        experiment_times.stop = [end_time]\n",
    "        return experiment_times\n",
    "    if env_states[\"state\"].iloc[-1] != \"Maintenance\":\n",
    "        warnings.warn(\n",
    "            \"No 'Maintenance' event at the end of the search range. \"\n",
    "            \"Using input `end_time` as last experiment stop time.\"\n",
    "        )\n",
    "        # Pad with a \"Maintenance\" event at the end\n",
    "        env_states = pd.concat(\n",
    "            [\n",
    "                env_states,\n",
    "                pd.DataFrame(\n",
    "                    \"Maintenance\",\n",
    "                    index=[end_time],\n",
    "                    columns=env_states.columns,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    # Use the last \"Maintenance\" event as end time\n",
    "    end_time = (env_states[env_states.state == \"Maintenance\"]).index[-1]\n",
    "    env_states = env_states[~env_states.index.duplicated(keep=\"first\")]\n",
    "    # Retain only events between visit start and stop times\n",
    "    env_states = env_states.iloc[\n",
    "        env_states.index.get_indexer([start_time], method=\"bfill\")[\n",
    "            0\n",
    "        ] : env_states.index.get_indexer([end_time], method=\"ffill\")[0]\n",
    "        + 1\n",
    "    ]\n",
    "    # Retain only events where state changes (experiment-maintenance pairs)\n",
    "    env_states = env_states[env_states[\"state\"].ne(env_states[\"state\"].shift())]\n",
    "    if env_states[\"state\"].iloc[0] == \"Maintenance\":\n",
    "        warnings.warn(\n",
    "            \"No 'Experiment' event at the start of the search range. \"\n",
    "            \"Using input `end_time` as last experiment stop time.\"\n",
    "        )\n",
    "        # Pad with an \"Experiment\" event at the start\n",
    "        env_states = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(\n",
    "                    \"Experiment\",\n",
    "                    index=[start_time],\n",
    "                    columns=env_states.columns,\n",
    "                ),\n",
    "                env_states,\n",
    "            ]\n",
    "        )\n",
    "    experiment_times.start = env_states[\n",
    "        env_states[\"state\"] == \"Experiment\"\n",
    "    ].index.values\n",
    "    experiment_times.stop = env_states[\n",
    "        env_states[\"state\"] == \"Maintenance\"\n",
    "    ].index.values\n",
    "\n",
    "    return experiment_times\n",
    "\n",
    "\n",
    "def exclude_maintenance_data(\n",
    "    data: pd.DataFrame, experiment_times: DotMap\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Excludes rows not in experiment times (i.e., corresponding to maintenance times)\n",
    "    from the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The data to filter. Expected to have a pandas.DateTimeIndex.\n",
    "        experiment_times (DotMap): A DotMap object containing experiment start and stop times.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing filtered data.\n",
    "    \"\"\"\n",
    "    filtered_data = pd.concat(\n",
    "        [\n",
    "            data.loc[start:stop]\n",
    "            for start, stop in zip(experiment_times.start, experiment_times.stop)\n",
    "        ]\n",
    "    )\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def get_raw_tracking_data(\n",
    "    root: str | os.PathLike,\n",
    "    subj_id: str,\n",
    "    start: pd.Timestamp,\n",
    "    end: pd.Timestamp,\n",
    "    source_reader: aeon.io.reader.Video = exp02.CameraTop.Video,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve pos tracking and video data and assigns subject ID.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path, or prioritised sequence of paths, where epoch data is stored.\n",
    "        subj_id (str): The subject ID string to be assigned.\n",
    "        start (pandas.Timestamp): The left bound of the time range to extract.\n",
    "        end (pandas.Timestamp): The right bound of the time range to extract.\n",
    "        source_reader (aeon.io.reader.Video, optional): The frame source reader. Default is exp02.CameraTop.Video.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "\n",
    "    subj_video = aeon_api.load(root, source_reader, start=start, end=end)\n",
    "    subj_pos = aeon_api.load(root, exp02.CameraTop.Position, start=start, end=end)\n",
    "    # replace \"raw\" in root with \"processed\"\n",
    "    processed_root = root.replace(\"raw\", \"processed\")\n",
    "    if subj_video.empty:\n",
    "        subj_video = aeon_api.load(processed_root, source_reader, start=start, end=end)\n",
    "        warnings.warn(\"subj_video is empty, retrieving data from processed\")\n",
    "    if subj_pos.empty:\n",
    "        subj_pos = aeon_api.load(\n",
    "            processed_root, exp02.CameraTop.Position, start=start, end=end\n",
    "        )\n",
    "        warnings.warn(\"subj_pos is empty, retrieving data from processed\")\n",
    "    subj_data = pd.merge_asof(\n",
    "        subj_video,\n",
    "        subj_pos,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        direction=\"nearest\",\n",
    "        tolerance=pd.Timedelta(\"1ms\"),\n",
    "    )[[\"x\", \"y\", \"id\", \"area\", \"_frame\", \"_path\"]]\n",
    "    subj_data.dropna(inplace=True)\n",
    "    subj_data[\"id\"] = subj_id\n",
    "\n",
    "    return subj_data\n",
    "\n",
    "\n",
    "def sample_n_from_bins(\n",
    "    subj_data: pd.DataFrame,\n",
    "    n_samples: int = 1,\n",
    "    n_bins: int = 50,\n",
    "    range: npt.ArrayLike = [[0, 1440], [0, 1080]],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uniformly samples n number of data from x number of bins.\n",
    "\n",
    "    Args:\n",
    "        subj_data (pandas.DataFrame): A pandas DataFrame containing pos tracking and video data, and subject ID.\n",
    "        n_samples (int, optional): The number of samples to take from each bin. Default is 1.\n",
    "        n_bins (int, optional): The number of bins to use for sampling. Default is 50.\n",
    "        range (list of lists, optional): The leftmost and rightmost edges of the bins along each dimension\n",
    "            (if not specified explicitly in the bins parameters): [[xmin, xmax], [ymin, ymax]]. All values\n",
    "            outside of this range will be considered outliers and not tallied in the histogram. Default is\n",
    "            [[0, 1440], [0, 1080]].\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing uniformly-sampled pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "\n",
    "    hist_data = stats.binned_statistic_2d(\n",
    "        subj_data.x,\n",
    "        subj_data.y,\n",
    "        values=subj_data,\n",
    "        statistic=\"count\",\n",
    "        bins=n_bins,\n",
    "        range=range,\n",
    "    )\n",
    "    subj_data[\"bin\"] = hist_data.binnumber\n",
    "    sampled_data = (\n",
    "        subj_data.groupby([\"bin\"]).sample(n=n_samples, replace=True).drop_duplicates()\n",
    "    )\n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "def create_session_dataset(\n",
    "    session: dict,\n",
    "    subj_ids: list = None,\n",
    "    plot_dist: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataset for a given session dict.\n",
    "    Args:\n",
    "        session (dict): A dictionary containing the root path, subject IDs, and their start and end times.\n",
    "        subj_ids (list, optional): A list of subject ids. If None, all subjects are selected.\n",
    "        plot_dist (bool, optional): Whether to plot the 1d and 2d histograms of x, y pos tracking for each subject.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas dataframe containing uniformly-sampled pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "    all_subj_data = pd.DataFrame()\n",
    "    if not subj_ids:\n",
    "        subj_ids = session[\"subjects\"].keys()\n",
    "    for subj in subj_ids:\n",
    "        subj_dict = {\n",
    "            \"id\": subj,\n",
    "            \"root\": session.get(\"root\", session[\"subjects\"][subj].get(\"root\")),\n",
    "            \"start\": session[\"subjects\"][subj][\"start\"],\n",
    "            \"end\": session[\"subjects\"][subj][\"end\"],\n",
    "        }\n",
    "        subj_data = (\n",
    "            create_subject_dataset(\n",
    "                subj_dict,\n",
    "                min_area=500,\n",
    "                n_samples=4,\n",
    "                n_bins=10,\n",
    "            )  # sample fewer points for manual annotation\n",
    "            if \"multi_\" in subj\n",
    "            else create_subject_dataset(\n",
    "                subj_dict,\n",
    "            )\n",
    "        )\n",
    "        all_subj_data = pd.concat([all_subj_data, subj_data])\n",
    "    if plot_dist:\n",
    "        fig = plot_position_histograms(all_subj_data)\n",
    "        fig.show()\n",
    "    return all_subj_data\n",
    "\n",
    "\n",
    "def plot_position_histograms(data: pd.DataFrame, n_bins: int = 50) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plots the 1d and 2d histograms of x, y pos tracking for each subject in a given DataFrame.\n",
    "    Args:\n",
    "        data (pandas.DataFrame): A pandas DataFrame containing x, y pos tracking and subject ID(s).\n",
    "        n_bins (int, optional): The number of bins to use for plotting histograms. Default is 50.\n",
    "    Returns:\n",
    "        matplotlib.pyplot: A plot containing 1d and 2d histograms of x, y pos tracking for each subject.\n",
    "    \"\"\"\n",
    "    subj_ids = data[\"id\"].unique()\n",
    "    fig, ax = plt.subplots(2, len(subj_ids))\n",
    "    n_bins = 50\n",
    "    if len(subj_ids) == 1:\n",
    "        data[[\"x\", \"y\"]].plot.hist(bins=n_bins, alpha=0.5, ax=ax[0], title=subj_ids[0])\n",
    "        ax[1].hist2d(\n",
    "            data.x,\n",
    "            data.y,\n",
    "            bins=(n_bins, n_bins),\n",
    "            cmap=plt.cm.jet,\n",
    "        )\n",
    "    else:\n",
    "        for i, subj_id in enumerate(subj_ids):\n",
    "            subj_data = data[data[\"id\"] == subj_id]\n",
    "            subj_data[[\"x\", \"y\"]].plot.hist(\n",
    "                bins=n_bins, alpha=0.5, ax=ax[0, i], title=subj_id\n",
    "            )\n",
    "            ax[1, i].hist2d(\n",
    "                subj_data.x, subj_data.y, bins=(n_bins, n_bins), cmap=plt.cm.jet\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_subject_dataset(\n",
    "    subject: dict,\n",
    "    min_area: float = None,\n",
    "    n_samples: int = 1,\n",
    "    n_bins: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataset for a given subject dict.\n",
    "\n",
    "    Args:\n",
    "        subject (dict): A dictionary containing the root path, subject ID, and their start and end times.\n",
    "        min_area (float, optional): The minimum area of the subject to be included in the dataset. Default is None.\n",
    "        n_samples (int, optional): The number of samples to take from each bin. Default is 1.\n",
    "        n_bins (int, optional): The number of bins to use for sampling. Default is 50.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing uniformly-sampled pos tracking and video data, and subject ID.\n",
    "    \"\"\"\n",
    "    subj_data = get_raw_tracking_data(\n",
    "        subject[\"root\"],\n",
    "        subject[\"id\"],\n",
    "        subject[\"start\"],\n",
    "        subject[\"end\"],\n",
    "    )\n",
    "    if min_area:\n",
    "        subj_data = subj_data[subj_data.area >= min_area]  # when animals fuse\n",
    "    subj_data = sample_n_from_bins(subj_data, n_samples=n_samples, n_bins=n_bins)\n",
    "    return subj_data\n",
    "\n",
    "\n",
    "def create_fully_labelled_dataset(session: dict, subj_ids: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a fully labelled dataset for all or selected subjects of\n",
    "    a given session dict. Useful to \"bookmark\" frames for use with SLEAP's\n",
    "    predict \"only-labeled-frames\" option.\n",
    "\n",
    "    Args:\n",
    "        session (dict): A session dictionary.\n",
    "        subj_ids (list, optional): A list of subject ids. If None, all\n",
    "            subjects are selected.\n",
    "    Returns:\n",
    "        pandas.DataFrame: A pandas DataFrame containing pos tracking,\n",
    "            video data, and subject ID.\n",
    "    \"\"\"\n",
    "    all_subj_data = pd.DataFrame()\n",
    "    if not subj_ids:\n",
    "        subj_ids = session[\"subjects\"].keys()\n",
    "        subj_ids = [subj for subj in subj_ids if \"multi_\" not in subj]\n",
    "    for subj in subj_ids:\n",
    "        root = session.get(\"root\", session[\"subjects\"][subj].get(\"root\"))\n",
    "        subj_data = get_raw_tracking_data(\n",
    "            root,\n",
    "            subj,\n",
    "            session[\"subjects\"][subj][\"start\"],\n",
    "            session[\"subjects\"][subj][\"end\"],\n",
    "            source_reader=exp02.CameraTop.Video,\n",
    "        )\n",
    "        all_subj_data = pd.concat([all_subj_data, subj_data])\n",
    "\n",
    "    return all_subj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries for each session\n",
    "aeon2 = {\n",
    "    \"root\": \"/ceph/aeon/aeon/data/raw/AEON2/experiment0.2/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1101818\": {\n",
    "            \"start\": pd.Timestamp(\"2022-06-23 08:39:04.261089801\"),\n",
    "            \"end\": pd.Timestamp(\"2022-06-23 11:14:46.121759892\"),\n",
    "        },\n",
    "        \"BAA-1101819\": {\n",
    "            \"start\": pd.Timestamp(\"2022-06-21 13:28:10.593659878\"),\n",
    "            \"end\": pd.Timestamp(\"2022-06-21 16:34:29.241280079\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"BAA-1101818_819\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Z:\\aeon\\data\\raw\\AEON2\\experiment0.2\\2022-06-22T08-51-10\\CameraTop\\CameraTop_2022-06-22T11-00-00.avi\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-03 16:40:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-03 16:55:00\"),\n",
    "        },\n",
    "        \"AEON3_TP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-03 17:01:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-03 17:22:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-03 17:23:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-03 17:43:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3_NTP_TP_local\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-03T17-00-00_multianimal.avi\"\n",
    "    ],\n",
    "    # multianimal \"2023-03-03 17:23:00\" \"2023-03-03 17:43:00\"\n",
    "}\n",
    "\n",
    "aeon3b = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-16 15:05:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-16 15:44:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-16 16:00:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-16 16:36:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-16 16:37:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-16 17:19:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_NTP_TP_local\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-16T16-00-00_multianimal.avi\",\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-16T17-00-00_multianimal.avi\",\n",
    "    ],\n",
    "    # multianimal \"2023-03-16 16:37:00\" \"2023-03-16 17:19:00\"\n",
    "}\n",
    "\n",
    "aeon3b_pattern = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 09:40:40\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:07:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:10:44\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:46:30\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:50:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 11:22:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 11:23:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 12:31:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_local\",\n",
    "    \"multianimal_videos\": [\n",
    "        # TP1 and TP2: 11:22:37 - 11:22:57\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-29T11-00-00_TP1TP2.avi\",\n",
    "        # all mice: 11:23:30 - 12:31:00\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-29T11-00-00_multianimal.avi\",\n",
    "        r\"C:\\Users\\chuan\\Documents\\SLEAP_Test\\aeon3_multi\\CameraTop_2023-03-29T12-00-00_multianimal.avi\",  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_nest = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 09:40:40\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:07:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:10:44\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 10:46:30\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 10:50:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 11:22:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-03-29 11:23:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-03-29 12:31:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"nest_coords\": [\n",
    "        (1223, 475),\n",
    "        (1223, 588),\n",
    "        (1352, 479),\n",
    "        (1352, 581),\n",
    "    ],\n",
    "    \"session\": \"AEON3B_pattern_local_nest\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Y:\\ProjectAeon\\sleap_tracking\\CameraNest_2023-03-29T11-12-00_pattern_nest.avi\"  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_tattoo = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/presocial0.1/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {  # BAA-1103352\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 16:13:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 17:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {  # BAA-1103353\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 17:04\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 18:04\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {  # BAA-1103351\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 18:08:19\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 18:38:52\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-06-16 18:41:30\"),\n",
    "            \"end\": pd.Timestamp(\"2023-06-16 19:12:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_tattoo\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Y:\\ProjectAeon\\sleap_tracking\\CameraTop_2023-06-16T18-19-00_pattern_tattoo.avi\",  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_tattoo2 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/multianimal-test/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {  # BAA-1103352\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 16:28:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 17:01:57\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {  # CAA-1120139\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 17:06:22\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 17:34:52\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {  # BAA-1103351\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 15:36:19\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 16:16:19\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 17:37:08\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 18:10:13\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_tattoo2\",\n",
    "    \"multianimal_videos\": [\n",
    "        r\"Y:\\ProjectAeon\\sleap_tracking\\CameraTop_2023-07-04T17-18-00_pattern_tattoo.avi\",  # all mice\n",
    "    ],\n",
    "}\n",
    "\n",
    "aeon3b_pattern_tattoo3 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/multianimal-test/\",\n",
    "    \"subjects\": {\n",
    "        \"AEON3B_NTP\": {  # BAA-1103352\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 16:28:10\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 17:01:57\"),\n",
    "        },\n",
    "        \"AEON3B_TP1\": {  # BAA-1103369\n",
    "            \"start\": pd.Timestamp(\"2023-07-28 14:24:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-28 15:15:00\"),\n",
    "        },\n",
    "        \"AEON3B_TP2\": {  # BAA-1103351\n",
    "            \"start\": pd.Timestamp(\"2023-07-04 15:36:19\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-04 16:16:19\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2023-07-28 15:21:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-07-28 16:18:00\"),\n",
    "        },\n",
    "        \"multi_animal2\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-01 10:19:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-01 11:07:00\"),\n",
    "        },\n",
    "        \"multi_animal3\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-03 10:40:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-03 11:28:00\"),\n",
    "        },\n",
    "        \"multi_animal4\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-08 14:14:10.119999886\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-08 15:01:32.288000107\"),\n",
    "        },\n",
    "        \"multi_animal5\": {\n",
    "            \"start\": pd.Timestamp(\"2023-08-11 11:54:01.340000153\"),\n",
    "            \"end\": pd.Timestamp(\"2023-08-11 13:20:36.303999901\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"AEON3B_pattern_tattoo3\",\n",
    "}\n",
    "\n",
    "social_01 = {\n",
    "    \"subjects\": {\n",
    "        \"CAA-1120747\": {  # CAA-1120747\n",
    "            \"root\": \"Z:/aeon/data/raw/AEON4/social0.1/\",\n",
    "            \"start\": pd.Timestamp(\"2023-11-27 13:00:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-11-27 14:00:00\"),\n",
    "        },\n",
    "        \"CAA-1120746\": {  # CAA-1120746\n",
    "            \"root\": \"Z:/aeon/data/raw/AEON3/social0.1/\",\n",
    "            \"start\": pd.Timestamp(\"2023-11-22 12:00:00\"),\n",
    "            \"end\": pd.Timestamp(\"2023-11-22 13:00:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"social_01\",\n",
    "}\n",
    "\n",
    "aeon3_social_dev_b5350ff = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON3/model-training/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104047\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:14:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:45:00\"),\n",
    "        },\n",
    "        \"BAA-1104045\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:50:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 17:20:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 15:37:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:09:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon3_social_dev_b5350ff\",\n",
    "}\n",
    "\n",
    "aeon4_social_dev_b5350ff = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON4/model-training/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104049\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:46:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 17:15:00\"),\n",
    "        },\n",
    "        \"BAA-1104048\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:10:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:39:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 15:21:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:07:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon4_social_dev_b5350ff\",\n",
    "}\n",
    "\n",
    "aeon4_social_dev_b5350ff2 = {\n",
    "    \"root\": \"Z:/aeon/data/raw/AEON4/model-training/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104049\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 20:33:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 21:13:00\"),\n",
    "        },\n",
    "        \"BAA-1104048\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 19:47:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 20:27:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 19:12:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 19:43:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon4_social_dev_b5350ff2\",\n",
    "}\n",
    "\n",
    "aeon3_social_dev_b5350ff2 = {\n",
    "    \"root\": \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104047\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-02-05 15:44:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-02-05 17:00:00\"),\n",
    "        },\n",
    "        \"BAA-1104045\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-01-31 11:29:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-31 13:00:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon3_social_dev_b5350ff2\",\n",
    "}\n",
    "\n",
    "aeon3_social_310524 = {\n",
    "    \"root\": \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104519\": {  # no tattoo\n",
    "            \"start\": pd.Timestamp(\"2024-05-31 13:21:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-05-31 14:00:00\"),\n",
    "        },\n",
    "        \"BAA-1104518\": {  # tattooed\n",
    "            \"start\": pd.Timestamp(\"2024-05-31 15:05:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-05-31 15:50:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"start\": pd.Timestamp(\"2024-05-31 14:16:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-05-31 15:00:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon3_social_310524\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject states\n",
    "start = pd.Timestamp(\"2024-05-31 00:00:00\")\n",
    "end = pd.Timestamp(\"2024-05-31 23:59:59\")\n",
    "aeon_api.load(\n",
    "    \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "    social02.Environment.SubjectState,\n",
    "    start=start,\n",
    "    end=end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment states\n",
    "aeon_api.load(\n",
    "    \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "    social02.Environment.EnvironmentState,\n",
    "    start=start,\n",
    "    end=end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>area</th>\n",
       "      <th>_frame</th>\n",
       "      <th>_path</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAA-1104518</th>\n",
       "      <td>1139</td>\n",
       "      <td>1139</td>\n",
       "      <td>1139</td>\n",
       "      <td>1139</td>\n",
       "      <td>1139</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAA-1104519</th>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_animal</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x     y  area  _frame  _path   bin\n",
       "id                                                 \n",
       "BAA-1104518   1139  1139  1139    1139   1139  1139\n",
       "BAA-1104519    394   394   394     394    394   394\n",
       "multi_animal   117   117   117     117    117   117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract single + multi-animal frames\n",
    "all_subj_data = create_session_dataset(aeon3_social_310524)\n",
    "all_subj_data.groupby([\"id\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample additional multi_animal data (without area threshold, i.e. animals are not close to each other)\n",
    "subj_dict = {\n",
    "    \"id\": \"multi_animal\",\n",
    "    \"root\": aeon3_social_310524[\"root\"],\n",
    "    \"start\": aeon3_social_310524[\"subjects\"][\"multi_animal\"][\"start\"],\n",
    "    \"end\": aeon3_social_310524[\"subjects\"][\"multi_animal\"][\"end\"],\n",
    "}\n",
    "multi = create_subject_dataset(\n",
    "    subj_dict,\n",
    "    n_samples=1,\n",
    "    n_bins=20,\n",
    ")  # sample random points regardless of area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample additional single animal data\n",
    "subj_dict = {\n",
    "    \"id\": \"BAA-1104519\",\n",
    "    \"root\": aeon3_social_310524[\"root\"],\n",
    "    \"start\": aeon3_social_310524[\"subjects\"][\"BAA-1104519\"][\"start\"],\n",
    "    \"end\": aeon3_social_310524[\"subjects\"][\"BAA-1104519\"][\"end\"],\n",
    "}\n",
    "BAA1104519 = create_subject_dataset(\n",
    "    subj_dict,\n",
    "    n_samples=3,\n",
    "    n_bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"BAA-1104519\" data with resampled data and merge with multi_animal data\n",
    "all_subj_data = all_subj_data[all_subj_data[\"id\"] != \"BAA-1104519\"]\n",
    "all_subj_data = pd.concat([all_subj_data, multi, BAA1104519])\n",
    "# drop duplicates\n",
    "all_subj_data.drop_duplicates(inplace=True)\n",
    "all_subj_data.groupby([\"id\"]).count()\n",
    "# save to csv\n",
    "all_subj_data.to_csv(f'{aeon3_social_310524[\"session\"]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fully labelled datasets for SLEAP model validation\n",
    "single_animal_data = create_fully_labelled_dataset(\n",
    "    aeon3_social_310524,\n",
    "    subj_ids=[\n",
    "        subj for subj in aeon3_social_310524[\"subjects\"].keys() if \"multi_\" not in subj\n",
    "    ],\n",
    ").sample(\n",
    "    frac=0.1\n",
    ")  # sample only 10% of the data\n",
    "single_animal_data.to_csv(f'{aeon3_social_310524[\"session\"]}_single_animal_frames.csv')\n",
    "multi_animal_data = create_fully_labelled_dataset(\n",
    "    aeon3_social_310524,\n",
    "    subj_ids=[\n",
    "        subj for subj in aeon3_social_310524[\"subjects\"].keys() if \"multi_\" in subj\n",
    "    ],\n",
    ").sample(\n",
    "    frac=0.1\n",
    ")  # sample only 10% of the data\n",
    "multi_animal_data.to_csv(f'{aeon3_social_310524[\"session\"]}_multi_animal_frames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve timestamps with temporal discontinuities for RETRAINING\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def adjust_ids(group, classes):\n",
    "    if len(group[\"id\"].unique()) != 2:\n",
    "        # Get the id of the row with the higher class_likelihood\n",
    "        max_id = group.loc[group[\"class_likelihood\"].idxmax(), \"id\"]\n",
    "        # Set the id of the row with the lower class_likelihood to the id that's not max_id\n",
    "        group.loc[group[\"class_likelihood\"].idxmin(), \"id\"] = [\n",
    "            id for id in classes if id != max_id\n",
    "        ][0]\n",
    "    return group\n",
    "\n",
    "\n",
    "# load SLEAP Pose data\n",
    "root = \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\"\n",
    "start_time = pd.Timestamp(\"2024-02-09 17:00\")\n",
    "end_time = pd.Timestamp(\"2024-02-09 18:00\")\n",
    "exp_times = get_experiment_times(root, start_time, end_time)\n",
    "pos = aeon_api.load(root, social02.CameraTop.Pose, start=start_time, end=end_time)\n",
    "pos = exclude_maintenance_data(pos, exp_times)\n",
    "pos[\"class\"] = pos[\"class\"].astype(int)\n",
    "classes = [\n",
    "    \"BAA-1104045\",\n",
    "    \"BAA-1104047\",\n",
    "]  # from SLEAP model config # AEON3[\"BAA-1104045\", \"BAA-1104047\"] # AEON4[\"BAA-1104048\", \"BAA-1104049\"]\n",
    "# assign subject IDs\n",
    "pos[\"id\"] = pos[\"class\"].map(lambda x: classes[x])\n",
    "pos_sorted = pos.sort_values(by=[\"class\", pos.index.name])\n",
    "pos_sorted[\"dist\"] = (\n",
    "    pos_sorted.groupby(\"class\")[[\"x\", \"y\"]]\n",
    "    .diff()\n",
    "    .apply(lambda x: np.linalg.norm(x), axis=1)\n",
    ")\n",
    "# set 100 as threshold for temporal discontinuities\n",
    "violations = pos_sorted[pos_sorted[\"dist\"] > 100]\n",
    "sampled_violations = (\n",
    "    violations.groupby(\"class\")\n",
    "    .apply(sample_n_from_bins, n_samples=2, n_bins=10, include_groups=False)\n",
    "    .reset_index()\n",
    "    .set_index(\"time\")\n",
    "    .sort_index()\n",
    ")\n",
    "# retrieve frames with temporal discontinuities\n",
    "top_frames = aeon_api.load(\n",
    "    root, social02.CameraTop.Video, time=sampled_violations.index.unique()\n",
    ")\n",
    "# merge frames with pose data\n",
    "top_frames_pos = pos[[\"id\", \"x\", \"y\", \"class_likelihood\"]].merge(\n",
    "    top_frames, left_index=True, right_index=True, how=\"inner\"\n",
    ")\n",
    "top_frames_pos = top_frames_pos.reset_index()\n",
    "top_frames_pos = (\n",
    "    top_frames_pos.groupby(\"time\")[top_frames_pos.columns]\n",
    "    .apply(adjust_ids, classes=classes)\n",
    "    .set_index(\"time\")\n",
    ")\n",
    "top_frames_pos.to_csv(\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/aeon3_social_02_retrain.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import sleap\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, Dict\n",
    "from sleap.io.pathutils import fix_path_separator\n",
    "from sleap.gui.suggestions import VideoFrameSuggestions\n",
    "from sleap.nn.config import *\n",
    "from sleap.nn.inference import main as sleap_track\n",
    "from sleap.nn.inference import TopDownMultiClassPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_tracks(labels: sleap.Labels) -> sleap.Labels:\n",
    "    \"\"\"\n",
    "    Removes instances from SLEAP Labels object where track = None.\n",
    "\n",
    "    Args:\n",
    "        labels (sleap.Labels): A SLEAP Labels object.\n",
    "    Returns:\n",
    "        sleap.Labels: A SLEAP Labels object with only tracked instances in each frame.\n",
    "    \"\"\"\n",
    "    lfs = [lf.remove_untracked() for lf in labels.labeled_frames]\n",
    "    return sleap.Labels(\n",
    "        labeled_frames=lfs,\n",
    "        videos=labels.videos,\n",
    "        skeletons=labels.skeletons,\n",
    "        tracks=labels.tracks,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_slp_dataset(\n",
    "    subj_data: pd.DataFrame,\n",
    "    skeleton: sleap.Skeleton,\n",
    "    tracks_dict: Optional[Dict[str, sleap.Track]] = None,\n",
    ") -> sleap.Labels:\n",
    "    \"\"\"\n",
    "    Generates .slp dataset for a given session dict.\n",
    "\n",
    "    Args:\n",
    "        subj_data (pandas.DataFrame): A pandas DataFrame containing the labeled data for a given session.\n",
    "        skeleton (sleap.Skeleton): A sleap Skeleton object.\n",
    "        tracks_dict (dict, optional): A dictionary containing track names and their corresponding sleap Track objects.\n",
    "            If None, a new dictionary is created from the subject IDs in the input data. Default is None.\n",
    "    Returns:\n",
    "        sleap.Labels: A SLEAP Labels object containing labeled frames.\n",
    "    \"\"\"\n",
    "\n",
    "    # create tracks dictionary from subj_ids that are not multi_animal\n",
    "    if not tracks_dict:\n",
    "        tracks_dict = {\n",
    "            subj: sleap.Track(spawned_on=0, name=subj)\n",
    "            for subj in subj_data[\"id\"].unique()\n",
    "            if \"multi_\" not in subj\n",
    "        }\n",
    "\n",
    "    lfs = []\n",
    "\n",
    "    # create video dictionary from new labels\n",
    "    videos_dict = {\n",
    "        video: sleap.Video.from_filename(video, grayscale=True)\n",
    "        for video in subj_data._path.unique()\n",
    "    }\n",
    "\n",
    "    # for each unique frame, create a new labeled frame\n",
    "    for _, row in subj_data.drop_duplicates(subset=[\"_path\", \"_frame\"]).iterrows():\n",
    "        instances = []\n",
    "        if \"multi_\" in row.id:\n",
    "            # duplicate instance for each track\n",
    "            for track in tracks_dict.keys():\n",
    "                instances.append(\n",
    "                    sleap.Instance(\n",
    "                        skeleton=skeleton,\n",
    "                        track=tracks_dict[track],\n",
    "                        points={\"centroid\": sleap.instance.Point(row.x, row.y)},\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            # create a new instance for each row\n",
    "            instances += [\n",
    "                (\n",
    "                    sleap.Instance(\n",
    "                        skeleton=skeleton,\n",
    "                        track=tracks_dict[inst.id],\n",
    "                        points={\"centroid\": sleap.instance.Point(inst.x, inst.y)},\n",
    "                    )\n",
    "                )\n",
    "                for _, inst in subj_data[\n",
    "                    (subj_data[\"_path\"] == row._path)\n",
    "                    & (subj_data[\"_frame\"] == row._frame)\n",
    "                ].iterrows()\n",
    "            ]\n",
    "        # create a new labeled frame\n",
    "        lf = sleap.instance.LabeledFrame(\n",
    "            video=videos_dict[row._path],\n",
    "            frame_idx=row._frame,\n",
    "            instances=instances,\n",
    "        )\n",
    "        lfs.append(lf)\n",
    "\n",
    "    return sleap.Labels(labeled_frames=lfs)\n",
    "\n",
    "\n",
    "def update_slp_video_paths(\n",
    "    labels: \"sleap.Labels\", old_path: str, new_path: str\n",
    ") -> sleap.Labels:\n",
    "    \"\"\"\n",
    "    Updates video paths in a SLEAP labels object (e.g., to move training from local to remote machine).\n",
    "\n",
    "    Args:\n",
    "        labels (sleap.Labels): A SLEAP Labels object.\n",
    "        old_path (str): Old path to video files.\n",
    "        new_path (str): New path to video files.\n",
    "\n",
    "    Returns:\n",
    "        sleap.Labels: A SLEAP Labels object with updated video paths.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    videos = [\n",
    "        sleap.Video.from_filename(\n",
    "            fix_path_separator(vid.filename).replace(old_path, new_path), grayscale=True\n",
    "        )\n",
    "        for vid in labels.videos\n",
    "    ]\n",
    "\n",
    "    lfs = []\n",
    "    for lf in labels.labeled_frames:\n",
    "        lf = sleap.instance.LabeledFrame(\n",
    "            video=videos[labels.videos.index(lf.video)],\n",
    "            frame_idx=lf.frame_idx,\n",
    "            instances=lf.instances,\n",
    "        )\n",
    "        lfs.append(lf)\n",
    "\n",
    "    return sleap.Labels(\n",
    "        labeled_frames=lfs,\n",
    "        videos=videos,\n",
    "        skeletons=labels.skeletons,\n",
    "        tracks=labels.tracks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new skeleton\n",
    "skeleton = sleap.Skeleton()\n",
    "skeleton.add_node(\"centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate slp training dataset for all subjects\n",
    "subj_data = pd.read_csv(f'{aeon3_social_310524[\"session\"]}.csv')\n",
    "labels = generate_slp_dataset(subj_data, skeleton)\n",
    "sleap.Labels.save_file(labels, f'{aeon3_social_310524[\"session\"]}.slp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate separate single, multi-animal .slp datasets for prediction/evaluation\n",
    "# single-animal frames are GT for evaluation\n",
    "# multi-animal frames are labelled to be used as bookmarks for prediction\n",
    "csv_files = [\n",
    "    f'{aeon3_social_310524[\"session\"]}_single_animal_frames.csv',\n",
    "    f'{aeon3_social_310524[\"session\"]}_multi_animal_frames.csv',\n",
    "]\n",
    "tracks_dict = {\n",
    "    subj: sleap.Track(spawned_on=0, name=subj)\n",
    "    for subj in aeon3_social_310524[\"subjects\"].keys()\n",
    "    if \"multi_\" not in subj\n",
    "}\n",
    "for csv_file in csv_files:\n",
    "    subj_data = pd.read_csv(csv_file)\n",
    "    labels = generate_slp_dataset(subj_data, skeleton, tracks_dict=tracks_dict)\n",
    "    labels = update_slp_video_paths(\n",
    "        labels=labels, old_path=\"Z:\", new_path=\"/ceph/aeon\")\n",
    "    sleap.Labels.save_file(labels, f\"{Path(csv_file).stem}_ceph.slp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate slp retrain dataset\n",
    "subj_data = pd.read_csv(\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/aeon3_social_02_retrain.csv\"\n",
    ")\n",
    "labels = generate_slp_dataset(subj_data, skeleton)\n",
    "sleap.Labels.save_file(\n",
    "    labels,\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/aeon3_social_02_retrain.slp\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial parameters\n",
    "subj_id = f'{aeon3b_pattern_tattoo3[\"session\"]}'\n",
    "run_name_centroid = f\"{subj_id}_topdown_top.centroid\"\n",
    "run_name_centered_instance = f\"{subj_id}_topdown_top.centered_instance_multiclass\"\n",
    "root = \"/ceph/aeon/aeon/code/scratchpad/sleap/tail_pattern/\"\n",
    "runs_folder = root + \"models/\"\n",
    "predictions_folder = root + \"predictions/\"\n",
    "groundtruth_folder = root + \"groundtruth/\"\n",
    "\n",
    "try:\n",
    "    skeleton\n",
    "except NameError:\n",
    "    # create new skeleton\n",
    "    skeleton = sleap.Skeleton()\n",
    "    skeleton.add_node(\"centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update local video paths to ceph\n",
    "new_labels = update_slp_video_paths(\n",
    "    labels=sleap.load_file(f\"{subj_id}.slp\"), old_path=\"Z:\", new_path=\"/ceph/aeon\"\n",
    ")\n",
    "sleap.Labels.save_file(new_labels, f\"{root}{subj_id}.slp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into train/val/test\n",
    "labels = sleap.load_file(f\"{root}{subj_id}.slp\")\n",
    "\n",
    "# generate a 0.8/0.1/0.1 train/val/test split\n",
    "labels_train, labels_val_test = labels.split(n=0.8)\n",
    "labels_val, labels_test = labels_val_test.split(n=0.5)\n",
    "\n",
    "# Save with images\n",
    "labels_train.save(f\"{root}{subj_id}.train.pkg.slp\")  # , with_images=True)\n",
    "labels_val.save(f\"{root}{subj_id}.val.pkg.slp\")  # , with_images=True)\n",
    "labels_test.save(f\"{root}{subj_id}.test.pkg.slp\")  # , with_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid model\n",
    "# initalise default training job config\n",
    "cfg = TrainingJobConfig()\n",
    "cfg.data.labels.training_labels = f\"{root}{subj_id}.train.pkg.slp\"\n",
    "cfg.data.labels.validation_labels = f\"{root}{subj_id}.val.pkg.slp\"\n",
    "cfg.data.labels.test_labels = f\"{root}{subj_id}.test.pkg.slp\"\n",
    "\n",
    "# preprocessing and training params\n",
    "cfg.data.preprocessing.input_scaling = 0.75  # 0.5\n",
    "cfg.data.instance_cropping.center_on_part = \"centroid\"\n",
    "cfg.data.instance_cropping.crop_size = 96  # set crop size manually\n",
    "cfg.optimization.augmentation_config.rotate = True\n",
    "cfg.optimization.epochs = 600  # 200\n",
    "cfg.optimization.batch_size = 4\n",
    "\n",
    "cfg.optimization.initial_learning_rate = 0.0001\n",
    "cfg.optimization.learning_rate_schedule.reduce_on_plateau = True\n",
    "cfg.optimization.learning_rate_schedule.reduction_factor = 0.5\n",
    "cfg.optimization.learning_rate_schedule.plateau_min_delta = 1e-06\n",
    "cfg.optimization.learning_rate_schedule.plateau_patience = 20  # 5\n",
    "cfg.optimization.learning_rate_schedule.plateau_cooldown = 3\n",
    "cfg.optimization.learning_rate_schedule.min_learning_rate = 1e-08\n",
    "\n",
    "cfg.optimization.early_stopping.stop_training_on_plateau = True\n",
    "cfg.optimization.early_stopping.plateau_min_delta = 1e-08\n",
    "cfg.optimization.early_stopping.plateau_patience = 30  # 20\n",
    "\n",
    "# configure nn and model\n",
    "cfg.model.backbone.unet = UNetConfig(\n",
    "    max_stride=16,\n",
    "    filters=16,\n",
    "    filters_rate=2.00,\n",
    "    output_stride=2,\n",
    "    # up_interpolate=True, # save computations but may lower accuracy\n",
    ")\n",
    "cfg.model.heads.centroid = CentroidsHeadConfig(\n",
    "    anchor_part=\"centroid\", sigma=2.5, output_stride=2\n",
    ")\n",
    "\n",
    "# configure outputs\n",
    "cfg.outputs.run_name = run_name_centroid\n",
    "cfg.outputs.save_outputs = True\n",
    "cfg.outputs.runs_folder = runs_folder\n",
    "cfg.outputs.save_visualizations = True\n",
    "cfg.outputs.checkpointing.initial_model = True\n",
    "cfg.outputs.checkpointing.best_model = True\n",
    "\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)\n",
    "trainer.setup()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part detection model: centered instance + multi-class\n",
    "# initalise default training job config\n",
    "cfg = TrainingJobConfig()\n",
    "\n",
    "# update path to 0.8/0.1/0.1 train/val/test split\n",
    "cfg.data.labels.training_labels = f\"{root}{subj_id}.train.pkg.slp\"\n",
    "cfg.data.labels.validation_labels = f\"{root}{subj_id}.val.pkg.slp\"\n",
    "cfg.data.labels.test_labels = f\"{root}{subj_id}.test.pkg.slp\"\n",
    "cfg.data.labels.skeletons = [skeleton]  # load skeleton\n",
    "\n",
    "# preprocessing and training params\n",
    "cfg.data.preprocessing.input_scaling = 1.0\n",
    "cfg.data.instance_cropping.center_on_part = \"centroid\"\n",
    "cfg.data.instance_cropping.crop_size = 96  # set crop size manually\n",
    "cfg.optimization.augmentation_config.rotate = True\n",
    "cfg.optimization.epochs = 600\n",
    "cfg.optimization.batch_size = 8  # 4\n",
    "\n",
    "cfg.optimization.initial_learning_rate = 0.0001\n",
    "cfg.optimization.learning_rate_schedule.reduce_on_plateau = True\n",
    "cfg.optimization.learning_rate_schedule.reduction_factor = 0.1  # 0.5\n",
    "cfg.optimization.learning_rate_schedule.plateau_min_delta = 1e-08  # 1e-06\n",
    "cfg.optimization.learning_rate_schedule.plateau_patience = 20  # 5\n",
    "cfg.optimization.learning_rate_schedule.plateau_cooldown = 3\n",
    "cfg.optimization.learning_rate_schedule.min_learning_rate = 1e-08\n",
    "\n",
    "cfg.optimization.early_stopping.stop_training_on_plateau = True\n",
    "cfg.optimization.early_stopping.plateau_min_delta = 1e-08\n",
    "cfg.optimization.early_stopping.plateau_patience = 30  # 20\n",
    "\n",
    "# configure nn and model\n",
    "cfg.model.backbone.unet = UNetConfig(\n",
    "    max_stride=16,  # 32,\n",
    "    output_stride=2,  # 4,\n",
    "    filters=16,  # 24,\n",
    "    filters_rate=1.5,\n",
    "    # up_interpolate=True, # save computations but may lower accuracy\n",
    ")\n",
    "confmaps = CenteredInstanceConfmapsHeadConfig(\n",
    "    anchor_part=\"centroid\",\n",
    "    sigma=1.5,  # 2.5,\n",
    "    output_stride=2,  # 4,\n",
    "    loss_weight=1.0,\n",
    ")\n",
    "# load labels.slp to get track names\n",
    "labels = sleap.load_file(f\"{root}{subj_id}.slp\")\n",
    "class_vectors = ClassVectorsHeadConfig(\n",
    "    classes=[track.name for track in labels.tracks],\n",
    "    output_stride=2,  # 16, #4,\n",
    "    num_fc_layers=3,\n",
    "    num_fc_units=256,\n",
    "    global_pool=True,\n",
    "    loss_weight=0.01,  # TODO: try 1.0\n",
    ")\n",
    "cfg.model.heads.multi_class_topdown = MultiClassTopDownConfig(\n",
    "    confmaps=confmaps, class_vectors=class_vectors\n",
    ")\n",
    "\n",
    "# configure outputs\n",
    "cfg.outputs.run_name = run_name_centered_instance\n",
    "cfg.outputs.save_outputs = True\n",
    "cfg.outputs.runs_folder = runs_folder\n",
    "cfg.outputs.save_visualizations = True\n",
    "cfg.outputs.checkpointing.initial_model = True\n",
    "cfg.outputs.checkpointing.best_model = True\n",
    "\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)\n",
    "\n",
    "trainer.setup()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume training\n",
    "# Load config.\n",
    "model_path = \"models/AEON3_NTP_TP_local_topdown_top.centroid/\"\n",
    "cfg = sleap.load_config(model_path)\n",
    "\n",
    "# Create and initialize the trainer.\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)\n",
    "trainer.setup()\n",
    "\n",
    "# Replace the randomly initialized weights with the saved weights.\n",
    "trainer.keras_model.load_weights(f\"{model_path}best_model.h5\")\n",
    "\n",
    "trainer.config.optimization.epochs = 200\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.keras_model.outputs[0].shape)  # confmaps\n",
    "print(trainer.keras_model.outputs[1].shape)  # id part"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial parameters\n",
    "subj_id = f'{aeon3b_pattern_tattoo3[\"session\"]}'\n",
    "run_name_centroid = f\"{subj_id}_topdown_top.centroid\"\n",
    "run_name_centered_instance = f\"{subj_id}_topdown_top.centered_instance_multiclass\"\n",
    "root = \"/ceph/aeon/aeon/code/scratchpad/sleap/tail_pattern/\"\n",
    "runs_folder = root + \"models/\"\n",
    "predictions_folder = root + \"predictions/\"\n",
    "groundtruth_folder = root + \"groundtruth/\"\n",
    "\n",
    "print(run_name_centroid, run_name_centered_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a single multi-animal video\n",
    "subj_idx = 0\n",
    "video_idx = 0\n",
    "\n",
    "multi_subj_ids = [\n",
    "    subj_id\n",
    "    for subj_id in aeon3b_pattern_tattoo3[\"subjects\"].keys()\n",
    "    if \"multi_\" in subj_id\n",
    "]\n",
    "\n",
    "# select one multi-animal session only\n",
    "input_file = f'{root}{aeon3b_pattern_tattoo3[\"session\"]}_{multi_subj_ids[subj_idx]}.slp'\n",
    "\n",
    "# infer on user-labeled frames on the first video only\n",
    "output_file_pr = f\"{predictions_folder}{subj_id}_{multi_subj_ids[subj_idx]}_pr.slp\"\n",
    "sleap_track(\n",
    "    [\n",
    "        input_file,\n",
    "        \"--model\",\n",
    "        f\"{runs_folder}{run_name_centroid}\",\n",
    "        \"--model\",\n",
    "        f\"{runs_folder}{run_name_centered_instance}\",\n",
    "        \"--only-labeled-frames\",\n",
    "        \"--video.index\",\n",
    "        str(video_idx),\n",
    "        \"--output\",\n",
    "        output_file_pr,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 100 suggestions based on low-scoring frames to be proofread\n",
    "labels_pr = sleap.load_file(output_file_pr)\n",
    "output_file_low_gt = (\n",
    "    f\"{groundtruth_folder}{subj_id}_1_{multi_subj_ids[subj_idx]}_low_gt.slp\"\n",
    ")\n",
    "labels_missing = sleap.Labels(\n",
    "    [label for label in labels_pr.labels if label.n_predicted_instances < 3]\n",
    ")\n",
    "suggestions = VideoFrameSuggestions.suggest(\n",
    "    labels=labels_missing,\n",
    "    params=dict(\n",
    "        videos=[labels_missing.videos[video_idx]],\n",
    "        method=\"prediction_score\",\n",
    "        score_limit=0.5,\n",
    "        instance_limit_lower=1,\n",
    "        instance_limit_upper=3,\n",
    "    ),\n",
    ")\n",
    "\n",
    "if len(suggestions) > 100:\n",
    "    suggestions = random.sample(suggestions, 100)\n",
    "\n",
    "lfs = []\n",
    "for suggestion in suggestions:\n",
    "    matching_frames = labels_missing.find(\n",
    "        video=labels_missing.videos[video_idx], frame_idx=suggestion.frame_idx\n",
    "    )\n",
    "    if matching_frames:\n",
    "        lf = matching_frames[0]\n",
    "        instances = []\n",
    "        for instance in lf.instances_to_show:\n",
    "            instances.append(\n",
    "                sleap.Instance(\n",
    "                    skeleton=instance.skeleton,\n",
    "                    track=instance.track,\n",
    "                    points={\n",
    "                        \"centroid\": sleap.instance.Point(\n",
    "                            instance.points[0].x, instance.points[0].y\n",
    "                        )\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        lfs.append(\n",
    "            sleap.instance.LabeledFrame(\n",
    "                video=lf.video,\n",
    "                frame_idx=lf.frame_idx,\n",
    "                instances=instances,\n",
    "            )\n",
    "        )\n",
    "sleap.Labels.save_file(sleap.Labels(labeled_frames=lfs), output_file_low_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 100 random consecutive frames as ground truth data for evaluation\n",
    "output_file_rand_gt = (\n",
    "    f\"{groundtruth_folder}{subj_id}_{multi_subj_ids[subj_idx]}_rand_gt.slp\"\n",
    ")\n",
    "random_frame_from = True\n",
    "consecutive = True\n",
    "num_frames = 100  # 3000 = 1min\n",
    "\n",
    "if consecutive:\n",
    "    frame_from = (\n",
    "        random.randint(0, len(labels_pr.labeled_frames) - num_frames)\n",
    "        if random_frame_from\n",
    "        else 0\n",
    "    )\n",
    "    selected_frame_idx = list(range(frame_from, frame_from + num_frames))\n",
    "else:\n",
    "    selected_frame_idx = random.sample(range(len(labels_pr.labeled_frames)), num_frames)\n",
    "\n",
    "sfs = []\n",
    "for idx in selected_frame_idx:\n",
    "    sf = labels_pr.labeled_frames[idx]\n",
    "    instances = []\n",
    "    for instance in sf.instances_to_show:\n",
    "        instances.append(\n",
    "            sleap.Instance(\n",
    "                skeleton=instance.skeleton,\n",
    "                track=instance.track,\n",
    "                points={\n",
    "                    \"centroid\": sleap.instance.Point(\n",
    "                        instance.points[0].x, instance.points[0].y\n",
    "                    )\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    sfs.append(\n",
    "        sleap.instance.LabeledFrame(\n",
    "            video=sf.video,\n",
    "            frame_idx=sf.frame_idx,\n",
    "            instances=instances,\n",
    "        )\n",
    "    )\n",
    "\n",
    "sleap.Labels.save_file(sleap.Labels(labeled_frames=sfs), output_file_rand_gt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAA-1104045 Accuracy: 0.977\n",
      "BAA-1104047 Accuracy: 0.84\n",
      "ID accuracy: 0.907\n",
      "Total tracks: 179343\n",
      "Tracks identified: 179454\n",
      "Tracks correctly identified: 162630\n"
     ]
    }
   ],
   "source": [
    "# evaluate single-animal predictions with ground truth data\n",
    "gt_file = \"/ceph/aeon/aeon/code/scratchpad/sleap/social_dev_b5350ff/predictions/aeon3_social_dev_b5350ff_single_animal_frames_ceph.slp\"\n",
    "pr_file = \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/predictions/aeon3_social_dev_b5350ff_single_animal_frames_ceph_pr.slp\"\n",
    "labels_gt = sleap.load_file(gt_file)\n",
    "labels_pr = sleap.load_file(pr_file)\n",
    "metrics = sleap.nn.evals.evaluate(labels_gt, labels_pr, oks_scale=96)\n",
    "framepairs = sleap.nn.evals.find_frame_pairs(labels_gt, labels_pr)\n",
    "matches = sleap.nn.evals.match_frame_pairs(framepairs, scale=96)\n",
    "positive_pairs = matches[0]\n",
    "false_negatives = matches[1]\n",
    "track_names = [track.name for track in labels_gt.tracks]\n",
    "correct_id = {track_name: [] for track_name in track_names}\n",
    "for positive_pair in positive_pairs:\n",
    "    gt = (\n",
    "        positive_pair[0]\n",
    "        if isinstance(positive_pair[1], sleap.PredictedInstance)\n",
    "        else positive_pair[1]\n",
    "    )\n",
    "    correct_id[gt.track.name].append(\n",
    "        positive_pair[0].track.name == positive_pair[1].track.name\n",
    "    )\n",
    "track_sums = 0\n",
    "track_lens = 0\n",
    "for track in track_names:\n",
    "    track_sums += sum(correct_id[track])\n",
    "    track_lens += len(correct_id[track])\n",
    "    print(\n",
    "        f\"{track} Accuracy: {round(sum(correct_id[track]) / len(correct_id[track]), 3)}\"\n",
    "    )\n",
    "print(\"ID accuracy:\", round(track_sums / track_lens, 3))\n",
    "print(\"Total tracks:\", len(labels_gt.all_instances))\n",
    "print(\"Tracks identified:\", len(labels_pr.all_instances))\n",
    "print(\"Tracks correctly identified:\", track_sums)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:06:00.867119: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-02-15 10:06:00.867151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hpc-gw1): /proc/driver/nvidia/version does not exist\n",
      "2024-02-15 10:06:00.867452: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max instances set, limiting instances to 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:06:21.137575: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpm6ucnd1f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 10:06:33.817603: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-02-15 10:06:33.817809: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2024-02-15 10:06:34.119018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 2517 nodes (2419), 4209 edges (4105), time = 133.61ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 3.514ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export model\n",
    "predictor = TopDownMultiClassPredictor.from_trained_models(\n",
    "    centroid_model_path=\"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON4/models/aeon4_social_dev_b5350ff2_retrain_ceph_topdown_top.centroid\",\n",
    "    confmap_model_path=\"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON4/models/aeon4_social_dev_b5350ff2_retrain_ceph_topdown_top.centered_instance_multiclass\",\n",
    "    resize_input_layer=False,  # SLEAP 1.3.0+\n",
    ")\n",
    "\n",
    "predictor.export_model(\n",
    "    \"/ceph/aeon/aeon/data/processed/test-node1/4546247/2024-02-13T17-00-00/topdown-multianimal-id-133/\",\n",
    "    max_instances=2,\n",
    "    unrag_outputs=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0e3000693f8b9aa662d7863f075a07b6f4295c6c6941a96ccabdea0fbe2a07d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

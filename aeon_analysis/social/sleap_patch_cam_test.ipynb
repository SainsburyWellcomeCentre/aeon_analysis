{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEON env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import aeon\n",
    "import aeon.io.api as aeon_api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from aeon.analysis.movies import gridframes\n",
    "from aeon.io.video import frames\n",
    "from aeon.schema.schemas import social02\n",
    "from dotmap import DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeon3_social_02 = {\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104047\": {  # no tattoo\n",
    "            \"root\": \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "            \"start\": pd.Timestamp(\"2024-02-05 15:43:11.581535816\"),\n",
    "            \"end\": pd.Timestamp(\"2024-02-08 14:49:41.552000046\"),\n",
    "        },\n",
    "        \"BAA-1104045\": {  # tattooed\n",
    "            \"root\": \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\",\n",
    "            \"start\": pd.Timestamp(\"2024-01-31 11:28:45.543519974\"),\n",
    "            \"end\": pd.Timestamp(\"2024-02-03 16:28:29.139999866\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"root\": \"/ceph/aeon/aeon/data/raw/AEON3/model-training/\",  # different root\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 15:37:00\"),  # placeholder\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:09:00\"),\n",
    "        },\n",
    "    },\n",
    "    # patch 1 and 2 rfids are swapped in AEON3\n",
    "    \"patch_camera_order\": [2, 1, 3],\n",
    "    \"session\": \"aeon3_social_02\",\n",
    "}\n",
    "\n",
    "aeon4_social_02 = {\n",
    "    \"subjects\": {\n",
    "        \"BAA-1104049\": {  # no tattoo\n",
    "            \"root\": \"/ceph/aeon/aeon/data/raw/AEON4/social0.2/\",\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:46:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 17:15:00\"),\n",
    "        },\n",
    "        \"BAA-1104048\": {  # tattooed\n",
    "            \"root\": \"/ceph/aeon/aeon/data/raw/AEON4/social0.2/\",\n",
    "            \"start\": pd.Timestamp(\"2024-01-09 16:10:00\"),\n",
    "            \"end\": pd.Timestamp(\"2024-01-09 16:39:00\"),\n",
    "        },\n",
    "        \"multi_animal\": {\n",
    "            \"root\": \"/ceph/aeon/aeon/data/raw/AEON4/model-training/\",  # different root\n",
    "            \"start\": pd.Timestamp(\"2024-01-21 19:12:00\"),  # placeholder\n",
    "            \"end\": pd.Timestamp(\"2024-01-21 19:43:00\"),\n",
    "        },\n",
    "    },\n",
    "    \"session\": \"aeon4_social_02\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_times(\n",
    "    root: str | os.PathLike, start_time: pd.Timestamp, end_time: pd.Timestamp\n",
    ") -> DotMap:\n",
    "    \"\"\"\n",
    "    Retrieve experiment start and stop times from environment states\n",
    "    (i.e. times outside of maintenance mode) occurring within the\n",
    "    given start and end times.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path where epoch data is stored.\n",
    "        start_time (pandas.Timestamp): Start time.\n",
    "        end_time (pandas.Timestamp): End time.\n",
    "\n",
    "    Returns:\n",
    "        DotMap: A DotMap object containing two keys: 'start' and 'stop',\n",
    "        corresponding to pairs of experiment start and stop times.\n",
    "\n",
    "    Notes:\n",
    "    This function uses the last 'Maintenance' event (if available, otherwise\n",
    "    `end_time`) as the last 'Experiment' stop time. If the first retrieved state\n",
    "    is 'Maintenance' (e.g. 'Experiment' mode entered before `start_time`),\n",
    "    `start_time` is used as the first 'Experiment' start time.\n",
    "    \"\"\"\n",
    "\n",
    "    experiment_times = DotMap()\n",
    "    env_states = aeon.load(\n",
    "        root,\n",
    "        social02.Environment.EnvironmentState,\n",
    "        # aeon.io.reader.Csv(\"Environment_EnvironmentState_*\", [\"state\"]),\n",
    "        start_time,\n",
    "        end_time,\n",
    "    )\n",
    "    if env_states.empty:\n",
    "        warnings.warn(\n",
    "            \"The environment state df is empty. \"\n",
    "            \"Using input `start_time` and `end_time` as experiment times.\"\n",
    "        )\n",
    "        experiment_times.start = [start_time]\n",
    "        experiment_times.stop = [end_time]\n",
    "        return experiment_times\n",
    "    if env_states[\"state\"].iloc[-1] != \"Maintenance\":\n",
    "        warnings.warn(\n",
    "            \"No 'Maintenance' event at the end of the search range. \"\n",
    "            \"Using input `end_time` as last experiment stop time.\"\n",
    "        )\n",
    "        # Pad with a \"Maintenance\" event at the end\n",
    "        env_states = pd.concat(\n",
    "            [\n",
    "                env_states,\n",
    "                pd.DataFrame(\n",
    "                    \"Maintenance\",\n",
    "                    index=[end_time],\n",
    "                    columns=env_states.columns,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    # Use the last \"Maintenance\" event as end time\n",
    "    end_time = (env_states[env_states.state == \"Maintenance\"]).index[-1]\n",
    "    env_states = env_states[~env_states.index.duplicated(keep=\"first\")]\n",
    "    # Retain only events between visit start and stop times\n",
    "    env_states = env_states.iloc[\n",
    "        env_states.index.get_indexer([start_time], method=\"bfill\")[\n",
    "            0\n",
    "        ]: env_states.index.get_indexer([end_time], method=\"ffill\")[0]\n",
    "        + 1\n",
    "    ]\n",
    "    # Retain only events where state changes (experiment-maintenance pairs)\n",
    "    env_states = env_states[env_states[\"state\"].ne(\n",
    "        env_states[\"state\"].shift())]\n",
    "    if env_states[\"state\"].iloc[0] == \"Maintenance\":\n",
    "        warnings.warn(\n",
    "            \"No 'Experiment' event at the start of the search range. \"\n",
    "            \"Using input `end_time` as last experiment stop time.\"\n",
    "        )\n",
    "        # Pad with an \"Experiment\" event at the start\n",
    "        env_states = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(\n",
    "                    \"Experiment\",\n",
    "                    index=[start_time],\n",
    "                    columns=env_states.columns,\n",
    "                ),\n",
    "                env_states,\n",
    "            ]\n",
    "        )\n",
    "    experiment_times.start = env_states[\n",
    "        env_states[\"state\"] == \"Experiment\"\n",
    "    ].index.values\n",
    "    experiment_times.stop = env_states[\n",
    "        env_states[\"state\"] == \"Maintenance\"\n",
    "    ].index.values\n",
    "\n",
    "    return experiment_times\n",
    "\n",
    "\n",
    "def exclude_maintenance_data(\n",
    "    data: pd.DataFrame, experiment_times: DotMap\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Exclude rows not in experiment times (i.e., corresponding to maintenance times)\n",
    "    from the given dataframe.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The data to filter. Expected to have a DateTimeIndex.\n",
    "        experiment_times (DotMap): A DotMap object containing experiment start and stop times.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The filtered data.\n",
    "    \"\"\"\n",
    "    filtered_data = pd.concat(\n",
    "        [\n",
    "            data.loc[start:stop]\n",
    "            for start, stop in zip(experiment_times.start, experiment_times.stop)\n",
    "        ]\n",
    "    )\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def get_single_frame(\n",
    "    root: str | os.PathLike,\n",
    "    video_reader: aeon.io.reader.Video,\n",
    "    time: pd.Timestamp,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Retrieve a single frame from the given root directory,\n",
    "    Video reader, and time.\n",
    "\n",
    "    Args:\n",
    "        root (str or os.PathLike): The root path where epoch data\n",
    "            is stored.\n",
    "        video_reader (aeon.io.reader.Video): The Video reader.\n",
    "        time (pd.Timestamp): The timestamp of the frame to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The raw frame.\n",
    "    \"\"\"\n",
    "    vdata = aeon.load(\n",
    "        root, video_reader, start=time, end=time + pd.Timedelta(seconds=1)\n",
    "    )\n",
    "    vframe = frames(vdata.iloc[:1])\n",
    "    return np.squeeze(list(vframe))\n",
    "\n",
    "\n",
    "def show_frame(raw_frame: np.ndarray, width: int = 1440, height: int = 1080):\n",
    "    \"\"\"\n",
    "    Display raw input frame(s).\n",
    "\n",
    "    Args:\n",
    "        raw_frame (numpy.ndarray): The raw frame.\n",
    "        width (int): The width of the display layout.\n",
    "        height (int): The height of the display layout.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    width = width\n",
    "    height = height\n",
    "    fig = go.Figure(\n",
    "        data=[go.Image(z=raw_frame)],\n",
    "        layout=go.Layout(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            xaxis=dict(\n",
    "                visible=False,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                visible=False,\n",
    "                scaleanchor=\"x\",\n",
    "            ),\n",
    "            margin=dict(l=0, r=0, t=0, b=0),\n",
    "        ),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify start, end times to be added to subject dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject states to retrieve enter, exit times\n",
    "root = \"/ceph/aeon/aeon/data/raw/AEON3/social0.2/\"\n",
    "# aeon.io.reader.Subject(\"Environment_SubjectState_*\"))\n",
    "aeon_api.load(root, social02.Environment.SubjectState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject region visits if subject states are not available\n",
    "# aeon.io.reader.Csv(\"Environment_SubjectVisits_*\", columns=[\"id\", \"state\", \"region\"]))\n",
    "subj_visits = aeon_api.load(root, social02.Environment.SubjectVisits)\n",
    "subj_visits[(subj_visits[\"region\"] == \"Environment\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curate frames and export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get experiment times for each subject within a session\n",
    "subj_ids = [subj for subj in aeon3_social_02[\"subjects\"]\n",
    "            if \"multi_\" not in subj]\n",
    "cameras = pd.DataFrame()\n",
    "for subj in subj_ids:\n",
    "    subj_dict = aeon3_social_02[\"subjects\"][subj]\n",
    "    root = aeon3_social_02.get(\"root\", subj_dict[\"root\"])\n",
    "    # patch 1 and 2 rfids are swapped in AEON3\n",
    "    camera_idx = aeon3_social_02.get(\"patch_camera_order\", [1, 2, 3])\n",
    "    start_time = subj_dict[\"start\"]\n",
    "    end_time = subj_dict[\"end\"]\n",
    "    experiment_times = get_experiment_times(root, start_time, end_time)\n",
    "    print(\n",
    "        f\"{subj}\"\n",
    "        f\"\\nexp start times: {experiment_times.start}\"\n",
    "        f\"\\nexp stop times: {experiment_times.stop}\"\n",
    "    )\n",
    "    for i in range(1, 4):\n",
    "        rfid_reads = aeon_api.load(\n",
    "            root,\n",
    "            aeon.io.reader.Harp(\n",
    "                pattern=f\"Patch{i}Rfid_32_*\", columns=[\"Rfid\"]),\n",
    "            start=start_time,\n",
    "            end=end_time,\n",
    "        )\n",
    "        rfid_reads = exclude_maintenance_data(rfid_reads, experiment_times)\n",
    "        # get the 3 hours with the most RFID reads\n",
    "        most_reads = rfid_reads.groupby(\n",
    "            pd.Grouper(freq=\"h\")).size().nlargest(6).index[3:]\n",
    "        rfid_most_reads = pd.DataFrame()\n",
    "        for hour in most_reads:\n",
    "            rfid_most_reads = pd.concat(\n",
    "                [rfid_most_reads,\n",
    "                    rfid_reads.loc[hour: hour + pd.Timedelta(hours=1)]]\n",
    "            )\n",
    "        n_samples = min(100, len(rfid_most_reads))\n",
    "        # randomly sample max 100 rows per patch\n",
    "        rfid_most_reads = rfid_most_reads.sample(n=n_samples)\n",
    "        camera = aeon_api.load(\n",
    "            root,\n",
    "            aeon.io.reader.Video(f\"CameraPatch{camera_idx[i-1]}_*\"),\n",
    "            time=rfid_most_reads.index,\n",
    "        )\n",
    "        camera[\"id\"] = subj\n",
    "        cameras = pd.concat([cameras, camera])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras.to_csv(\n",
    "    f'/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/{aeon3_social_02[\"session\"]}_rfid_patch_frames_test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional sanity check to make sure frames contain animals\n",
    "show_frame(\n",
    "    gridframes(list(frames(cameras.sample(n=25))),\n",
    "               width=1440, height=1080, shape=25)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLEAP env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sleap\n",
    "from sleap.gui.suggestions import SuggestionFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = pd.read_csv(\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/\"\n",
    "    f\"{aeon3_social_02['session']}_rfid_patch_frames_test.csv\"\n",
    ")\n",
    "cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dict = {\n",
    "    video: sleap.Video.from_filename(video, grayscale=True)\n",
    "    for video in cameras._path.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SuggestionFrames to be inferred using existing patch cam models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_path = (\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/\"\n",
    "    f\"{aeon3_social_02['session']}_rfid_patch_frames_id.slp\"\n",
    ")\n",
    "labels_train = sleap.load_file(slp_path)\n",
    "tracks = labels_train.tracks\n",
    "\n",
    "sfs = []\n",
    "for _, row in cameras.drop_duplicates(subset=[\"_path\", \"_frame\"]).iterrows():\n",
    "    # create a new SuggestionFrame for each row\n",
    "    sfs.append(\n",
    "        SuggestionFrame(\n",
    "            video=videos_dict[row._path],\n",
    "            frame_idx=row._frame,\n",
    "        )\n",
    "    )\n",
    "labels_suggest = sleap.Labels(videos=list(\n",
    "    videos_dict.values()), tracks=tracks, suggestions=sfs)\n",
    "len(labels_suggest.suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_path = (\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/\"\n",
    "    f\"{aeon3_social_02['session']}_rfid_patch_frames_test.slp\"\n",
    ")\n",
    "sleap.Labels.save_file(labels_suggest, slp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/ceph/aeon/aeon/code/scratchpad/sleap/multi_point_tracking/single_animal_CameraPatch/models/231201_173729.single_instance.n=400\"\n",
    "slp_pr_path = (\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/\"\n",
    "    f\"{aeon3_social_02['session']}_rfid_patch_frames_test_gt.slp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system sleap-track -m \"{model_path}\" --only-suggested-frames -o \"{slp_pr_path}\" \"{slp_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert predictions to user labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pr = sleap.load_file(slp_pr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create skeleton with just 'centroid' and 'spine_top'\n",
    "skeleton = sleap.Skeleton()\n",
    "skeleton.add_nodes([\"centroid\", \"spine_top\"])\n",
    "skeleton.add_edge(\"spine_top\", \"centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of Tracks\n",
    "tracks_dict = {\n",
    "    subj: sleap.Track(spawned_on=0, name=subj) for subj in cameras[\"id\"].unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = []\n",
    "for lf in labels_pr.labeled_frames:\n",
    "    instances = []\n",
    "    video_path = lf.video.filename.replace(\"Y:\", \"/ceph/aeon\")\n",
    "    for inst in lf.instances:\n",
    "        track_name = cameras[\n",
    "            (cameras._path == video_path) & (cameras._frame == lf.frame_idx)\n",
    "        ][\"id\"].values[0]\n",
    "        instances.append(\n",
    "            sleap.Instance(\n",
    "                skeleton=skeleton,\n",
    "                track=tracks_dict[track_name],\n",
    "                points={\n",
    "                    node.name: sleap.instance.Point(point.x, point.y)\n",
    "                    for node, point in inst.nodes_points\n",
    "                    if node.name in [\"centroid\", \"spine_top\"]\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    # create a new labeled frame\n",
    "    user_lf = sleap.instance.LabeledFrame(\n",
    "        video=videos_dict[video_path],\n",
    "        frame_idx=lf.frame_idx,\n",
    "        instances=instances,\n",
    "    )\n",
    "    lfs.append(user_lf)\n",
    "labels_user = sleap.Labels(labeled_frames=lfs)\n",
    "labels_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap.Labels.save_file(\n",
    "    labels_user,\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/\"\n",
    "    f\"{aeon3_social_02['session']}_rfid_patch_frames_test_gt.slp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with patch cam ID model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/models/CameraPatch.multi_class_bottomup\"\n",
    "slp_pr_path = (\n",
    "    \"/ceph/aeon/aeon/code/scratchpad/sleap/social0.2/AEON3/\"\n",
    "    f\"{aeon3_social_02['session']}_rfid_patch_frames_test_pr.slp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system sleap-track -m \"{model_path}\" --only-suggested-frames -o \"{slp_pr_path}\" \"{slp_path}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
